start,end,text
880,29640," Hello, and welcome to another Zorzin session. How about that? So I have a breaking news for you guys. Python is slow. So yeah, basically, we've been developing our own programming language for the past like three weeks. And we're developing this programming language in in Python, as you can see. So yeah, it's kind of weird. I know developing the programming language in Python, but that's what we're doing."
30000,59980," And to be fair, the specific language we're using for doing that doesn't really matter because we're generating assembly code anyway. So the final result is actually quite fast, right? So it doesn't matter what's the host, like how fast the host language is, it only affects the the process of compilation, how fast the compilation go, but the final result is just actually unaffected by the by the host language. But here's the interesting thing. On top of the compilation,"
60000,89980," simulation mode, our language also has a simulation mode. And I think simulation is actually quite bad name for the for for this, I rather mean emulation. So what it does, instead of compiling the program, it emulates the program, essentially, it interprets it. So we're interpreting a language using an interpreted language. And that is unsurprisingly, very slow. But I didn't realize how slow that is until recently,"
89980,104980," until we try to use this language for solving project Euler problems. For those who doesn't know project Euler is basically a collection of computer, computer science problems, right, you can find this thing in the description, I'm going to put it in the description."
104980,109980," Right, so there you go, I'm going to put a lot of things in the description. So you can find the source code of the language we're developing also here. And we already accumulated like a good playlist of the series of me developing this thing. So in here is the project Euler. And honestly, I'm going to also put the link to the stream where we were solving the project Euler problems. So project Euler"
109980,116980," Euler solving stream, right, right, so all that is going to be in the description, right, so all that is going to be in the description. So I'm going to put the link to the stream where we were solving the project Euler problems. So project Euler solving stream, right, so all that is going to be in the description."
116980,124220," good playlist of the series of me developing this thing. So in here is the project Euler. And"
124220,131440," honestly, I'm going to also put the link to the stream where we were solving the project Euler"
131440,139460," problems. So project Euler solving stream, right? So all of that is going to be in the description."
140280,146680," All right, so and we are solving the fourth problem, right? The specifics of this problem"
146680,156420," doesn't really matter. What matters is that we have two nested loops, right? So from 100 to 1000,"
156420,165500," right? So essentially, yeah, like roughly 1000 of iterations, 900 iterations. And inside of that loop,"
165680,172380," we have additional loop, which basically factorizes the number, right? So we have essentially three"
172380,180520," nested loops. And let's take a look at how fast this program runs, actually, right? So let's go ahead"
180520,188020," and compile that program. So this is going to be example and problem fourth. Actually, that example"
188020,196720," is actually Euler problem fourth, fourth. All right, so this is how quickly it compiled and then run."
196720,201840," Right. So as you can see, we generated assembly code, we compile the assembly code, and then we link it into"
201840,206980," the program. And then we run the program, we can run the program separately without the process of"
206980,214780," compilation just to time it. Right. So the expected result is 906609. Right. And if we time this entire"
214780,221860," time, I think it's relatively fast, could have been faster, but it's usually does not exceed 200 seconds,"
221860,231340," at milliseconds, 200 milliseconds. So and we can try to simulate that program, right? So a simulation will"
231340,236140," essentially not compile it will it will just try to interpret this program. And let's see how much time it"
236140,243900," will take to do. So I'm going to put a sim in here, and I'm going to put the time in here. And so it will go,"
243900,254060," if I remember correctly, like for five minutes, roughly 150 milliseconds, five minutes, to be fair,"
254060,261100," five minutes is actually pretty long time. So let's make a small cut and just like jump straight into"
261100,269660," this thing being finished. Holy moly, it actually took eight minutes instead of expected five, it took five"
269660,274780," minutes when I was not running OBS, but with OBS, it actually added like three extra minutes."
274780,280860," Okay, so as you can see, the program actually still works correctly, it produces the same result, it's just"
280860,288700," extremely slow. As a matter of fact, like it's like magnitude slower, and I never actually experienced the"
288700,296700," simulation mode being that slow. So the discrepancy was there, but it was not that many magnitudes. So"
296700,303100," there's something really, really fishy going on in here. And to be fair, like the the performance of"
303100,309980," the simulation mode got so bad, to the point that I don't consider it useful anymore. And it was like,"
309980,316460," seriously thinking to completely remove it from the language. But here's the thing, I think the simulation"
316460,323340," simulation mode by itself, like Python, and like, you know, performance aside is a very useful thing, because"
323340,328860," you're essentially executing the program in a sandbox environment, and you have a full control of that"
328860,335100," environment. And you can, for instance, gather some interesting metrics about the program you're running"
335100,341660," without compiling it or without, you know, using something platform dependent, right. So it's actually a pretty cool"
341660,350300," sandbox that can give you a lot of insights into the into your program that you're simulating. And so"
350300,358620," here's another thing that something is fish is going on. I think Droka, one of my viewers actually"
358620,364940," rewrote the simulation mode just for shits and giggles in Go. Right, so I'm going to put their"
366540,379420," their implementation in description. So here it is. So Porth simulation in Go. Right, so this is where"
379420,385580," we're going to have here. And here's an interesting thing for a thing for rule 110 specifically, right,"
385580,393740," so we have a bunch of examples for a written in our language. So for all 110, the simulation in Python was"
393740,400780," four seconds. But when we're written in Go, it actually went down to 26 milliseconds, right,"
400780,408860," dramatically faster. So basically, the problem is probably with Python somewhere. So if we used like"
408860,414220," a different language, we wouldn't have to remove the simulation mode and simulation mode would have been"
414220,423420," feasible. Right. So what I decided to do, I decided to try to look into how we implement the simulation"
423420,430780," mode in Python, and see if we can improve something, right, and see if there is any particular operation"
430780,435980," within the simulation mode that is extremely slow, some like maybe some sort of a bottleneck that we can"
435980,442060," fix and improve the performance of this thing overall. So and let's take a look at it. Let's take a look at"
442060,449660," how the simulation is implemented generally. So it's implemented in a function called simulation,"
449660,455980," actually simulate little endian Linux, right, it accepts a program, a sequence of operations or a"
455980,462380," sequence of instructions of a bytecode, and just iterates over them. And it has a huge switch case and"
462380,469980," just interprets them, right. So and what I wanted to do, I wanted to add some sort of instrumentation"
469980,477260," for each individual operation and each individual intrinsic. And just gather how many times a particular"
477260,485420," operation was executed to just see what's the hottest operation for that specific program. And also maybe"
485420,493500," gather some timing, right, so for like, how much time the program spent executing that instruction and that"
493500,502300," intrinsic. And maybe if we run it for the problem 04, we'll gather enough insights to actually see where"
502300,509500," the problem, right. So maybe there is one particular operation here that is extremely slow. And if we fix and"
509500,514860," speed up that instruction, the simulation mode overall is going to become faster, right, so but we don't"
514860,520380," know what that instruction yet. So to to know that instruction, we need to do some some measurements,"
520380,528780," right. So how are we going to be doing measurements, let's actually create some sort of a table. All right, so"
531020,539100," OP stats, right. So I want this thing to be some sort of a dictionary that maps OP type to, let's say, an"
539100,545180," integer, and this is going to be essentially a counter how many times a particular operation has been executed."
545180,552620," So as far as I know, dictionary is not particularly convenient, because it doesn't really have a default"
552620,560220," value, does it? Maybe we can make it have a default value, maybe we can pre initialize it with default"
560220,565980," values or something. So if I have something like this, and if I query something that doesn't exist,"
565980,572620," it will essentially tell me, well, basically throw an exception, I cannot just do a plus one and assume"
572620,578380," that it's going to be defaulted to zero, maybe there is a way to do a default. I remember there was something"
578380,584620," like set default. But I don't quite remember how to use that. Can I just set default to zero, right,"
584620,594140," and then just do plus one? Probably doesn't work like this. So luckily, operation type is enumeration."
594140,600540," So one of the things we can do, we can probably make this entire thing at least, right, we're going to be"
600540,609980," making it a list. And then we're going to create a list of the size of the operation types, right. So"
609980,616780," operation types, as you can see, class or P type is enumeration. And if you take a length of this"
616780,623420," thing, it will give you this thing, it will give you eight, eight enumeration values. So we can create"
623420,631740," the list. And now we should be able to access the OP stats by doing something like OP type, right,"
631740,637180," so by doing something like OP type, and then do plus one, because all of them are initialized with zero."
637180,643260," I think it's actually kind of useful. Okay, so I think it would make sense to actually"
643260,651260," bump the operation counter at the end of the iteration or after the types are checked correctly."
651260,658860," And we're trying to get a statistic for non existing operation. So this is where we're going to be"
658860,668380," doing all of that. Right. Oh, shit. Okay. So yeah, we have a pretty cool flag in here, a debug flag."
668380,676300," It's only enabled if you provide minus debug before the sub command of the compiler. So I think we're"
676300,681180," going to be printing the this stuff in the debug mode, right? So I'm not going to print"
681180,689420," the memory dump. And here I want to do something like OP type in OP type. And here I'm going to just"
689420,696140," bring the statistics. So this is going to be the name of the operation. And this is how many times"
696140,702700," the operation has been, you know, encountered has been executed rather, right? So this is going to be OP type."
703660,713980," And then OP stats, OP type. There we go. So if I try to run it, let's actually run it on a smaller program."
715180,725020," something like simulate maybe tests, right? And it's going to be a stack, right? So step forth."
725020,732540," Okay, so we have some problem in here. Least indices must be integer or slices. Oh, okay. So since"
732540,742060," enumeration is not an integer, I cannot use it as an index, which is kind of sus, not gonna lie. But here's an"
742060,750300," interesting thing. Can I just convert enumeration to an integer? Let me load the porc compiler into the"
750300,757500," shell. There we go. So I have something like OP type. And let's take a look at the push int, right? Can"
757500,765740," I do just int? Must be a string, I cannot even convert it. Okay, so there must be a way to do that. Python,"
766380,778140," Enum to int. Okay, so int. So there's something called int enum. Base classical creating immersion"
778140,782940," contains that are also subclasses. Oh, this is perfect. This is exactly what I need. So I think"
782940,789660," what I just have to do is I have to do int enum. And also probably need to import this entire thing."
790300,795020," Right. So by default, enum doesn't act like an integer, right? So if you want it to act like an"
795020,801980," integer, you have to, you know, inherit a different thing. Okay, so I didn't enable the debug mode."
801980,806060," Let's quickly do that. And list index out of range."
808620,815580," Why would it be out of range? This is kind of strange. Don't they start from zero?"
815580,824940," Don't they start from zero? Wait a second. So if I go and do okay, so the first one is push int. And"
824940,832380," it's it's be serious. It's it starts from one. Jesus Christ. Okay. So"
835100,842540," OP type. So what I have to do in here, I suppose I will have to do minus one here and in here. All"
842540,849820," right. I wonder if we can specify the the starting value somehow. Anyway, so here we can see that for"
849820,858380," such a simple program, the hottest instruction was intrinsic. But to be fair, intrinsic, like it's not"
858380,865500," very useful operation. And also I did a fucky wacky, I suppose, and a little bit of oopsie doopsie."
865500,871100," I keep forgetting that you have to do formatting like this, right? There we go. So this is what I"
871100,877500," expected in here. Intrinsic is not very useful because there is a shit ton of intrinsics, which act"
877500,885660," like their own separate operations. So in fact, we have 29 intrinsics. So which one of those intrinsics was"
886220,893740," exactly like specifically slow, right? We don't really know. So which one of 29th? So I think we"
893740,901900," need to have like a separate table for intrinsics as well. So int inter stats, right? So this is going to"
901900,909980," be this int length for intrinsic intrinsic is also enumeration. And since it's enumeration, I suppose we'll"
909980,918780," have to do int enum for this thing as well. All right, so this is where we handle intrinsics, right?"
918780,926940," So this is how many of them we have. So it's actually quite a lot of intrinsics, not gonna lie."
926940,933260," Some of them not even implemented properly. But primarily the syscalls, right? Because to implement the"
933260,937500," syscalls, you have to simulate Linux or any other operating system you're simulating."
937500,945660," And so inter stats. So in the type of the intrinsic is located in the operation operand, right? And we"
945660,951740," have to do minus one and we have to bump this entire thing. So what I'm thinking is that after we printed"
951740,962540," this thing, we want to check if the OP type is OP type intrinsic, right? Intrinsic. And if it is intrinsic,"
962540,968540," let's actually do like a similar dump of the table, but with a little bit of an intention for the intrinsic"
968540,976220," cell. So you will see that operation intrinsic took like was this amount of times, but specifically for"
976220,985980," each individual intrinsic, there will be a separate counter. So enter type in intrinsic, right? And here we're"
985980,997260," going to have space, space, space, space, space, s, d, OP type, not a p type, but enter type,"
997260,1006140," enter stats, enter type minus one. All right, so let's see if it will give us more information in"
1006140,1012460," here. And it does, in fact, give us more information. So now we can see that the hottest intrinsic is print."
1012460,1019020," So we're primarily printing something. We're not doing much. We're not doing any arithmetic operations"
1019020,1022860," at all. We're primarily printing things. For different kinds of programs, we're going to have"
1022860,1026940," different things, I suppose. For arithmetics, it's going to be primarily arithmetics, I would"
1026940,1032300," presume. All right, so how many arithmetic operations we have in here? Not that many, actually."
1032300,1037580," So well, in arithmetics test, we just test each individual arithmetic operation. So there's nothing"
1037580,1044300," special in here. We can take a look at more sophisticated programs like examples rule 110."
1044300,1048540," All right, so this is the most sophisticated program. So you see how slow it is in the simulation"
1048540,1056700," mode. This is unbearably slow. Holy shit, that's a lot of operations. So I suppose the hottest one"
1056700,1066140," is memory. All right, so not even memory plus actually 77,000. Right, so the plus was the hottest"
1066140,1072060," one. But here's this interesting thing. So the amount of times a particular operation or intrinsic"
1072060,1079660," executed is not very useful because it may be executed a lot of times, but it could be super fast. On the other"
1079660,1087420," hand, we can have a very slow operation that is executed a few times, but the accumulated time it"
1087420,1093980," took was longer. Right, so maybe we also have to measure how much time it took to compute all of"
1093980,1100140," these instructions. And that will give us more information about what's going on under the hood."
1101420,1108300," So we need a way to time the execution of the programs, right? So we need a way to say,"
1108300,1113820," okay, so let's take the time step starting from here. And after we finish the execution operation,"
1113820,1118460," we want to take another timestamp, find the difference, find elapsed time and add that to"
1118460,1123980," the statistics as well. And then I'll put it in the in the final table, I think it's going to be a rather"
1123980,1131900," useful. And I think it's going to be rather useful. So Python time execution, is there any convenient"
1131900,1136220," way to do that in Python? How do I get time of Python program execution? Okay, it's talking to"
1136220,1145980," full circle for please enlighters. Okay, so we can just use time. And okay, so that gives a but what's"
1145980,1152060," the resolution, right? So is the resolution in seconds, I want to have a resolution in microseconds,"
1152060,1156780," and preferably even nanoseconds, because some operations can be very, very fast, but accumulated"
1156780,1161500," result is going to be very slow, because there's a lot of such operations, right? So I want to have a"
1161500,1168700," pretty fine resolution. Okay, so we're going to have a time and all right, so it's a float,"
1168700,1174380," if I understand correctly. So is there doubles and floats in Python? I don't know, maybe there's only"
1174380,1181980," floats. Okay, and it goes down to microseconds and a little bit down to nanoseconds. But"
1181980,1186460," it could be like just like an error or something. So we can assume that we have a resolution of"
1186460,1195820," microseconds, which is not that bad. I think we can work with that. All right. So let's import this"
1195820,1201900," into that, I think. So this is going to be time. Simulation of our nation. So where are we going to"
1201900,1207820," keep all of that stuff? Where are we going to keep all of that stuff? I think I would like to keep it in"
1207820,1216140," here, like so. But I think the tuples are immutable. In here, I think the tuples are straight up immutable."
1216140,1220380," So I think it's going to be kind of a pain in the ass to work with. So if I have something like"
1220380,1226380," like this, I won't be able to do things like yeah, the tuples are immutable. You cannot just do that."
1228220,1236220," So maybe we could maybe we could have a separate tables. So okay, let's actually rename"
1236220,1247100," OP stats, maybe even stats to count. Right, so this is the count num now. And we're going to have a"
1247100,1252700," separately OP time, which is going to be a list of floats. All right. And here we're going to have something"
1252700,1263180," like lan OP type. And similarly, we're going to have intrinsic time, which is a list of floats, zero"
1263180,1270300," lan intrinsics. Right, so we're going to collect information about all of that. All right, so we're"
1270300,1277180," going to start the measurement from here. So this is going to be time, time. And when it's about to do"
1277180,1290860," inter count, right, so we're going to do inter time operation like this. Start minus time time, there we"
1290860,1298860," go. And when it's time to measure the whole operation, we're going to do something like OP time OP type minus"
1298860,1307980," one plus start minus one plus start minus time time. There we go. So now we can do something like this."
1307980,1314460," So times, and maybe in the parentheses, we're going to do something like F sex. That's right."
1314460,1326380," A very funny word. So OP time OP type minus one. So this is the time for this thing. And the"
1327180,1339740," timing for the intrinsics. So enter, enter time, enter type. Can I actually just keep it somewhere"
1339740,1347900," up there? Because yeah, import type minus one is it working? All right, so let's see what's going to"
1347900,1353020," happen. So far, so good. So it doesn't crash anything. So maybe we're going to have some interesting timing"
1353020,1359980," information. So it's negative, because you're supposed to subtract the end from the start,"
1359980,1367660," not the other way around. Oh my God. That's why I'm unemployed. That's literally why I'm employed."
1367660,1371980," And that's why I'm streaming on Twitch. I'm not even streaming on Twitch anymore."
1372540,1379900," All right. So what do we have in here? So what's the hottest operation in your area? So the hottest"
1379900,1388620," one is intrinsic. And we spent three seconds, 3.5 seconds just executing intrinsics and nothing else."
1388620,1395580," And the whole execution was like five seconds. And within these five seconds, we primarily did plus."
1395580,1403260," Plus took half of a second. And swap. Swap was actually kind of slow. Also half of a second."
1403260,1411180," So yeah, apparently swapping things is actually kind of kind of slow. Interesting. So I think we have"
1411180,1418860," all of the necessary information, right? And I think we can try to run this profiler, whatever the"
1418860,1427900," fuck it is, on the problem 04, on the problem that takes eight minutes to compute, when if you compile"
1427900,1434300," it to assembly, it takes 200 milliseconds, right? So and maybe after that, we'll get some insights on"
1434300,1439580," what the hell is going on in there? And what's the slow separation? And can we improve anything at all?"
1440300,1446940," All right, so let's go ahead and do that. I'm going to try to simulate the Euler problem 04. Right. And"
1446940,1452620," let's just cut into the final result, because I'm pretty sure it's going to be even slower. Because"
1452620,1458300," on top of just simulating and running OPS, we're also profiling, we're also collecting information."
1458300,1465820," So it's probably going to be like 10 minutes, I don't know, we'll see. So well, it took 11 minutes."
1466460,1470620," So let's take a look at the data. So yeah, we can already see that do"
1470620,1478060," holy shit, that's a lot of like, it's a 6 million times for 15 seconds, like the modern computer can"
1478060,1486780," do so much, like within 15 seconds, way more than 6 million operations. Come on. So okay, so we can"
1486780,1495660," already see pretty hot things in here, like 105 swap, drop and over. Huh, this is very interesting. Okay,"
1495660,1501100," let me actually save this information, because this is a very important and very well available"
1501100,1506460," information. And I don't want to wait another 11 minutes just to gather that. So we're going to do"
1506460,1512540," something like problem 04 prof, right? So this is where we're going to save all of that. And I want to"
1512540,1522380," actually align everything a little bit so I can read it. Okay, so none of that was actually executed. So 1315"
1522380,1528300," milliseconds are not that interesting. So these are the most interesting operations like swap, drop and"
1528300,1536860," over. Like, yeah, I wouldn't expect this thing to be so slow. To be fair, what I expected to be slow in"
1536860,1544700," in this particular situation is a memory access things like load in store, because we are if you take a look at"
1544700,1557180," the problem itself, right? So problem 04, we are using load 64 and store 64. So we're loading and storing 64"
1557180,1563980," bit numbers in and from the memory. And here's an interesting thing, our language does not support that."
1564540,1571420," It only supports loading and storing one bytes. And well, we do plan to actually implement that properly."
1571420,1578860," But what I did as a like half of a joke is I implemented load in store 64 byte by byte, right?"
1578860,1585180," So essentially, if you want to load 64, we're just iterate eight times. And we just like, you know,"
1585180,1591420," build a 64 bit number out of bytes. And we do the same for the store, right? I just want you to see"
1591420,1598620," how slow is it going to be. And I expected low key that this was the bottleneck of the execution. And"
1598620,1604620," I was hoping that like, I'm going to just like make these things intrinsic, and I'm going to gain a huge"
1604620,1613900," speed up. But in reality, the memory access, the memory access is like less than a second. Like, yeah,"
1613900,1620780," so the the program was actually waiting primarily on swapping, dropping and doing over basically the stack"
1620780,1629100," operations, something that should be insanely fast. So I'm actually, yeah, this is really weird."
1629100,1635340," Like, and essentially, what swap, drop and over means is that swap swaps elements on the stack,"
1635340,1641340," drop removes the element from the stack and over copies the element below the top, right,"
1641340,1646780," it's just like a stack operations. And what do we do? What do we use for the stack is actually just"
1646780,1653820," list list, like I would expect lists, the the most common data structure in Python to be very fast,"
1653820,1659020," right, it should be the most optimized, optimized data structure. But why is it so slow? Right,"
1659020,1667340," so stack is the is the least. All right. So it's kind of sus. No, I'm gonna lie. Let me actually do"
1667340,1676620," something. Let's create a file something like stack stress. Let's actually stress test the stack."
1676620,1685180," Right, so I'm going to do user bin environment, Python three, and let's just create a stack,"
1685180,1693420," nothing special. So like this. And how many times this instruction is executed? So swap is executed. I want to"
1693420,1702780," three more to 15 million times. Okay, so let's do the following thing. For I in the range, 15 million,"
1702780,1709980," right, like so 15 million. And what we're going to do within this loop is just basically push 69 and pop."
1709980,1717820," There we go. So and also maybe we are going to time this entire thing. So let's do something like start"
1718380,1727100," time, time, time. And in here, we're going to print f six. Haha, time, time minus start. There we go."
1727100,1733820," So and let's just go ahead and execute the this entire thing. So let's see how like a pure pushing"
1733820,1740700," and popping on and from the stack is going to perform. So 15 million times is actually shouldn't be that"
1741260,1747100," many, you know, many, you know, operations. So it should be relatively fast in any say saying language,"
1747100,1753660," this should be like below one second, it must be below one second. And let's see. So,"
1753660,1760860," so we can put out it's a pen. I keep forgetting that it's a pen. In fact, are you serious?"
1763020,1771660," I really, five, wait a freaking second, just such a simple thing that has to be optimized because it's"
1771660,1781580," so common. Is that slow? I can't even properly, you know, print this entire thing. I'm so in shock"
1781580,1791980," that I forgot how to use Python. It shouldn't be that slow. Seriously? 15 million times pushing and"
1791980,1800700," popping on the stack is 6.5 seconds. Really? So just to just to show you why I'm in such a shock,"
1800700,1806700," let's take a look at C++ or okay. So I know that comparing C++ and Python is kind of like unfair"
1806700,1810140," game, but I'm going to disable all of the optimizations, right? So I'm going to tell the"
1810140,1817020," competitor it generate the most dumb assembly that you can generate, right? And let's write a similar"
1817020,1825740," program in C++, right? So we're going to use a vector, right? So we're going to allocate the vector"
1825740,1833020," on the stack. So this is going to be our stack. So what I'm going to do in here, I'm going to just do"
1833020,1839740," 15 million times. Does 15 million even fit into the integer? I think it does. I think there should be"
1839740,1848460," be fine. Right. So this is 15 million, right? So that I think in C++, oh, my C++ mode cannot support"
1848460,1854220," that. So I have to use a proper C++ mode, unfortunately, but it's extremely slow in my Emacs."
1854940,1863900," Anyway, so and in here, I'm going to do stack, push back, right? So I'm going to do 69 and then stack."
1863900,1870060," What the fuck was that? I think it was trying to out complete something, but then it just like turned"
1870060,1876060," into a horrible mess. Okay, so let's try to compile this entire thing. And I'm going to tell the compiler,"
1876060,1883660," oh, zero, you see, I'm disabling all of the possible optimizations, right? So it's not going to like do"
1883660,1889340," any trickery. It will generate like very dumb assembly, right? And we're going to do something"
1889340,1895820," like main, main CPP, right? And let's just try to compile this entire thing and see how much time"
1895820,1904220," it will take to push and pop from the stack using C++. It was less than a second. Less than a second"
1904220,1915820," with all the optimizations turned on. Really? It's like magnitude faster, magnitude faster. And I'm"
1915820,1921980," really not sure what Python is doing. So if we take a look with optimizations, right? If we crank up"
1921980,1926300," optimizations, I think it could be even faster. I think it would be even illuminated. I'm pretty sure"
1926300,1930940," the compiler just saw that I'm not even using the result for anything. And it's just like straight up,"
1930940,1936940," like stripped it off. But yeah, without optimizations, it has no rights to actually"
1936940,1942140," strip it off. So it was like less than a second, right? It's just like almost a second, but it's not"
1942140,1950140," six seconds. Come on. You can do so much within six seconds. It's insane. So I don't know. I don't"
1950140,1956940," like the conclusion to which we're coming so far. And the conclusion which we're coming so far is that"
1956940,1963260," it's the problem with the language, right? And it's just like, how can you optimize that?"
1963260,1971100," Right. So if we take a look, so this is the most basic operation and there's nothing to optimize in"
1971100,1982300," here. You're just pushing and popping. So I don't really like this conclusion. Though there's one thing,"
1982300,1992780," one last thing we can try to do. We can't fix the language, but we can try to change the implementation,"
1992780,1998380," if you know what I'm talking about. So here we get heard about PyPy. This is actually a very interesting"
1998380,2007180," thing. PyPy. Well, it's kind of advertised to be a Python implemented in Python. But it's not necessarily"
2007180,2014620," true Python. PyPy is implemented not in Python, but in something called RPython, which is a restricted"
2014620,2023500," subset of Python. It's so restricted that it's translatable to C, right? And that's why it's"
2023500,2029900," faster than the CPython implementation, because essentially it's implemented in C, but in the"
2029900,2035740," restricted Python that is translated to C. I looked briefly into this entire thing, so I might be wrong."
2035740,2045020," But it's claimed to be faster than Python and also it has a JIT compilation. And even Guidovan Rossum said"
2045020,2051180," that if you want your code to run faster, you should probably just use PyPy, right? So he said it"
2051180,2060860," himself, creator of Python. Excuse me. And maybe that's what we should try to do. So maybe we should just"
2060860,2067660," see if using PyPy instead of C Python would make it faster. So let's actually go ahead and download. So"
2067660,2074220," maybe we're going to take the third one. I can't right click because my Chromium is dumb. So I have to"
2074220,2080540," fix it yet again. Just a second. I'm sorry. All right. So I'm going to copy link address and I'm going to"
2080540,2088780," download this thing right inside of my port. And it's going to take some time apparently. Maybe I have a slow"
2088780,2098060," internet. Maybe the internet on the server is rather slow. Well, the last time I used PyPy, it was rather"
2098060,2107500," fast. So I don't know if it's still as fast as it used to be. We're about to find out. About to find out."
2107500,2115820," Okay. So let's unpack this thing. So it's just like a regular package. It has a bin folder. I can already"
2115820,2129020," see that. And yes, yes, yes, yes. Okay, cool. Looks good to me. So if I try to run this entire thing,"
2129020,2139580," so this is going to be PyPy. I cannot see shit in this mist. Bin PyPy. All right. So it even has like the,"
2139820,2149420," you know, the shell of Python. So everything looks okay so far. Now, what if we run the"
2149420,2162860," stack stress, stack stress using this thing? Well, it's actually faster than C++ without optimizations."
2162860,2167500," I'm not even fucking joking. C++ without optimizations."
2169420,2183260," Wait, what? Really? So what if we try to use PyPy for the porth? Can we do that?"
2183260,2193500," So PyPy bin PyPy. And I'm going to do porth. And let's actually try to run something that is not very"
2193500,2199340," heavy, but reasonably heavy. Rule 110. And let's see how much time it will take. So I didn't do"
2199340,2208140," that correctly. I should have put a simulation mode in here. It feels faster. It actually,"
2208140,2213820," so the startup is very slow. I presume this is because it maybe compiles something up front."
2213820,2221820," It's kind of similar to JVM to be fair, because JVM also has a very slow startup. But once it warms"
2221820,2229020," up, it can actually JIT compile like hotspots and it runs very, very fast. So maybe the same thing goes for"
2229020,2236140," PyPy. So the startup time of CPython seems to be really fast, but it runs slow, right? It's already"
2236140,2241820," started, but it, you know, you see it runs very slow. But for PyPy, it takes a little bit of time to"
2241820,2248780," start up, but then it actually goes very fast. So if we take a look at the timing, so yeah, it's one"
2248780,2254300," second. So it's actually more reasonable. Yeah. So and it doesn't complain. So it's completely"
2254300,2259100," compatible with our source code. It didn't support the typing. I was, I was actually afraid to use"
2259100,2264780," PyPy for ports because I was thinking maybe it doesn't support the typing and stuff like that."
2264780,2270700," Right. So where's the typing? It's all because we're using like optional typing to check things around."
2271420,2281100," So, okay, let's go ahead and try to use that thing for the Euler, right? Euler problem zero four. Is"
2281100,2286380," it going to be even like reasonably, is it going to be like one minute or how much time it will take?"
2286940,2293100," So it's already taken. Okay. So, I don't know. Maybe we'll have to cut the entire thing,"
2293100,2299260," but maybe we can wait a little bit because it actually speeds up dramatically. Also, maybe we should"
2299260,2304220," should be, we should probably disable the, you know, profiling and stuff like that."
2304220,2310140," Okay. Let's actually cut and wait until it actually finishes this entire thing."
2311660,2316860," All right. That was actually faster than expected 30 seconds, uh, 30, 36 seconds. It's actually,"
2316860,2324300," well, it's way better than 10 minutes. Uh, yeah, it's 20 times better than 10 minutes."
2324300,2331100," Yeah. It's, it's not bad. Um, so what if I disable the, uh, profiling and stuff like that?"
2331100,2336620," Let's actually try to remove the profiling, uh, simulate, and it's also going to be probably faster"
2336620,2344540," without the OPS. Uh, so let me straight up remove the profiling. Right. So, and to check things around,"
2344540,2349660," I'm going to use my pie because it will tell me what other things I have to remove from here. Uh,"
2349660,2359740," so porth, uh, to, to, to, to, uh, well, that's, that's rather slow maybe. Okay. Uh, so we need to remove"
2359740,2367340," that, uh, another one, um, okay. Count and also maybe I should have just commented that. Okay. So"
2367340,2373900," let's not remove this entire stuff because I think it might be actually useful in the future. So I have"
2373900,2379820," a tendency to implement useful stuff and then remove it and then regret it removing it. So let's actually"
2379820,2388060," get out of that habit. Uh, right. So I didn't think it's a very healthy habit. Uh, all right. So I"
2388060,2393420," disabled the, uh, profiling and let's see if it's going to speed up the entire thing. Um,"
2393420,2400940," so let's just wait a little bit. So it should be like half of a minute. So maybe I'm not going to even"
2400940,2411500," cut it. Um, because if it's less than minute, the simulation actually becomes feasible and maybe this"
2411500,2419100," is something, uh, 20 seconds. This is something that we can already kind of run on CI, which is not that"
2419100,2432220," bad. So maybe I should completely switch to PyPy. Because why not? So yeah, so it's pretty good."
2432220,2439020," So why do, why do we need CPython? Why people still use CPython? PyPy is actually way better. Uh, right."
2439020,2449500," So, and sometimes it's even faster than C++. So, all right. I guess from now on, I'm going to switch"
2449500,2454860," all of my development to PyPy. PyPy is actually a very interesting thing. It's highly compatible with,"
2454860,2463740," uh, with CPython. So it's even runs like a popular, um, libraries like Django, uh, and stuff like that."
2463740,2468700," So yeah, if you never heard about this thing, uh, give it a try. Apparently it's actually a pretty cool thing."
2469500,2475580," So maybe that's the future of Python. Maybe that's what everyone should use instead of CPython implementation."
2475580,2485660," You know, it's pretty cool. So I wonder like also it supports typing. Can it actually gather a useful"
2485660,2491980," information out of the typings and just like, yeah, maybe with the help of PyPy in the future,"
2491980,2498300," Python will become like a proper statically typed compiled language, uh, finally. Um, yeah, I don't know."
2499020,2504220," In any case, uh, from now on, I'm going to actually migrate all of my development environment in infrastructure to PyPy."
2504220,2510540," And, uh, we're probably going to run this entire thing on the CI in PyPy. Not, not like it matters,"
2510540,2517580," because we're going to rewrite the whole thing in port, uh, in the future anyway, but, uh, a little bit of a boost up in"
2517580,2523580," execution is going to help us to get that faster. And now I don't even, uh, have to remove the simulation"
2523580,2529340," mode anymore. Right. Because with PyPy, it's kind of feasible. It's still kind of sucks with 20 seconds,"
2529340,2535340," but it's not 10 minutes. And, uh, without OBS, it's probably going to run even faster. And on, uh,"
2535340,2540860," the Microsoft CI, it's probably even faster than that because their, uh, virtual services are faster than"
2540860,2547740," my laptop. So, yeah. Uh, so I hope today's session was interesting for you. It was definitely interesting"
2547740,2554220," for me. So I gained a couple of interesting insights. So thanks everyone for watching, uh,"
2554220,2560060," check stuff in the description. Uh, right. I put some links in here. I think I'm going to put the link"
2560060,2568860," to PyPy, uh, to the description as well. Uh, right. There we go. And, uh, I think I'm going to go,"
2568860,2574380," right. I think I'm going to go. Thanks everyone for watching. Uh, love you."
