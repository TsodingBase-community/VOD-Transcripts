start,end,text
80,5200," looks like we're live hello everyone and welcome to yet another azuzin session"
5200,10480," azuzin session let's make a little bit of an announcement and officially start the stream"
10480,17680," so uh what are we doing today on a twitch dot television website it's a rather interesting"
17680,29200," question uh red circle live on twitch and today we are developing a simple c slash c plus plus"
29200,34720," alexa to syntax why does it say two it's supposed to be for syntax highlighting"
34720,42400," uh okay so let me quickly fix all that shite i don't speak english anyway english is my like 69th"
42400,47920," language so i don't really speak it well so yeah i'm gonna give the link to uh the place where we're"
47920,54480," doing all that witch.tv/zozin and i'm gonna ping everyone who's interested in being pinged there we"
54480,60960," go the stream has been officially started so today we continue developing uh dead which is"
60960,65840," a dramatic text editor that we started to develop some time ago you can find in here i copy pasted the"
65840,71360," link in the chat or for people who happen to watch this shed on youtube for whatever reason it is going"
71360,80960," to be available in the description so uh let's take a look at this uh thing uh dead i said dead let's take"
80960,88000," a look at the status status is clean let's fetch some uh latest changes i wonder if i did anything off"
88000,94000," screen i think i did something off screen uh for this text editor actually didn't okay so that's that's fine"
94000,100240," so i was slacking uh mother flipping slacking all right so this is the text editor this is how it"
100240,106560," looks like and uh the point of the editor is that it's very dramatic as you start typing things you"
106560,111360," know the camera action kicks in and it just like follows your cursor and it's just like holy"
111360,117840," fucking uh right so recently we started to support a selection which doesn't really do anything except"
117840,122880," uh selecting the text you can't select the text and copy paste it yet but we have a mechanism for"
122880,128080," selection and one of the important thing that we did on the previous stream on the the very previous"
128080,134960," stream is that we tried to implement the syntax highlighting so you can do shed like int and it"
134960,144400," highlighted it int main uh all right and then you can maybe write a for loop right you can iterate"
144400,152240," something with a for loop if you want to uh right let's let's put it this way right so this is going"
152240,157680," going to be another one and so on and so forth and as far as i know we actually like had coded like all"
157680,165200," of the c slash c plus plus keywords so i'm pretty sure it can recognize things like uh templates right"
165200,170160," so can i put template in here yeah it does recognize it but there is a little bit of a problem uh and the"
170160,175040," problem is the way we actually handle all of that we handle all of that in a very dumb way"
175600,181920," uh right we we look for substrings of keywords meaning that if i have something like forward"
181920,189520," four is going to be highlighted as well right so uh the problem here is that the text editor does not"
189520,196960," tokenize the keywords uh properly right and uh the topic of the stream is going to be actually implementing"
196960,204560," a small subset of the c tokenizer right of a c tokenizer so we can highlight uh things properly"
204560,210640," right and since we're going to be able to actually classify different tokens differently maybe we will"
210640,217680," be able to even highlight them differently uh so yeah that's going to be very interesting um so yeah"
217680,222720," that's the topic for the stream so we're going to implement like a simple c tokenizer which goes"
222720,228880," through the entire text and groups the sequences of characters according to their class according to"
228880,235840," their like token kind and then i suppose we can pass that information to the renderer and the renderer is"
235840,241200," going to look at those tokens and depending on the kind of the token it is going to just color them"
241200,246720," differently right or maybe it's going to even apply some special shaders right so we have the cool thing"
246720,252240," about the renderer for this text editor is that the renderer can do shit like that uh right so"
252240,258160," you can apply shaders on the on the text that you're rendering so maybe the renderer is going to look"
258160,265840," at the kind of the token and it's going to uh render tokens with the rainbowish color like for"
265840,270080," example for types or something like that or maybe it's going to be custom thing maybe you'll be able"
270080,277920," to customize what kind of shaders to use for certain keywords right uh so that sounds actually kind of"
277920,285840," cool right imagine like uh defining like a text editor theme not in terms of like the token color but token"
285840,294160," shader i think that's kind of cool i think that's kind of cool uh so yes yes yes so that's going to be"
294160,303280," basically the idea so we could have just tried to use existing c tokenizer right but uh before using an"
303280,311120," existing c tokenizer we have to ask ourselves a question we just want to highlight some in a text"
311120,320960," editor in a shady toy text editor do we need an entire standard compliant tokenizer to just highlight some"
320960,329120," shit you know the military grade standard compliant tokenizer just to highlight some"
329120,337040," it's like we probably don't it's like imagine like trying to implement like a pixelated flappy"
337040,346480," bird without any effects or anything like that and using unreal engine just like yeah i guess you can go ahead"
350960,357040," what can i say what the fuck is a military great game dev engine it's just like what the fuck is that"
357040,364320," but yeah you can try to use that but i mean you probably don't need even 99.9999 percent of the"
364320,372800," shed that is in unreal engine just to to do that so yeah you just probably don't need to do that and my"
372800,380320," point is we're gonna implement like our own tokenizer uh our own tokenizer which is like a small subset of"
380320,387200," standard compliant tokenizer uh that is sufficient enough to just highlight some things in a toy text"
387200,394800," right so and the cool thing about implementing your own tokenizer is that um it's completely customizable"
394800,403360," meaning that you can couple it more with your renderer right imagine that you're using an existing tokenizer"
403360,411520," from for example from stb uh right so there are already um readily available uh tokenizers for c um"
411520,417600," like and for instance uh from from stb libraries that you can just use uh but one of the things"
417600,424480," one of the advantages that we're going to have will be able to maybe store in the tokens some additional"
424480,430320," information for the renderer for instance i have the following idea what if we take the text and pass it"
430320,435040," through the tokenizer and tokenizer gives us the sequence of tokens but on top of the sequence of"
435040,444000," tokens the token each token contains its kind and its text on top of that the tokenizer can also decide"
444000,449280," where physically in a two-dimensional in a continuous two-dimensional space that token goes"
449280,454400," right because it kind of knows where it goes it knows the it may know the dimension"
454480,460320," of the phone and stuff like that but while tokenizer tokenizing it can actually compute the layout"
460320,466880," where it's going to be located so the each token also contains x and y in floats x and y in floats where"
466880,472960," the token goes and then the renderer just takes the stream of these tokens it already has the text it"
472960,478000," already has the positions and what it does it just renders them just like it just says okay so here's the"
478000,483520," tokens just place that token in that specific position that the tokenizer told me with that specific color"
483520,491680," so it's actually super easy because we control everything right so we can tie the different"
491680,498720," components of the system a little bit better uh to make our lives a little bit easier so that's basically"
498720,505520," another reason to implement our own shit anyway so we got a couple of subscriptions while i was uh"
505520,514480," talking nonsense um thank you so much mxvism for uh nine months of twitch prime subscription with"
514480,524320," the message c plus plus in the title progress yeah uh so just just by supporting c plus plus keywords i have"
524320,530640," an opportunity to put c plus plus in a title and then debate all of the people who will come to my stream"
530640,535920," see the c code and tell me that this is not c plus plus even though i was not saying that i was"
535920,540720," programming in c plus plus but on the internet people don't have a reading comprehension enough to"
540720,546960," understand that anyway so and another subscription from element uh zero to 16 thank you so much for"
547680,555280," 12 months a year of tier one subscription with the message uh underkill is better than overkill right"
555280,563280," so it's like it was spelled in a programmish kind of way with greater underkill maybe it depends on how"
563280,569120," much you under killed and how much you over killed all right so with the ready solutions"
570080,578880," right if you are under killed and implemented your own solution it is quite easy to just add a little"
578880,584000," bit more to make it less of an under kill if you under kill too much it's kind of difficult to do that"
584000,590400," but if you under kill but a little bit it's super easy to just add more but if you used a ready solution"
590400,595440," and you over killed a little bit more how easy it is to get rid of that overkill"
596800,601040," well you have a library which is a black box you can't really change it unless you"
601040,606480," just make a copy of that library but uh then you will have to port all of your changes to next release"
606480,611040," of the library i don't know it's it's kind of difficult it all depends on the specific situations"
611040,616240," people want like a universal solution that works everywhere so they never have to think and just"
616240,620480," follow the dogmas it doesn't work like that i'm sorry you have to take a look at the project and see"
620480,625520," does it work for that specific project i'm sorry you have to use your brain sorry to tell you that"
625520,633280," people but you have to analyze each situation uh differently i know it's it's boring i know it's"
633280,638480," difficult i know it's easy to follow some paradigm but it is what it is and it isn't what it isn't"
645200,655600," surely you can just solve a problem once surely kappa uh all right anyway so uh let's go and try to"
655600,661840," implement the goddamn tokenizer uh i have no idea how to implement the c tokenizer i never implemented"
661840,668000," the c tokenizer in my entire life uh so i'm gonna be trying to implement a c tokenizer for the first time"
668000,675040," in my life right on the stream right so but here's the thing i implemented like a lot of different"
675040,684400," tokenizers before so i kind of know the drill so yeah we'll see how it goes um so uh let me let me see"
684400,692800," interestingly interestingly um so what we're gonna start with i suppose we're gonna start with maybe"
693440,699600," uh lexa let's just call it lexa dot h i'm not gonna say that it's a it's some sort of specific lexa"
699600,705200," it's gonna be maybe abstract lexa uh that is going to work only with c but maybe later we're gonna"
705200,711840," abstract it out and it's gonna be a general lexa uh that can be used for like any language because"
711840,714880," the editor probably gonna support like several languages or something like that"
716320,725360," uh okay so if not defined lexa dot h we're gonna define that god then lexa dot h and then and if"
725360,731840," this is going to be a comment so uh let's define different kinds of the token so this is going to be"
731840,738720," a token kind what kind of coins do we want to have in here i suppose my favorite um token kind is more"
738720,747440," of a like token ant right so this is essentially the token that is uh returned at the end of the stream"
747440,753600," right so you consumed all the tokens and the last token that the lexa keeps um returning to you is the ant"
753600,758560," right so it's quite convenient to have such token so another token that we're gonna have let's take a"
758560,766880," look at this c code right so the first c code that we usually have is um it's usually some pre-processer"
766880,775120," right it is usually some preprocessor and i'm thinking um right in a preprocessor do we tokenize"
775120,782400," the preprocessor i think we should try to tokenize the preprocessor uh all right so maybe we're gonna"
782400,790160," have a token um token pound right so what is the name for for this sign i think it's a pound or something"
790160,796640," right so it's a hash pound or whatever um right and another common uh symbol that we can have in"
796640,803520," here is a some sort of a symbol some sort of a name uh right so let's actually call it token symbol"
803520,810640," right and let's just start with these kind of tokens and then we'll be able to extend with uh with more"
810640,819200," uh hashtag i think it's like i feel like it depends on english right so in american english it's i think it's"
819200,826160," pound in in which english it is pound and in which one is it hash like i don't remember like i don't speak"
826160,834960," english at all um so i suppose i i heard casey calling it pound but casey is american he speaks"
834960,841760," he speaks americanese so in americanese as far as you know it should be and then pound right it depends on"
841760,842800," the context okay i see"
848720,855680," at least here in texas you can call a pound or a hash oh okay so just like yeah in different parts in"
855680,857200," america you can also go different one"
857200,868320," okay so i'm gonna call it hash because i'm an internet person and everyone on the internet calls"
868320,875280," it hash because of twitter because twitter is cool am i right kids twitter is cool it's hip and cool"
875280,880080," okay so we're gonna have uh the token right"
880080,886240," we're gonna have a token and uh we're gonna also have a token kind"
886240,892240," so but on top of that we also need to have the text the text of the token right so we're gonna"
892880,898960," basically store the text of the token in a sized string because usually you have the content which"
898960,905200," is the entire string and token is a sub string and token like i like to program the tokenizer so the"
905200,910720," tokens don't own the text and they are just like having references and because of that it is easier to"
910720,917040," store them in a size text uh right so then on top of that we're gonna have a um text len as you can see"
917040,922960," it already auto completes it suggests me to call it a certain way that i would like to call it's almost"
922960,929520," like gpt it's yeah it's almost like a gpt model of some sort like a cockpilot or whatever it's called"
929520,936640," these days i don't know but what it does it basically auto completes the existing tokens in all the open"
936640,942480," buffers so yeah anyway and it's almost like cockpilot"
944880,954160," now uh what else do we have i think usually that is it for me but since we're preparing the"
954160,960320," tokens for the renderer i might as well also provide something like a position uh right position on the"
960320,967440," screen um also yeah i forgot a very important thing um i also have some sort of um a thing called location"
967440,973520," right which denotes where exactly it is located within the text usually it is needed for reporting"
973520,980000," purposes right for some sort of reporting purposes where you specify the file path uh where it is"
980000,986800," located all right and then row row and the column but here is an interesting thing"
986800,993520," i don't think for syntax highlighting i need any of this information actually"
995120,1002240," uh right so i'm not going to report anything like why do i need to know the row i kind of need to know"
1002240,1008640," row and column so i can render it properly but then i can like straight up specify the position on the"
1008640,1017040," screen so this is not needed at least right now i don't see any use for that but if i will have some use"
1017040,1021920," for that for that specific tokenizer i may edit but right now it feels like if i just preparing"
1021920,1027600," the tokens for rendering i kind of don't need this usual information that i put in the tokens when"
1027600,1034160," i'm developing for instance interpreters or compilers so i'm doing that purely because i have a reflex right"
1034160,1039520," so i developed interpreters and compilers and parsers and usually i need to report errors"
1039520,1044560," here i didn't think yeah here's an interesting thing if i have some sort of like a tokenization error"
1044560,1050480," i probably not gonna even stop tokenizing i probably gonna just like skip an invalid token and continue"
1050480,1056240," tokenizing right because i i don't want to break the highlighting or something it's actually kind of cool"
1056240,1064400," so tokenizing for syntax highlighting is kind of different than tokenizing for parsing right so for"
1064400,1070320," different purposes purposes you can just actually tokenize things differently that's so cool and"
1070320,1076080," that's another reason why to write your own tokenizer for syntax highlighting because who knows for what"
1076080,1080960," kind of purpose this tokenizer was implemented for i'm pretty sure this tokenizer was implemented for"
1080960,1088640," um code generation for analyzing c code and some code generation it may work for your case but there's"
1088640,1093680," always going to be a little bit of a like a misfit right every time you take a component and it doesn't"
1093680,1100720," fit quite well to you uh to your purpose you pay a little bit of a cost right because you always have"
1100720,1108640," to adjust uh maybe break some parts around just to feed that component in there right so always like pay"
1108640,1114240," a small cost you may say that it's a very small cost but it accumulates over time and nobody thinks about"
1114240,1120800," that actually nobody really thinks about that until it's too late until it's too late and it's impossible"
1120800,1124560," to rewrite your project from scratch you know what i'm talking about you know what i'm talking about"
1124560,1130960," anyway i'm sorry i'm talking too much uh today uh okay so this is what we're going to have in here so"
1130960,1138080," just the token the kind the text the position and stuff like that right so and uh usually i have the"
1138080,1146080," structure that keeps track of the current uh lexus state right so usually we have something like the"
1146080,1150720," content so it points at the beginning of the content of the entire thing that we're trying to parse"
1150720,1159600," uh then uh how much of the text right so basically how much of the content we have but i already call"
1159600,1165520," this thing lens so maybe i'm going to call it a content level all right and usually in c specifically i"
1165520,1172720," like to keep track of the cursor right so where it is located right now right so the position of the thing"
1172720,1180880," um maybe we also need to keep track of the current line right so where where on the line are we located"
1180880,1188000," right because it's since the lexa is also going to define the position where um the token is going to go on"
1188000,1192560," the screen it kind of needs to know on which line we're located so it can calculate the location"
1192560,1201040," properly uh right so cursor is actually absolute position it is absolute position line is just the"
1201040,1207760," the line all right we don't keep track of the role instead of keeping track of the role i usually keep"
1207760,1214080," track of this something called beginning of the line right and if i want to know the uh the role we're"
1214080,1220640," currently located at right so if i have lexa like this i need to know the role the uh the column uh"
1220640,1227760," the column is going to be equal to the lexa cursor minus the beginning of the line that's how we usually"
1227760,1233440," do that i don't really store the column where i currently at i only store the cursor which is absolute"
1233440,1239120," position uh which also may point at the new line and stuff like that and i also keep track of the"
1239120,1245760," beginning of the line right and every time the cursor encounters a new line what i do i increment"
1245760,1252880," the cursor save the new line and increment the line right so i can treat the stream of characters"
1252880,1258400," without thinking about the lines but every time i encounter a new line i just increment and update these"
1258400,1263200," two values and having these two values allows me to also keep track of the column as well does this make"
1263200,1269840," sense this make sense i'm not really sure if it does but i stole this idea it's not my idea by the way"
1269840,1273760," doing it like that and like that is not my idea i stole it from a camel's lexa"
1273760,1281680," believe it or not uh one day i was actually going through like a camel's lexa or something like that"
1281680,1288400," lexa ml i don't remember where i saw that uh and they were literally doing that so there was a definition of"
1288400,1298800," the lexa structure that they use uh and they were doing that but i'm not sure if i can find that uh"
1298800,1305200," right okay i'm not sure if i can find it right away but trust me i stole that idea from a camel"
1305200,1312240," usually if i steal idea i like to credit the places from where i stole all that right so yeah i stole that from"
1312240,1321360," the camera because i used to actually store just column and line instead and it was a huge pain in"
1321360,1328640," the ass to keep track of the things but this one is a little bit easier anyway anyway so what else do"
1328640,1332880," we want to have uh we probably want to have some some sort of constructors right so we want to be"
1332880,1340320," able to construct the lexa uh let's create lexa new and uh we're going to only accept content and length and"
1340320,1346880," everything else is going to be automatically initialized for you i hope uh right so size t con"
1346880,1353920," content length right so we're going to do that and uh what's going to be the next thing uh we're going"
1353920,1361760," to have lexa next which should return the next token right which should return the next token and let's"
1361760,1366880," actually try to do something like token uh we're going to provide the pointer to the lexa"
1366880,1373360," and that is it uh i'm not sure if we want to have any sort of like um"
1373360,1381200," error reporting because what kind of error you're going to report you encounter an unknown token and"
1381200,1388240," what you're going to do about it you're going to cry piss your pants maybe maybe i know there's nothing you"
1388240,1394480," can do about that right so you maybe um maybe we're going to have some sort of like uh token invalid"
1394480,1404880," right token invalid and then the um how to say that the the renderer can maybe highlight it with red or"
1404880,1413600," something like that um okay so something like this do we need anything else i don't think so right um"
1414240,1421680," okay and how are we going to be renderable then so you know what i just thought um we can probably"
1421680,1428960," tokenize all of that on every for every frame is that a bad thing to do what because you're going to"
1428960,1437360," have a text and it's probably a bad thing to do yeah if if we never change the text maybe we never have"
1437360,1443120," to tokenize anything right so you can just the cache the the tokens all of the tokens and every time you"
1443120,1448720," change the text you recalculate all the the tokens it's kind of similar to how we compute the lines in"
1448720,1459520," the editor my god it is yeah the the lines the the lines recomputation is basically tokenization"
1459520,1466880," but by lines that's cool i think that is very fucking cool yes yes yes yes so it's basically you can"
1466880,1471840," tokenize text differently right depending on your purposes and stuff on your goals not purposes goals"
1471840,1477120," all right so lexa.c and we're going to include lexa.h"
1477120,1481680," and let's go and let's just do that"
1481680,1492080," okay so i'm gonna create lexa uh maybe i'm gonna zero initialize this entire thing and i'm gonna set the"
1492080,1500880," content to content to content right content to content and then content length and just return l"
1500880,1506000," so everything else is going to be zero initialized and this is exactly what i want to have for now at"
1506000,1514080," least right so in here um i probably want to create the token that i'm about to return so initially it is"
1514080,1519200," going to be uh zero initialized and then i'm going to just simply return this thing"
1519200,1527840," depending on uh different situations we'll be able to set the token kind to different things but for"
1527840,1533600," now it's going to be that and what's cool is that end is zero so mean it means that if you just create"
1533600,1540560," the token structure with uh zero right so zero initialize that means that token points to the end"
1540560,1546160," right so which is sense which is a sensible uh default in my opinion right but for now i'm going to say"
1546160,1558960," unimplemented unimplemented uh unimplemented uh lexa next right so and this thing is well it is used"
1558960,1564800," but i can say that this thing is in use for now all right so let's actually add all of that stuff to the"
1564800,1569680," building right to the building process otherwise we won't be able to even know whether this entire thing"
1569680,1576240," compiles or not right so let's have alexa dot c and let's try to run build dot sh"
1576240,1588480," all right so size t doesn't know what is the size t as far as i know size t is defined somewhere in"
1588480,1597920," std def right and why did i put defining here what the hell is going on um so this one is no process i"
1597920,1604880," think it's just something something weird uh what else do we have a vector for position okay so this"
1604880,1611120," is located in linear algebra module so i'm going to include that as one as well it's kind of weird"
1611120,1621040," the tokenizer that also uses math right so continuous like 2d graphics which is i mean it's it's not that"
1621040,1627760," it's not that bad actually it's not that weird uh right because tokenization is like a very abstract"
1627920,1632640," process it's process it's process of just grouping characters and classifying characters"
1632640,1638160," for a certain purpose right who said you can't really attach additional information to to the group"
1638160,1645840," of the of the characters for example position on the screen right so who said you can't do that you can't do that"
1647920,1655440," all right so everything seems to be okie dokie and maybe even a karaoke uh right"
1655440,1666320," so the first thing before doing any sort of tokenization right we want to do is basically"
1666320,1673280," get rid of the white spaces right so uh let's maybe create something like alexa trim"
1673840,1679520," a left so and essentially this is going to be a function that simply uh keeps removing the white"
1679520,1684240," spaces until it hits something that is not a white space right uh lexa"
1684240,1690800," trim left lexa like this right so this thing is unimplemented"
1693920,1702320," lexa trim left there we go and what we're gonna do like after we trimmed all of the white spaces and"
1702320,1709040," there is a very weird situation when the cursor for some reason is greater or equal to the content length"
1709040,1716880," what does this mean what does this mean that means we reach the end so and the only sensible thing you can"
1716880,1723600," do in this case is return a token right so we also set the token to be like zero at the beginning of"
1723600,1730480," this entire uh you know endeavor and that actually works out naturally why we didn't have an opportunity"
1730480,1737920," to even classify the token somehow so we just said okay so it's just end of the stream but on top of"
1737920,1745840," that it would be kind of nice if the elements of the tokens right things like text and text len were"
1745840,1751600," actually pointing uh at the end of the stream like they were actually correct pointers and if i"
1751600,1757120," did something like text minus one it would point at the first character of the content that would"
1757120,1763600," be kind of nice so uh it's not on the end it actually points at the memory after after the end so"
1763600,1769440," it's kind of cool so maybe before doing all of that right so we trimmed everything and then we say okay"
1769440,1779440," text starts at the content uh cursor at the content cursor this is where it starts we don't really set"
1779440,1787840," the text length yet it is zero for now but we can update it as we go and tokenize things right so"
1787840,1793520," initially doesn't have a any kind well initial kind is and but it's kind of a default value it points"
1793520,1799680," at the thing uh after trimming at the first non-zero character or end of the stream and then if the"
1799680,1804960," cursor is greater we just return that and it just like has sensible values i think it's kind of cool"
1804960,1815520," so after this entire stuff right after all these entire checks we are 100 sure that the cursor is"
1815520,1823440," less than the content length it is less which means it is absolutely saves saves"
1823440,1830080," to do something like this absolutely safe it's so safe it feels like you're programming in the rest"
1830080,1837520," that's how safe i'm joking by the way so the memory actually with alexa can be corrupted and uh you may"
1837520,1843040," end up with incorrect pointer in here and it might be actually not safe even if this condition is true"
1843040,1850480," right so never never feel safe that's what i'm trying to say right so always always be ready"
1850480,1858000," that something's bad's gonna happen anyway uh so what kind of tokens do we even have in here"
1858000,1864800," right what kind of tokens do we even have in here we defined uh hash right so how can we define a hash"
1864800,1874640," okay so if this character if this thing is equal to the hash well we can just say okay token kind uh is equal to"
1875280,1882640," token hash isn't that cool and what's the size of the token so what's cool is that the the text of"
1882640,1887920," the token already points at the right place it already points to the right place we don't have to do anything"
1887920,1894640," but we know that the token hash is like a one character so that means we can say okay text len is equal to"
1894640,1903280," one and that is basically kind of enough almost uh one of the things we have to do we kind of have to consume that"
1903280,1908400," character right we have to consume that character and increment the cursor by one right we have to"
1908400,1915280," increment the cursor by one and then we can just return the token right then we can just return the"
1915280,1924080," token and there we go we successfully tokenized the uh the thing right uh we successfully tokenized the thing"
1925680,1931520," so interestingly enough uh just incrementing cursor by one is kind of dangerous right"
1931520,1938160," because well i mean it's kind of actually kind of fine uh right i was thinking about what if you"
1938160,1943600," encounter new line somewhere there but the new line should be handled by trim left right new line is a"
1943600,1951520," space uh right so it should be handled by the by these things in here so it should be fine uh okay so what other"
1951520,1961200," things things do we have uh we have symbols right so we need to decide what are the symbols right in c the"
1961200,1970080," symbols are things uh that basically can be used for keywords for uh names of the variables names of the"
1970080,1981520," types names of the functions and so on and so forth uh right so c symbol um okay valid symbol names is that"
1981520,1987360," the thing that we can google up what is a valid and invalid c variable names but it's not only for variables"
1987360,1993680," that's actually right it's kind of similar um"
1993680,2003200," i forgot that quora out of all things quora is banned in my country i completely forgot about"
2003200,2010480," i have no idea why uh our government is insane they're just banning like all this uh okay so let's"
2010480,2015280," actually go to microsoft and microsoft is not banned would you look at that microsoft is not banned but"
2015280,2025680," quora for whatever reason it's banned somebody left a comment that uh our government didn't like"
2025680,2036240," on quora right chat gpt banned well chat gpt is banned by chat gpt but quora is banned in in russia right"
2036240,2042800," so there is a kind of a weird situation where like half of the sites are banned from within and half of the"
2042800,2050080," side of the site of ban from like from the outside and it's just like okay it is what it is and it isn't"
2050080,2063680," all right all right all right all right truly sad game truly sad game"
2066000,2072960," okay so what are the uh valid identifiers do we have a simple rules like i know the rules"
2072960,2081120," right you know the rules and so do i but i just wanted to have the you know confirmation right somewhere"
2081120,2087120," from the uh from some sources or something like that the rules are the following right so the names may"
2087120,2097840," contain uh alphanumeric values basically um english letters and numbers and also underscores right and"
2097840,2106160," they cannot start with a number they can contain number but they cannot start with a number right they"
2106160,2112080," can contain but they cannot start so and the reason is probably because of the scientific notation right so for"
2112080,2120160," instance this is a number right it may feel like a name like at least this part because it contains a"
2120160,2126640," character but this is a number and it's indicated by the fact that it starts as a number right because a"
2126640,2133200," number literal may contain characters another one is a uh hexadecimal value right something like this"
2133200,2138960," this is a number it contains a letter uh right but it's not a variable name and it's indicated by the fact"
2138960,2145440," that it starts with a number so this is kind of like the rules so um there is a difference between"
2145440,2153440," um name that contains a character and actually valid uh valid variable name so we need to separate"
2153440,2158000," maybe symbol start and just the symbol so i want to have two functions like is"
2158000,2163520," symbol start right and we can accept a character right so something like this"
2165200,2173360," uh unimplemented right is symbol start right and is symbol which is going to be this"
2173360,2185520," is symbol so when a symbol start is going to be is digit right so it's is digit i think"
2186400,2196800," i can just use is which basically includes letters and uh digits um i'll numb or uh underscore"
2196800,2202880," right actually wait wait wait is alpha i'm sorry i'm gonna do that i just explained that it can"
2202880,2213120," start with the characters and stuff like that uh right so alpha or equal to underscore but it cannot be digit"
2213120,2218160," so the symbol right so the symbol right the symbol in here is uh all numb"
2218160,2222800," uh is all numb"
2222800,2232400," so yeah it's kind of interesting that they have like the the same length right they have the same length and"
2232400,2239760," it's easy to confuse them the only difference is just these three characters right alpha and none"
2239760,2246080," okay anyway so essentially what we want to do if"
2246080,2252080," el content so i'm speaking spanish right now el cursor"
2254080,2265040," el content el cursor is symbol start right is symbol start uh we need to basically keep consuming the"
2265040,2270320," character this is actually kind of cool because essentially what i can do now is while"
2271680,2283200," el content and content uh el cursor is symbol all right while it is a symbol i can simply increment"
2283200,2293120," the token uh the token text el content yeah exactly uh the token text length and also the cursor"
2293120,2299200," right so the cursor i increment the cursor and uh the text but uh most of all i have to also check that"
2299200,2306320," this thing is less than the content length right than the content length while it is a symbol i just"
2306320,2312720," advance the cursor and i also increment the size of the token uh uh i also have to set the kind of the"
2312720,2321280," token to the token uh symbol right so this is a token symbol right and after we reach the end right"
2321280,2327520," after we reach the end i can just return that specific token and there we go so we now can tokenize"
2327520,2334640," the end of the stream right so the end of the stream uh the hash signs and also the symbols so that means"
2334640,2341120," um effectively we should be able to tokenize at least include right so we're gonna have two separate"
2341120,2349520," tokens in here this uh the hash sign and the symbol uh so after that we have some sort of like a file path"
2349520,2356160," right so we have a file path and what's interesting is that it only makes sense if you are in some sort of"
2356160,2362000," like a pre-processor mode right if you are in pre-processor mode and maybe this is what tokenizer"
2362000,2369600," should be a should be able to do it should have a mode are we right now in a pre-processor mode if we"
2369600,2375120," are in pre-processor mode we're gonna treat this as a string right if we're not in pre-processor mode we're"
2375120,2381200," gonna treat it as like a different thing so i wonder if the modern c compilers do it like that right"
2381920,2387600," because in the old days there were always two programs the pre-processor and then the compiler"
2387600,2392400," so you pass the code through the pre-processor first and you get the c code without pre-processor"
2392400,2397680," stuff and then you have a compiler right but as far as i know these days at least i looked into"
2397680,2405040," compilers like tcc like a tiny c compiler this compiler doesn't really distinguish between pre-processing"
2405040,2413520," and compile it's like uh two in one right and essentially it expands the pre-processor tokens"
2413520,2419920," as it compiles like it doesn't care it's a compiler and pre-process simultaneously so the first thing it"
2419920,2426800," does it takes the token and it expands the token until it reached the end of the expansion process and on"
2426800,2432640," the then this it considers the next token and then it proceeds compiling so it sort of pre-processed things"
2432640,2438720," lazily right it pre-processes the tokens as it goes and there is no really separation between pre-processer"
2438720,2445520," and compiler in tcc i looked like i know that because we hacked tcc at some point right i wonder if you"
2445520,2454480," guys remember that but yeah so and to achieve that i suppose you need a special tokenizer that can have"
2454480,2461200," several states right so as soon as it encounters this thing it goes into the pre-processer state"
2461200,2468080," right and it starts to return different kinds of tokens uh right for instance it can uh if it encounters"
2468080,2475120," hash it goes into pre-processer mode until it encounters the new line after that whatever uh less"
2475120,2481040," or greater symbols you put in here are going to be interpreted as less or equal you know what i mean"
2481040,2487760," right so unless you put a backslash in there if you put a backslash in there so going to the new line"
2487760,2490800," it's still going to be in the pre-processer mode so it's going to tokenize things differently"
2494800,2505360," uh so interestingly enough you can still have less or greater in here uh in the definition for example"
2505360,2513200," when you do define uh and it's going to be fine i guess which is kind of strange so it raises the"
2513200,2520960," question how exactly does it tokenize uh those things uh but i suppose it doesn't really matter"
2521600,2524800," we'll see we'll see we'll see it's kind of an interesting thing it's kind of an interesting thing"
2524800,2534080," uh right so the problem here though is that i ran out of tea so it's kind of difficult for me to uh"
2534080,2538160," think of a good solution so we probably need to make a small break and after the small break we're"
2538160,2547600," going to think how we can do all that um okay so i think i want to maybe check how this entire tokenizer"
2547600,2554320," works i think that will be kind of interesting i think uh but it's kind of not really easy to check"
2554320,2560400," it for now uh right so because we have some things that are not implemented so let's actually go ahead"
2560400,2566880," and just do it like this so this is main uh right so let's create an alternative main"
2568720,2575680," let's say that we're going to have some sort of a content in here which is const char content and uh"
2575680,2582960," so for now we only support hashes right and uh yeah there we go so hash include maybe i'm going to put"
2582960,2593280," another hash in here right so let's go ahead create a lexa out of that uh lexa new content strln content right"
2593280,2598960," so this is going to be that and essentially what we're going to have uh we're going to have a token"
2598960,2610960," right and then i do uh t equal lexa next right and i keep doing that while t uh kind is not equal"
2610960,2618000," token end right so we keep pulling tokens out of this uh out of these things and let's see what we can have"
2618000,2626560," in here we can try to print the token somehow um so let's say that we're going to have something like"
2626560,2634160," a token kind name right we want to be able to convert like a token kind to a name so we can display that"
2634160,2640080," in in here uh and after that i think that should be fine so this is how we're going to be uh you know"
2640080,2647440," lexically analyzing this specific string right so it would be also nice to uh print that string here"
2647440,2653600," somehow but i don't remember how you print size string with print f right print f sized strings"
2653600,2659600," because it's kind of weird you have to put like a star in here and dot here but i don't remember do"
2659600,2666000," you put dot here or here it it never makes sense to me like i can never remember it's such a weird way"
2666000,2672960," of printing size strings so uh i always have to google it doesn't have any sense and doesn't make any sense"
2672960,2681760," okay so you have to put dot uh first right so you have to put dot first so text um and then you have"
2681760,2689600," to provide the text length right so text length and the text link must be integer not size uh right so it"
2689600,2694960," is integer with meaning that it can be negative for whatever reason uh i don't know why but it can be"
2694960,2700480," negative sure and that should be enough so we're also going to wrap this entire thing in parentheses to"
2700480,2708000," separate the actual text from the uh from the kind of the token right so uh let's try to compile this"
2708000,2712640," entire thing and see how it miserably fails right so what do we have in here we don't have a lexa"
2713360,2721520," because we need to include the lexa lexa dot h there we go so what else do we have we don't have a token"
2721520,2727360," kind name let's actually introduce that okay so where's the token kind where's the token kind is going to"
2727360,2741600," return the const uh char and we accept token kind uh token kind uh lexa dot c so let's maybe put it somewhere"
2741600,2757200," here and now i can do something like this switch kind boom then boom case this return boom boom boom"
2757200,2764000," boom so in case of default situation we're going to say something like uh unreachable right so unreachable"
2764000,2772160," uh and there we go that should be enough i think so in here we can just return uh maybe no let's"
2772160,2776800," return no in case we're going to try to print this and i think it should set fault but it should be"
2776800,2782080," unreachable in my opinion right it should be definitely unreachable we can even put some sort of a message"
2782080,2795840," in here token kind name so end of uh end of what end of string content let's call it called end of"
2795840,2807440," token end of content uh invalid token uh hash sign so this is a hash sign a symbol right uh so this is kind of"
2807440,2813520," stuff still token kind name right so if we try to compile that you should complain about unreachable"
2813520,2817600," because i don't think we have unreachable or do we have unreachable i don't remember"
2817600,2824160," okay so yeah we don't have unreachable and reachable should be easy to implement all right so we have"
2824160,2831040," things like unimplemented uh all right so let's introduce unreachable uh because it's kind of simple"
2831040,2839280," similar it's just like a different text unreachable yeah and let's also realign backslashes okay damn it"
2839280,2844160," get fucking damn it meat okay i'm sorry"
2844160,2857120," so it complains about is alpha but this is because we didn't import uh include c um c type but it also"
2857120,2865840," complains about boolean so it wants to have uh something like std boolean right std boo"
2865840,2869840," std bully"
2869840,2874720," okay so we also need to include c type"
2881920,2887440," cool so it combines and if we try to run this entire thing all right so this is gonna be that"
2887440,2894240," and it says lexa trim left is unimplemented and we can go here and implement it so how are we gonna be"
2894240,2908080," doing all that all right uh so while cursor is less than the content length uh right and content l cursor"
2910080,2918640," uh is space while it is space we simply increment"
2918640,2929360," the cursor that is it it is as simple as that while we have some characters in a content and those"
2929360,2936080," characters are spaces we just remove those characters by advancing the cursor so basically cursor plus one is"
2936080,2945840," just consuming the character um but interesting enough what if that specific character um is a new line"
2945840,2950240," right what is what if it's a new line this one is rather interesting actually"
2950240,2960480," so if it's a new line uh we have to um update our current line and the beginning of the line so we can compute"
2960480,2969360," things correctly uh so and i'm not even sure as i already said that we do care too much about beginning"
2969360,2973920," of the line maybe we do actually yeah so because we need it for the for the position and stuff like that"
2973920,2986160," right so essentially if the content not not just the cursor but also a new line right before incrementing"
2986160,2991360," things we also have to increment the line right so on which line we are we start with a zero now it's one"
2991360,3000240," and then um right and then we have to assign a new beginning of the line but here's the interesting"
3000240,3008320," thing so we have this situation a b c d and then new line right so the currently the cursor is at new line"
3008320,3016800," right we're currently at the new line uh right but we need to so and this starts another line uh right"
3016800,3021760," but the beginning of the line has to be the next one right it has to be the next one so that means"
3021760,3028160," this kind of condition has to be checked after we incremented this thing so we may do something like"
3028160,3037600," character x just save this entire thing in here then increment the cursor and if it's if it was a new"
3037600,3043120," line we're gonna increment the line and also we're gonna set the beginning of the line to the new cursor"
3043120,3050960," like so um something like that right it may evolve into something interesting in the future uh we'll see how it goes"
3057520,3063680," right so this is something that we have in here okay good so let's rebuild the entire thing"
3063680,3076160," and it keeps printing hash sign isn't that cool that cool i think it's pretty cool so it keeps saying"
3076160,3083360," it's a hash sign it's a hash sign it's a hash sign uh let's find out uh why is is it keep saying something"
3083360,3093840," like that right um right we incremented the uh the thing right we incremented the thing um and that"
3093840,3102080," should be fine i don't see any problems with that uh right so it may happen because of"
3102080,3108560," this if we forgot to put uh plus one in here but we didn't forget to put uh this one in here"
3109520,3118800," uh right we didn't forget to put plus one here so this one might be kind of weird this one might be"
3118800,3128640," kind of weird uh so maybe on top of that after we oh yeah i know why because we never actually get"
3128640,3138800," the next token yeah i've completely forgot to do next token in the loop there we go so this is what"
3138800,3147760," we have we have first hash sign then include as a symbol then a hash sign again right interestingly uh as"
3147760,3152960," i already said uh because of the way we tokenize it doesn't really matter how many spaces we have in"
3152960,3159040," here right none of that matters if you're gonna retokenize this entire stuff it's still going to be"
3159040,3165840," hash sign symbol hash sign right we can add another symbol in here another valid symbol in here"
3165840,3174640," right and it says include full and it sees it as two separate symbols but again if i put if i remove"
3174640,3180000," white space between them uh it is going to be considered one symbol again right so this is like sort"
3180000,3184800," of like the nature of the tokenization you know what i mean it's the nature of the tokenization"
3184800,3190400," uh right so uh and we can tokenize this kind of stuff"
3190400,3197200," is that cool so i think we don't handle invalid tokens right for instance if i have something like include"
3198000,3209040," uh right uh right so let me see something like stdio.h i don't think it's gonna work properly uh right"
3209040,3217760," yeah a lexon yeah that's actually kind of cool so it basically went through all of the conditions in here"
3217760,3223840," right and it didn't uh recognize any of the existing tokens right it didn't recognize any of the existing"
3223840,3233440," tokens and uh then we hit unimplemented okay so here usually what i do i report an invalid token right so"
3233440,3241200," if we reached this point this is an invalid token token invalid okay here's an interesting thing uh"
3241200,3250400," what we can do we can actually set the token text len to one right and say okay we encountered a known"
3250400,3257120," token we don't know what the it is right we're going to report it as a token over symbol one hoping that"
3257120,3263680," the next token the next character starts with a valid token you know what i mean uh we can try to do"
3263680,3271200," something like this and uh let's try to recompile this into anything and it keeps saying invalid and one of"
3271200,3278160," the interesting thing i forgot is to also consume the token right so el cursoro uh is going to be plus one"
3278160,3284960," yeah so that's kind of important uh and now we can see how exactly it tokenized uh this entire thing"
3284960,3292800," right so first it found the hash sign right it is correct it is a hash sign then a symbol include"
3292800,3302640," a symbol like this then invalid token invalid token this thing right and then it found a symbol so it"
3302640,3309760," recognized this thing as a symbol uh then it found another invalid token uh right which is dot then a"
3309760,3315040," symbol and then another invalid token so we can handle it like that i'm not saying that this is how we're"
3315040,3321920," going to be handling that uh but for now we can just keep it like that so if we um went through all of the"
3321920,3326720," checks if we checked for all the possible tokens and we couldn't recognize that token we just take that"
3326720,3336080," character and report it as invalid token so maybe the um the renderer is going to render it with a red sign"
3336080,3341920," telling you that like i don't understand what the did you just say uh correct that right you know what"
3341920,3349760," i mean you know what i mean so that's basically the idea that's basically the idea but specifically"
3349760,3355840," from the pre-processor right so the thing with the pre-processor pre-processor are a little bit finicky"
3355840,3363680," uh because the tokenization of pre-processor directives depends on the directives themselves"
3364640,3373040," right because for instance if we're talking about directive include it tokenizes uh less and greater"
3373040,3379600," as the beginning and the end of a string for the file path right but if we're talking about define"
3379600,3388720," where you define a certain thing this thing tokenizes uh you know greater and less as tokens of c because"
3388720,3394400," it's going to replace token foo with this sequence of tokens so it not only depends on whether"
3394400,3401200," you are in pre-processor mode it also depends greatly on the pre-processor directive itself different"
3401200,3406800," pre-processed directive we're going to just tokenize things differently because of that uh i want to"
3406800,3414560," actually sort of put the idea of tokenizing pre-process on a back burner by doing the following hack"
3414560,3424160," essentially uh if we encounter the uh the hash sign we basically take all of the characters up until"
3424160,3433120," the end of the line and report it as a single token pre-processor right pre-processor and uh then the"
3433120,3441840," the render color it with a single color for now for now right so and of course it's going to be a"
3441840,3450560," little bit more um how to say that uh more nuanced because the pre-processor may continue uh working if"
3450560,3456080," you put backslash because in the pre-processor you can backslash the uh the new lines right so we're"
3456080,3459600," going to handle that as well but in any case everything that is in the pre-processor we're"
3459600,3466080," going to say it's a single token it's a pre-processor bullshit just color it somehow and then we continue"
3466080,3471440," tokenizing as usual so what's interesting is that in a similar way we're going to be pre-processing"
3471440,3477840," uh we're going to be tokenizing comments and strings right because in comments and strings"
3477840,3483360," it's kind of similar right because if you encounter slash slash it's basically okay take everything"
3483360,3488640," starting from slash slash up until the end of the line and say this is a comment no matter what kind of"
3488640,3493600," shit do you have in here do you have spaces you don't have spaces doesn't matter single token comments"
3494400,3500320," the same goes with the strings right it's just like you have spaces don't have spaces doesn't"
3500320,3506320," matter everything up until the end up until the double quote it's a string render it somehow plus you"
3506320,3512560," may have situations when you like um escape some of the things right so it's like we're going to be"
3512560,3518720," handling pre-processor comments and strings in a similar way uh but pre-processing handling is going"
3518720,3525200," to be like like that for now just because i don't want to go into this weirdness of if we encountered"
3525200,3530640," include that means we change the tokenization to that if it's defined change tokenization to that"
3530640,3534960," i really want to deal with that you know what i mean it's just kind of like i can do that maybe later"
3534960,3544720," right for now i just want to have something something working right uh all righty you know what i mean"
3544720,3552240," you know what i mean uh hopefully you know what i mean okay so uh we have and we have invalid uh we"
3552240,3557280," don't we're not going to have a hash we're not going to have a hash we're going to have a pre-processor"
3557280,3570320," right uh maybe i'm going to call prep prep prep so then we're going to be able to handle the symbols"
3570320,3576880," and some other uh legomegger uh thank you so much for five months of tier one subscription with the"
3576880,3584080," message sub zozin a sub hello hello really good to see so we have any other uh subscriptions okay we don't"
3584080,3591680," have any other subscriptions um preproc yeah but prep prop sounds funny"
3597840,3608960," all right so uh let's go uh so if we encounter hash if we encounter hash what do we need to do"
3608960,3615200," we basically need to start doing the following thing consume everything up until the end of the line"
3615200,3625680," right consume everything up until the end of the line while l l cursoro is less than l contento length"
3625680,3639920," right and l contento uh l cursor cursor is not equal to the new line right we basically keep incrementing the"
3639920,3653520," cursor and uh keep uh incrementing the size of the text right so basically token uh text length plus one"
3653520,3658400," so we just keep incrementing that we just keep incrementing that so and of course uh the token kind"
3658400,3669760," has to become pre-processor pre-proc that's it so interestingly we may have a weird situation"
3669760,3678240," that yeah so when we encounter new line we also have to update the beginning of the line and the line itself"
3678240,3685120," so we know the coordinates where we are located so uh that means now we have to do this thing in two"
3685120,3691600," places in here when we consume the pre-processor and also in here when we trim the left white spaces"
3691600,3698320," so i encountered this situation over in oregon when i developed the tokenizers and i came with a solution"
3698320,3705440," to have a separate function that consumes a single character you know what i mean uh so essentially"
3705440,3714400," lexa chop uh maybe char or something like that um right and essentially is going to return the character"
3714400,3720800," and what it does it takes the current character it just chops it and returns to you"
3721440,3727520," uh some people suggest it maybe it's it but i like to call it chop right so it's going to report the"
3727520,3734000," character to you and um it's going to increment the cursor it's going to also update the line"
3734000,3737920," and the beginning of the line depending on whether you encounter any line and stuff like that so we're"
3737920,3743520," going to encapsulate this entire logic into a single function that just works with a single character"
3743520,3750240," and we'll forget about it right we'll forget about it so it's going to be like that so uh i think it's"
3750240,3754560," not going to be a responsibility of this function to check whether you reach the end of the content so"
3754560,3762320," we're going to assert uh that the cursor is less than the l content right so it's like it's not up to this thing"
3762320,3772480," um all right so the next thing we can literally take actually this chunk of code and take it as an"
3772480,3778400," implementation of the function believe it or not and we can just return x actually it works really great"
3778400,3784640," it works it's like it's the implementation of the function is literally this right because we take"
3784640,3790480," the next character if it's new line we just update that but we still return this entire thing uh right"
3790480,3800720," and then here what we're gonna do uh is i think man this is actually kind of weird because i feel like"
3800720,3808960," the entire implementation is just lexa uh chop character l and that is it and the while loop is empty"
3808960,3819440," uh you know what i mean well probably not no probably not because you don't want to do it like that"
3819440,3828320," right so essentially you want to first check yeah it's kind of dangerous you check for that"
3829520,3836480," and you just call yeah for this one it's not going to work like this uh chop character l right but for"
3836480,3840560," this specific case we don't really care about the result right so we don't really care about the"
3840560,3845760," result so we're going to ignore the result uh so sometimes to indicate that i don't really care about"
3845760,3852000," the result of a certain function i just wrap it in unused i'm not sure if it's it's sort of like i i say"
3852000,3857200," that i know that this function is supposed to return something but i don't care about it"
3857200,3866320," it's just like yeah so for documentation purposes like yeah yeah i know it returns something but in"
3866320,3874000," this specific case we kind of don't care okay okay um all right so what we're gonna have in here um"
3875120,3887040," essentially so while this thing is um is not a new line uh we're going to do the following stuff wait wait a"
3887040,3903520," second yeah this is fine um so and what we can do is just lexa chop character right so this is a"
3903520,3909920," preprocessor while we have something and that something is not equal to the new line uh we're going to chop the"
3909920,3917040," character right i don't care about the uh the final thing of that character and so we can have different"
3917040,3924080," situations in here for instance when we reach the end of the stream uh if we didn't reach the end of"
3924080,3930560," the stream we have a new line in here right we do have a new line in here so maybe i'm gonna actually do"
3930560,3938560," the following thing if this thing is still less than the content i just do lexa chop character like i"
3938560,3945200," chop an extra character uh right which is not becoming part of the token and the way it becomes"
3945200,3954160," part of the token i also increment the text uh length all right so as i chop the characters uh the chop"
3954160,3959200," the characters i increment the length and after that if uh we still have some characters that means this"
3959200,3966320," thing is equal to the new line so i chop this thing and automatically go to the new line and so on so"
3966320,3975120," what's worth okay so that's fine that is very very cool uh right so now uh let's go and try to recompile"
3975120,3980960," this entire thing so now if everything's correct uh so token hash we don't have a token hash but we do have"
3980960,3990000," a uh pre-proc um pre-processor directive uh directive uh directive so what else do we have in here"
3990000,3994720," uh huh so we don't have an assert and this is because we want to encode assert"
3994720,4008480," as earth as earth okay uh and yeah that's actually kind of cool so this is the tokenization it recognizes this entire thing as a pre-processor directive"
4008480,4019040," easy tokenizer by the way anyway so uh what else can we do in here uh right i'm gonna use the feature that i"
4019040,4027520," you know hated c4 i'm gonna use the multi-component string literals because it makes it easier to do"
4027520,4033200," things like this right so what if we have an actual code in here so how are we going to tokenize this"
4033200,4042320," thing um all right and let's actually one two three four return zero let's try to tokenize like a very"
4042320,4050480," simple c code uh right so what we're going to have in here so the first thing we recognized the first thing we"
4050480,4057440," recognized we recognized we recognized a pre-processor directive then we recognized int as a symbol right"
4057440,4064640," then main as a symbol then we found invalid token which is open pairing then void symbol invalid token"
4064640,4073520," invalid token return symbol invalid token invalid token invalid token but it's working right so it kind of"
4073520,4079760," recognizes the main components of the c language if you know what i mean right so it kind of like me"
4079760,4085040," starting to make sense of this thing so the next thing we need to do we probably need to add support"
4085040,4091280," for open parent right and then for closed parent and so on and so forth let's go ahead and try to do that"
4091280,4099680," right so since we already have like sort of like a backbone of this thing uh we can just like throw"
4099680,4106800," more and more tokens on top right so it's going to be token open uh parent right there we go token open"
4106800,4116560," parent and let's see what we can do in here uh so token open parent and we can say that this is an open"
4116560,4127760," parent uh not parent but parent and when do we encounter open parent well when l content uh l cursor"
4127760,4136640," is equal to open parent right when it is equal to that uh we say that the token kind is equal to"
4136640,4146640," token open parent then we know that the size of this thing is in fact uh one right it is equal to one"
4146640,4153680," and then we can actually increment this thing and then we have to increment we have to lexa uh chop"
4153680,4161120," character l unused so i feel like i'm constantly using used maybe this thing should not return anything"
4163200,4170880," and then we just return out of that right so there we go um look at that so it complained about something"
4170880,4177840," uh it has to be equal sure it complains about something one more time and this is because we have"
4177840,4187040," to return the token yeah okay look at that so uh let's open the code as well right let's open the code as"
4187040,4194320," well so the first thing we recognized is pre-process a directive then a symbol int right so here is the"
4194320,4203440," symbol int then symbol main and then open parent it is not invalid symbol anymore look at that it is not"
4203440,4209680," invalid and then we've got the void symbol and then uh rest is invalid stuff but what's cool is that it"
4209680,4214320," doesn't really matter like what kind of white spaces you put in here right it doesn't really care about the"
4214320,4219280," white spaces like it literally doesn't give a shit uh right so it's going to still tokenize it as as"
4219280,4224880," usual right so we have an open parent and some stuff like that so the next thing we probably want to do"
4224880,4232240," is to add a close parent right so let's go ahead and do that so we just added a close parent uh believe it"
4232240,4240080," or not it's as simple as that and then i say okay close parent close parent let's find the open parent where"
4240080,4244560," where it is where it is where it was i think it was something like this and close parent is just"
4244560,4251840," basically copy paste this code close parent close parent and there you go simple as that oh"
4251840,4263280," and look at that close parent open parent close parent and you just keep repeating process you just keep"
4263280,4270720," adding tokens just keep adding tokens uh which one that's a very interesting question like isn't that"
4270720,4275920," like a lot of copy paste code right isn't that a lot of copy paste code like to just do that that's kind of"
4275920,4282880," weird maybe we can abstract that out holy"
4282880,4294160," um let's introduce a notion of literal tokens and by literal tokens i mean the tokens that you interpret"
4294160,4301040," literally right for instance uh you have a token open parent and if you encounter open parent in the code"
4301040,4309280," that's the token it's literally that token it's not like very vague uh like like a string right because"
4309280,4314560," string it could be any kind of combination it's kind of like a very fuzzy very weak token it says starts"
4314560,4319760," with quote a double quote and ends with double code but within them you can have all sorts of things"
4319760,4325920," it's not like literal right but you have a literal token open parent is open parent god damn it it's"
4325920,4332080," literal talking and we have majority of the tokens like that are going to be like that all right so uh"
4332080,4337360," let's introduce the notion of a literal token so uh what i want to do okay"
4337360,4341520," i want to create a structure uh let's call it a literal maybe literally"
4341520,4349600," token let's call it literally talking so in here we're going to have is the name right so the actual"
4349600,4356560," name or maybe the actual text of the token and its associated kind right so basically if you see"
4356560,4363600," this combination of characters assign that specific token kind to that you know what i mean right just"
4363600,4370480," assign that specific kind uh right and let's just have a global table of literally tokens"
4370480,4380880," right let's call it literal okay so uh literal token uh literal tokens and we're gonna have an array of them"
4380880,4389600," right so that's what i like to do so and uh for instance i have a text if i encounter uh just an open"
4389600,4400320," parent the kind is going to be token open parent if i encounter a close parent the kind is going to be"
4400320,4406320," close parent uh what else do we have in here do we already have something um so open"
4407040,4413920," pre-proc invalid that's that's kind of fine okay so and for instance if we want to support curly braces"
4413920,4422720," right so this is going to be open curly and this is going to be close curly right and down there we're"
4422720,4428800," going to just have a loop that iterates through all of these things right and if we want to add another"
4428800,4433840," like literal token we can just add it there and it will automatically pick it up and stuff like that"
4434480,4442400," sounds good sounds good sounds good okay so we also want to know the like amount of elements of this"
4442400,4448720," array so let's actually introduce something like literal tokens uh literal tokens count uh which is"
4448720,4457600," essentially size of literal tokens divided by size of literal uh talking zero right so little tokens there"
4457600,4463840," i'm going to put it in here and uh so essentially what we're going to do in here we're going to remove"
4463840,4468720," all of this stuff all of this repetitive stuff with just a single loop that iterates through the literal"
4468720,4475520," tokens size i so all that stuff in here up until here is going to be deleted it's going to be replaced"
4475520,4483920," with the loop that we're currently uh implementing right so uh literal tokens count plus plus i right"
4485360,4492320," so and then um and here's an interesting thing so for now literal tokens they start um"
4492320,4503360," they start with they consist of a single um single character but what if we're going to have multiple"
4503360,4513760," characters right so for instance uh think like this is a separate token this is a separate token but if like a"
4513760,4519520," single one but if you put a space in here this is going to be treated as two separate tokens"
4519520,4524880," so there is a little bit of a complication right so as you can see tokens are like very much space"
4524880,4530880," sensitive depending on like on kind of tokens and like what spaces between them it can be tokenized"
4530880,4535280," completely differently uh it can be tokenized completely differently uh it can be tokenized completely"
4535280,4547040," different so uh what do we want to do what do we want to do we want to have a function that can check"
4547040,4556240," whether whether the lexa the content of the lexa the current content of the lexa starts with a certain prefix"
4556240,4562240," right it's kind of similar to what we did on the previous stream with the editor right so uh editor"
4562240,4567520," yeah starts yeah it's kind of that like i want to implement something like that but for the token for"
4567520,4572080," the tokenizer you know what i mean uh something like that but for the tokenizer"
4574000,4580560," uh let me let me let me see what we have in here"
4580560,4594080," all right so uh boolean lexa starts with so we provide lexa and we provide the prefix right we provide"
4594080,4601200," the prefix how are we going to be doing all over that how are we going to be doing all that so um"
4601200,4610000," i think i'm going to steal this code believe it or not uh yeah so because the first thing we do"
4610000,4617920," we calculate the length of the prefix right and then if the length of the prefix is equal to zero"
4617920,4623440," that means it always starts with the prefix like any strings always start with an empty prefix that makes"
4623440,4633840," sense uh then uh what do we do so this is a line some other stuff and if i take the"
4633840,4639280," cursor and add the prefix length plus one"
4639280,4642720," it should be"
4642720,4652960," less than the end of the of the lexa essentially so essentially if it's greater"
4652960,4661600," or equal to the lexa content length this is straight up no no that means the prefix is bigger than"
4661600,4669040," whatever content we have it doesn't make much sense and after that we just iterate through the prefix"
4669040,4678240," values right through the prefix values uh so this is basically uh content content"
4682000,4688400," l cursor plus i and if it's not equal instant return false otherwise we return true okay so"
4688400,4694880," yeah some of the code that we used for the previous highlighting mechanism can be reused in the tokenizer"
4694880,4699200," which is kind of nice i really like that so let's try to compile this entire thing uh it doesn't really"
4699200,4709200," compile because yeah so first i need to finish the implementation of the of this thing so essentially if um lexa"
4709920,4716240," starts with so this is the lexa and literal token right so this is a literal token"
4716240,4724640," uh literal token text if the lexa starts with this specific uh literal token that we found uh we have"
4724640,4730880," to do the following thing we have to set the token kind to the literal token that we found"
4730880,4741600," and then increment the text length to the length of the text of that token might as well"
4741600,4748800," save this thing to the text len right because we're going to be reusing it i think at least two times"
4748800,4759280," right because we also need to increment the cursor by that thing and then we should just return uh return the token"
4759280,4766240," so i'm not sure if like chop character is important here right so it's only going to produce an errors if"
4766240,4771680," there is new lines within this thing but having a literal token with a new line is kind of weird"
4771680,4782960," uh right so maybe i'm going to put it to do in here so um note this code assumes that there is no new lines"
4783680,4792960," in uh here right so we're kind of making like a very bold assumption but maybe that's fine because like"
4792960,4798320," it's kind of difficult to imagine such situation but it's kind of important to keep that at the back of"
4798320,4805360," your head uh back of your head uh all right okay and that should be it right so we just like can add"
4805360,4811520," more tokens in here and this copy paste is just replaced with a single loop right so let's actually"
4811520,4817920," go to the compilation errors let's go to the compilation errors and we need to add more tokens in here"
4817920,4827600," right uh let's go ahead and do that lexic lexic lexic dot h so this is going to be curly all right curly"
4827600,4833520," open curly close curly uh here we also probably have to add the names maybe i should replace this thing"
4833520,4843040," with um with an array as well so here's the curly here's another curly uh right so and let's go"
4844880,4851440," so it's still compiling but it's producing some warnings and stuff like that so here's string"
4851440,4859440," what else we have okay so as you can see it is working and it is tokenizing and classifying things"
4859440,4867280," correctly more or less i think uh so as you can see open parent close parent open curly uh close curly"
4867280,4874720," but it does not recognize numbers and um the semicolons right but it's super easy to add semicolon right"
4874720,4886160," so uh semi colon uh colon so then in alexa.c uh we're just doing the following thing"
4890560,4899280," semicolon right so this is a semicolon and if i try to run this thing one more time uh it's going to"
4899280,4904160," kind of understand but talking kind yeah i forgot to add a token kind semicolon that's actually kind of"
4904160,4911120," cool uh right so it can it caught this kind of situation uh semi colon"
4914320,4921200," it actually got that right so and we have only one invalid token which is a number which is also super"
4921200,4931040," easy to uh tokenize as well right um so"
4935040,4940640," isn't that cool isn't that cool isn't that cool i think it's pretty freaking cool chat interesting"
4940640,4952720," very cool i also think so so it's kind of like already done to some extent right it's already done"
4952720,4960720," to some extent we can try to plug it into the uh renderer right uh so i don't really want to implement"
4960720,4967920," like literally everything because it's not going to be um you know very productive it's better to take"
4967920,4973120," whatever like little tokenization that we already have right like a little tokenization we already have"
4973120,4979840," and just plug it in and then keep extending the tokenization uh and having it connected with the"
4979840,4990080," renderer already you know what i mean um connected to the renderer already so but the thing that i didn't"
4990080,4997120," implement here yet the thing that i didn't implement here is essentially the calculating of the position"
4997120,5002880," right so because the token doesn't really have a position uh right so this is going to be lexi.h"
5002880,5008560," and this is what we have in here uh and"
5008560,5016320," what i'm thinking what i'm thinking is that"
5020560,5026640," maybe we should keep track of the position maybe we should keep track of the position the same way we"
5026640,5029840," keep track of the line and the beginning of the line and stuff like that"
5029840,5041680," though uh with the way we render things right now uh we assume the regular height of the of the characters"
5041680,5049360," right so that's basically what we do maybe we can do a similar thing right maybe we can do a similar thing"
5049360,5055520," uh and essentially yeah"
5055520,5061600," and essentially yeah so i have a interesting idea"
5063680,5072720," so here is the text right and here is the position uh i might as well do it like this i suppose token"
5072720,5084720," position x right so token position x i take the um line and multiply it by the whatever we have like in"
5084720,5091520," the free glyph uh height thing here right so free glyph font size uh right and the way we actually use"
5091520,5097840," it right now in the code yeah i just take a row uh i just take a row and i multiply it i even not not"
5097840,5105280," only take a row but actually take a negative because we go down uh right because we go down and this one is"
5105280,5113360," basically like a line so that's basically the position the position x the position y is uh rather"
5113360,5118960," interesting i mean it's it's it's actually why i'm sorry i'm an idiot i'm already getting tired so the"
5118960,5123600," position x you initially should start with zero but it's already initialized with zero so we don't have"
5123600,5143040," to really worry about it too much um yeah um so this is where it is kind of um kind of tedious right uh"
5143040,5149920," because we have to keep track of the current x of the lexa we have to keep track of the current x"
5150800,5158080," float x i'm not really sure how to uh how to call it but i'm going to call it x and essentially essentially"
5158080,5168800," as we chop a character as we chop a character we increment um its x by its width by the width of the"
5168800,5177040," character so here i already called it x but i mean it's it's under the the namespace of the lexa right so"
5178640,5191200," essentially what i can do i can take the x and i can increment um this thing by the um by the metric so"
5191200,5201440," i have to go to the atlas uh right i have to go to the atlas and the atlas is this uh right so in atlas"
5201440,5210480," freglyph.c right what we do we just add the matrix yeah we just add the matrix of that thing"
5210480,5217680," so x and y this is position within um within the coordinates i suppose"
5217680,5223360," uh i don't remember what it is but i suppose"
5225600,5230080," i think that's what we have to increment it by yeah that's what we have to increment it by"
5230080,5236960," uh and then reuse it then reuse it so"
5236960,5244320," i think i want to make a small break chat i think i want to make a small break because now what this"
5244320,5254320," means is that the lexa should also also be aware of the atlas right it should be aware of the atlas so we"
5254320,5258720," have to pass it somehow we can't really pass it as an argument uh because it's more of an internal"
5258720,5267040," function uh but maybe one of the things we can do in here is uh keep track of the free glyph"
5267840,5276880," atlas in here somewhere right so and accept this thing during the construction uh right so then later"
5276880,5280160," we can actually properly use it"
5280160,5290160," uh right so because it's kind of difficult to just by knowing the coordinates like in characters to find the"
5290160,5298960," coordinates in screen right even though we're using monospace uh font should so it should be fine but"
5298960,5303840," if you switch to non-monospace font it's kind of going to be it's not going to work but we have to like"
5303840,5308880," design everything around the idea that you can use any font right so we have to design around that idea"
5308880,5314240," so yeah let's make a small break and after the break i'm gonna uh just go through implementation of"
5314240,5321760," this entire thing and yeah so the main problem here is basically figuring out the positions on the"
5321760,5327360," screen for the tokens and after that you can just feed the tokens into the renderer and tell it just"
5327360,5335760," render those things there um should be crazy yeah anyway so uh let's make some more break let's continue"
5335760,5342240," uh what we need to do i think i want to try to compile and go through the compilation errors"
5342240,5346960," and just fix the compilation errors all right so because here we're supposed to provide the"
5346960,5352000," the pointer to the atlas in this specific case yeah it makes it kind of difficult to"
5353600,5362720," um you know test like uh test that in a what is it called in the terminal because we don't have the"
5362720,5367680," font atlas in the terminal right so because it requires like loading things up creating textures and"
5367680,5372560," stuff like that we don't really have that in here so i'm going to put a null in here uh and"
5372560,5380160," i think i'm going to create alexa that simply doesn't care about the atlas if you provide it"
5380160,5390240," no uh right so it's called free glyph free glyph dot h since when wait the"
5390240,5397760," fuck free since when it has icons like that i don't remember it having icons like holy"
5397760,5405200," fucking shit do i have like a properly configured text editor without a completion check what the"
5405200,5414800," fuck i don't remember doing that um okay it was weird but it is what it is uh so atlas"
5414800,5424720," and what we want to have in here is atlas all right so atlas now we have it isn't that poggers my dude"
5426240,5437440," i think it's pretty full complete uh free glyph atlas where's my dude why is it still playing music i'm"
5437440,5444640," gonna get copyright striked copy striked that's what it's called okay so in here what do we do we need to"
5444640,5454480," basically uh take the metrics of the of the character right so we only need to do that when this thing is"
5454480,5458320," not equal to new line when the thing is equal to a new line i think we're going to actually put zero in"
5458320,5467680," here uh yeah so that's the reason nothing to do but here if it's not zero we have to uh take the metrics"
5467680,5474880," take the metrics and the way we take the metrics first of all we figure out the glyph of the text"
5474880,5486080," all right so essentially uh the glyph index so i uh it's a text the glyph index is literally this thing"
5486080,5493840," yeah if it's x if it's greater than glyph metrics capacity we basically assign it to a question mark"
5493840,5501760," yeah so that's what we're gonna do here and then we take the metrics for that specific glyphs in there"
5502480,5509440," uh right that we pre-computed and stuff like that of course and then we want to increment x by that"
5509440,5519840," specific metric that's what we do and i think that is basically it right so but it only makes sense if um"
5519840,5527680," the atlas was actually provided right so for instance we're going to do if atlas"
5529280,5535840," is defined if we provided null in there we probably don't want to do that um right and we'll probably"
5535840,5537200," have to do l atlas"
5537200,5546800," so look at the look at the amount of indirections in here look at the amount of indirection my gut"
5546800,5554880," it's insane okay so everything seems to be compiling uh but on top of that we also compute the position of the"
5554880,5564560," tokens which is kind of poggers i think i personally think it is poggers um so the the only thing we need"
5564560,5570000," to do now is to actually plug it into the editor right so let's actually go ahead and plug it into the"
5570000,5577200," editor so the way i want to plug it into the editor is basically uh within the editor on top of keeping"
5577200,5584800," track of the lines i want to keep track of the tokens right tokens for the highlighting and uh we're going"
5584800,5589280," to have the following thing we're going to have a tokens tokens is going to be the classical dynamical"
5589280,5595920," array the dynamical dynamic array uh the elements of which which which is basically a structure with three"
5595920,5602480," fields items count and capacity uh right and of course these things has to be size t"
5602480,5610800," and uh the items are tokens right the items are tokens so we put it in here and what i'm thinking is that"
5610800,5618320," we already have a moment within the text editor when we need to recompute the lines which are basically"
5618320,5627040," also kind of tokens uh what if we do a similar thing what if we say uh okay um when you recompute the lines"
5627040,5634160," also retokenize the entire thing uh let's go to the editor uh recompute man this is actually too"
5634160,5642080," fucking simple what the fuck okay so where do we do that here it is okay we recompute the lines and uh here"
5643200,5649600," we're gonna do another thing we're gonna create the lexa out of the text right so this is gonna be lexa"
5649600,5658080," uh lexa new and we have to provide the atlas do we have the atlas though in the editor itself we kind"
5658080,5670800," of don't and this is something that we'll have to do uh yeah man yeah man okay so that means we need to"
5670800,5679440," store the atlas within uh the entire thing within the entire thing uh we only pass the atlas when"
5679440,5687200," we're rendering this entire stuff which is which can become a problem which might become a problem so"
5687200,5693520," yeah let's do the following thing i'm gonna do free glyph atlas"
5696080,5703280," atlas becoming kind of invasive so a lot of parts of the code need information from atlas which worries"
5703280,5705760," me a little bit but maybe that's fine maybe that's basically"
5705760,5709840," where the architecture converges to so maybe that's fine"
5709840,5716880," so i'm gonna keep modifying it like that and see uh if it's going to work or not okay"
5718800,5726320," so in the editor we create the lexa lexa wants to have the atlas"
5726320,5735040," so here's the atlas then we take the data and the items of the data and the data"
5735040,5740800," count right so data actually stores the character the actual text"
5742160,5748240," right and since we also keep track of the tokens so the editor we take the tokens and we reset"
5748240,5752240," the tokens to zero right so this is basically the tokens now"
5752240,5757840," and now i'm going to do the following thing so here's the token uh maybe i'm going to do it like"
5757840,5767120," that lexa next i provide lexa and while uh token kind is not equal token and"
5767120,5777840," we keep adding that token to the tokens of the text editor so here's the tokens and we add the token"
5777840,5786880," and we repeat that process until the end uh right so that's basically it so this is the entire re-tokenization"
5786880,5797040," re-tokenization re-tokenization uh cool so we have here so this is the token we don't have a token so we have to"
5797040,5807360," include the lexa in here right lexa in here okay that's cool okay so we're still uh doing the test thing"
5807920,5815440," right so i probably have to get rid of the testing code and just use the actual production code and see"
5815440,5821760," if it still works right so we need to see if it still works okay so everything seems to be working"
5821760,5827840," everything seems to be twerking uh we didn't really break anything yet which is super nice"
5827840,5836560," uh which is super nice so the next thing we need to do so editor when i'm initializing the editor"
5837200,5841840," uh so here's the editor where do i use the editor for the first time so i re-compute the lines in here"
5841840,5851520," maybe what i have to do is i need to first initialize the um what is it called"
5851520,5864000," the free glyph atlas right uh after we initialize the free glyph atlas i take the editor and i set the atlas"
5865280,5869680," uh to it uh to it and now recompute the lines i think that's what we need to do in here"
5869680,5875040," i think that's what we need to do in here okay so"
5875040,5885520," let's recompile and see how it goes so there is a little bit of a concern that i almost forgot about"
5886560,5892880," is that now we never have to directly do cursor plus one um right"
5892880,5900880," because um when we chop a character as we do cursor plus one"
5900880,5911200," we also need to recompute uh the position and stuff like that so i think i need to make sure that i never"
5911200,5914880," call the cursor plus one directly and always do that through the chop character"
5914880,5922240," cursor plus okay so this stuff should never happen in my opinion and this stuff should never happen as"
5922240,5930480," well and this one is never happen as well uh so this thing is happening so we're not modifying this thing"
5931760,5937840," this one within the chop uh chop character this is fine but this one this one is a little bit interesting"
5937840,5947520," okay um so how can we even do that i suppose we can just do something like size ti but this one is"
5947520,5962960," going to be j less than text length uh plus plus j and um it's just lexa chop character l right so we're"
5962960,5969280," just chopping the character one by one uh it's not particularly great but it might be correct so maybe"
5969280,5976320," the chop character should actually accept length like how many of them do you want to chop which is a good"
5976320,5982880," solution actually because i feel like we don't really need to return anything in here i don't think this"
5982880,5987920," thing should return anything right because it's not particularly useful because we always check for the"
5987920,5994880," character first anyway through the l content right so we first check it like that anyway so it doesn't"
5994880,6000320," make it make sense and it would make sense to actually just provide the the length like how many of"
6000320,6007280," them do you want to chop i think it's i think it's reasonable right um i do think it's reasonable um"
6007280,6016880," so and essentially that means i can just wrap this entire thing into into that and it will make it"
6016880,6022880," easier to just say okay so i know the length of the token that i want to chop off i can just pass that"
6022880,6027680," length and forget about it and it's going to update all of the necessary coordinates uh for me"
6027680,6033440," automatically i think that's it's a good thing i really like that okay so it means i have to repeat"
6033440,6040400," this stuff multiple times i don't need to return anything uh okay so here i just check that the l cursor"
6040400,6047200," is less than content uh i could have actually just checked for that a bit earlier in here so i never have"
6047200,6058400," to assert in here uh but i'm a little bit lazy so um get rid of this assert by checking the length of the"
6058400,6066400," chopped prefix up front right so similar to how we do that with the prefix but i feel like i'm a little bit"
6066400,6073680," lazy right now um okay so that updates the metrics that also updates everything in here and that should be"
6073680,6079600," fine okay so let's actually uh go ahead and go through the compilation errors in here uh okay so"
6079600,6087280," when i trim left i can always say just one right so this is going to be just one uh what's the next thing"
6087280,6097440," uh we chopping things by one uh and here we're also chopping by one it would be kind of nice if c had default"
6097440,6104160," parameters so i could do something like by one by default because that's usually what you want to do"
6104160,6115920," uh but it is what it is okay and in here right so that's entirely the reason why i introduce that stuff"
6115920,6123440," i can now do uh text line that's it so because of that it maybe it makes sense to call uh chars but i'm"
6123440,6129920," gonna change that later maybe we'll see and seems to be compiling that's that's cool"
6129920,6138480," uh unused okay is that it it feels like it feels like it's so oh yeah i i need to i still need to get"
6138480,6144400," rid of the uh things that update and cursor yeah for example here"
6144400,6156320," and um alexa chop character l one that's totally fine and here"
6156320,6165200," and then we just don't do this thing all right uh and cursor we can refer to l cursor just to check check"
6165200,6173120," things around but we better not update it right so updating this thing must be done through a centralized"
6173120,6179360," place because it may require updating the coordinates and stuff like that right so i think i think that's"
6179360,6189280," quite important i think that's quite important okay so um i guess that's it so the next step is to"
6189280,6198320," actually go into the renderer right and just render all of the tokens that's what we want to do we just"
6198320,6204560," want to render all of the tokens we have quite a lot of this stuff in here that renders the text right so"
6204560,6213840," which we probably don't even need anymore believe it or not right so we have 73 lines of code that render the"
6213840,6222480," text i'm not really sure if we need that anymore uh so i'm gonna just like factor that out i mean uh"
6222480,6227680," comment it out that's what i want to say not factor that out but comment it out right because what we have"
6227680,6235920," to do now we have to just iterate uh through the tokens right we just need to iterate through the tokens"
6235920,6241360," and depending on the color of the token we just have to render them differently so um to do that"
6241360,6250960," we need to set uh a shader for the text right so let's set the shader for the text"
6250960,6257600," uh and then of course we want to flush that shader afterwards there we go so we're setting"
6257600,6263200," the shader for the text and let's iterate through the tokens uh right so this is going to be like this"
6264880,6276560," uh editor yeah so it's editor tokens count uh plus plus i right and within each individual token"
6276560,6285440," right these are the tokens that we tokenized right uh items i so within the token we have a position"
6285440,6290400," now we have to use that position to render something there"
6292640,6302080," uh so okay go how are we gonna do it i'm already streaming for more than two hours my guts it's kind"
6302080,6308240," of interesting like every time i'm doing anything in even remotely simple with the tokenization it takes"
6308240,6313040," a lot of time for some reason i don't know why even though the the concept is extremely simple it's just"
6313040,6321600," like yeah for some reason it just takes a lot of time um okay so how do we render the text uh so we just do"
6321600,6330720," free glyph measure blah blah blah blah and the way we do that is rather weird we need to keep track of the"
6330720,6336960," position right so we need to save the position uh somewhere here so this is going to be the token position"
6336960,6345120," uh so what do we do token text"
6345120,6356880," token uh text length and here's the position surprisingly that is it"
6359280,6365280," uh it's uh it's just we also have to do that with a different color by the way where do we put the"
6365280,6373520," color uh oh yeah and then we render a solid rectangle uh a solid rectangle with a certain color"
6379040,6389040," it's a selection i'm sorry i'm gonna do it um same with getting up we are from bed in the in the"
6389040,6394400," morning simple process it takes a lot of time for some reason yeah it is kind of similar"
6395840,6404960," um i forgot how do we specify the color uh share for the color shaded for the text"
6404960,6413280," oh yeah here like we specified the color in here right so let's say that i'm going to use the color"
6414480,6423520," white yeah so this is measure i have to use render and here's the color we're just using white color in"
6426720,6433120," okay so talking text it didn't really like the token text uh incompatible pointer type what are you"
6433120,6445120," talking about uh huh so let me find the render line sized yeah so we have to provide"
6445120,6455920," this thing so first comes the atlas then a simple renderer then the text then the length position"
6456480,6461520," and the color makes sense too okay"
6461520,6467920," the fact that it still renders is already great"
6467920,6478000," okay that's cool"
6478000,6484960," oh okay made"
6487040,6494000," so you can clearly see when it didn't update the uh the position of the token properly"
6494000,6498480," i mean it works exactly as i would expect right so it even has the bugs"
6498480,6505760," that i expect uh right with the symbol um when we chop a character all right when we chop a character"
6505760,6510160," we have to sort of update it like that but something something's weird"
6511840,6520320," yeah that's that's that's basically the problem uh we have to set the x of the lexa that's what we forgot"
6520320,6527920," uh right we have to set the x of the lexa but it already like recognizes the tokens right which is"
6527920,6531520," super nice yeah there we go so now it just positions them properly"
6534160,6542480," uh okay uh okay so oh it doesn't update the camera as well right so this is another problem uh another"
6542480,6547600," problem uh another problem which i can probably fix for now with a weird fix but nonetheless"
6548480,6564640," um so um so max lan line len right so this is a max line len and so for now it's always going to be equal to"
6565280,6578080," yeah uh fix temporary zoom epic zoom camera action so let me just do it like that"
6580080,6588160," okay uh okay uh so yeah so essentially what we have to do depending on different tokens"
6588160,6594560," we have to provide different colors that's it so we can already recognize the tokens"
6594560,6601280," uh so that's what's cool about all that so here's the color right uh color and"
6606160,6613040," if for instance token kind is equal token uh pre-proc we can set it to something else"
6613040,6617920," we can just set it to something else for instance uh we can set it to red"
6617920,6625280," zero zero one right if the token is that uh the tokens are going to be just with this core"
6625280,6630960," so let's see how it works so here's the regular thing but then i define include right everything up"
6630960,6634720," until the end of the string is going to be red and then everything's going to be finding again"
6636160,6641680," so for let's introduce something even more interesting right let's introduce so-called"
6641680,6649760," keywords right because that's what we wanted to highlight all along um right so how we're going"
6649760,6658560," to be introducing them let's introduce uh token keyword here's the token keyword uh in alexa"
6659920,6668160," we have to also define the name for this thing uh correct so this is going to be key word and this"
6668160,6675360," is also going to be keyword the thing about keywords is that there are symbols right there are symbols um"
6675360,6684000," but there are special symbols what i'm thinking is that as soon as we um as soon as we understand as"
6684000,6688800," soon as we parse the symbol what we want to do we want to compare it with one of the keywords and if"
6688800,6694320," it's in the list of the keywords we're going to change the kind to the keyword you know what i mean"
6694320,6702080," uh right so we already have a list of keywords here they are so here are the keywords uh i might as"
6702080,6708160," well actually just copy paste this entire shit and move it into the lexa right now we're going to have the"
6708800,6718240," uh the keywords so what we want to do we want to um after we you know took the uh symbol we want to iterate"
6718240,6727760," through the keywords uh for size i less keywords uh keywords count i think that's what it is"
6732400,6739840," so and uh let's just go ahead and compare things all right so but the thing is a little bit more"
6739840,6750240," complicated so we need to have a keyword length so str len keywords i so we know the length right so we know"
6750240,6762320," the length in here now if keyword uh length keyword length uh is equal to the token text length that means"
6762320,6769360," they're probably equal to each other and we can use something like maybe mem cmp to actually do that"
6769360,6774720," right so the problem is that we're comparing null terminated string with a sized string that doesn't"
6774720,6781200," have a new termination and because of that we have to use mem copy uh mem cmp not mem copy so"
6781200,6791280," we're going to take the keywords i and the token text and we're going to provide the keyword length and if it's"
6791280,6800080," equal to zero we found the keyword and we basically say okay this token is a keyword and we break out of"
6800080,6806240," the loop right so essentially the idea is the following we successfully parts the symbol we check"
6806240,6812560," is it a part of the any keywords if it is we reclassify this thing to a keyword and now we can"
6812560,6817680," distinguish keywords from a regular symbols and now we can highlight them differently so that's kind of"
6817680,6826240," cool right hopefully we'll see we'll see so recompile everything uh recompile everything okay so this is the"
6826240,6834480," preprocessor uh and then uh here with that okay so let's go to the editor uh let's go to the editor and"
6835920,6848560," we can even start doing a switch right so token kind uh if you have token preproc so uh red for a"
6848560,6853360," preprocessor is kind of weird but i'm gonna keep it for now i'm gonna just keep it for now we're gonna"
6853360,6861680," change it later if it's a keyword we're gonna use yellow corner okay so this is a simple table of like"
6861680,6868640," colors so this chunk of code is basically the color theme of the text editor right because we are signing"
6868640,6874480," different colors to different tokens and you can even maybe create a simple text format which is"
6874480,6880640," basically name of the token it's color name of the token it's color right and you can just parse it or"
6880640,6886480," something like that or maybe json people like json people keep asking me can you do the json for some"
6886480,6892480," reason it's important for people to use a specific json format i don't know why uh i personally don't"
6892480,6901280," care like computers don't care either the only people who care the uh the only the only one who cares"
6901280,6906400," about the specific format is humans for some reason okay so we we don't have these things so maybe i'm"
6906400,6912320," gonna do default in here and just like an empty thing oh it's a web oh that explains it okay it's it's"
6912320,6919040," web developers it's just web developers being web developers okay so now let's put some keywords"
6919040,6939760," oh look at that right so you have int main but if you remove a space from here it's a single word now"
6942320,6951840," is it cool isn't it cool is it not cool that that that that holy fucking shit and it works properly"
6951840,6958960," because it tokenizes shit uh we can try to open the source code of this thing oh look at that this is so"
6958960,6966400," cool this is bash file right this is bash file but we're using the tokenizer uh c tokenizer and it kind of"
6966400,6972720," works to some extent right it kind of works to some extent at least it recognizes the preprocessor thingy"
6972720,6978240," uh oh the this selection actually doesn't work anymore right the selection doesn't work but i think we can"
6978800,6992160," we can do something about that so let me okay so i'm gonna put this thing somewhere here yeah so now we"
6992160,7001200," should have selection um now we should have selection if i put some shit in here yeah okay so that's fine it's not"
7001200,7008400," really that difficult boom yeah that's so fucking cool now let's open the source code of the editor"
7008400,7015440," itself uh within the text editor okay so we we can see the preprocessor shit which is fine the comments"
7015440,7020160," are not tokenized properly uh this is probably something that we want to address at some point but"
7020160,7027520," the keywords are fine as far as you can tell so static some other shit uh maybe we should tokenize"
7027520,7039840," comments let's give it a try i'm gonna go ahead and tokenize comments uh lexa dot h uh comments all right"
7039840,7046720," and it's kind of similar to tokenizing preprocessor right now it's only that the preprocessor doesn't"
7046720,7059840," can handle new lines uh pre uh proc should also handle new lines so in here we have to do lexa"
7059840,7074160," starts with slash slash right and then what do we want to do we want to do lexa chop character and we want to"
7074160,7080560," chop two characters all right we also want to set the kind to comment right so this is the comment"
7080560,7087840," and while we don't have until the end of the line we keep chopping the characters we just keep choking"
7087840,7092960," chopping the character and that's it actually that's literally it so what we're going to put as a comment"
7092960,7105360," in here uh what we're going to put as a comment um so comment uh usually i i use like an orange color"
7105360,7113120," in here or a brownish color so maybe let's put it like half of this thing i think maybe it's going to"
7113120,7123360," do something uh all right so we have some code right so here's the code and then i want to comment out"
7123360,7130000," something it seems to be working but something went terribly wrong in here as you can see yeah"
7131280,7139040," i don't know what exactly but uh yeah oh that's oh i think i know why i'm an idiot uh i should"
7139040,7145280," have not removed these two things in alexa because it would have worked automatically anyway i think"
7145280,7151440," yeah it's kind of weird that i don't have to do that but sure sure not"
7157600,7165280," right so yeah that's that's fine now so and the reason uh it works out magically that's that's so"
7165280,7172320," cool uh okay so let's actually open the code so here's the pre-processed here's the"
7172320,7178960," comments you can clearly see the comments now all right the comments are properly handled and all right"
7183760,7191760," it works so we can comment out and as you can see it commented out so it's cool how if you have like"
7191760,7198160," a proper tokenizer like coloring the text uh becomes trivial right because it's basically the condition"
7198160,7203360," uh do we have numbers we can also try to support numbers at some point but"
7203360,7210000," that's cool we don't support strings we can also try to support them but supporting them means"
7211520,7218080," uh supporting escaping but i don't think we use much escaping here at all right i don't think we"
7218080,7225280," use much escaping here okay let's try to maybe use some specific cores the core them right use some"
7225280,7232640," specific core of them uh the problem with the coding in my case is because all the cores are four"
7232640,7239360," dimensional vectors like floating points vectors right so i need some sort of a function that would help me to"
7239360,7245840," convert hexadecimal codes that because i want to what i want to do i want to take the core theme of emacs"
7245840,7254880," and use it there right that's what i want to do um so but all of the colors in here uh all right so rexium"
7254880,7262640," group duck uh yeah there are hexadecimal values right so as you can see there are hexadecimal values"
7263440,7268160," so i need to convert that to um floating point vectors and stuff like that"
7268160,7278800," does the tokenizer run for every character type yes and this is on a 10 years old laptop"
7278800,7287440," this is on 10 years old laptop from which i'm also streaming computers are insanely fast you have no idea how"
7287440,7294080," fast computers are it's fucking insane especially when you get rid of most of the abstractions"
7294080,7298560," most of the redundant shit and just take the pure computational power of the computer"
7299120,7311680," it's fucking insane right um all right so what do we have"
7311680,7321920," uh to do so where are we gonna pull this kind of stuff i wonder by the way um i'm actually doing two"
7321920,7328400," tokenizations per character per character type all right because first i tokenize by lines"
7328400,7334640," and the second tokenization now we added the second tokenization for four colors so my usual test that"
7334640,7342000," i like to do is to have like 100 000 lines and see how it performs with that well it's not going to work"
7342000,7349040," for that specific editor because we also have to do the rendering okay so let's actually see if it's going"
7349040,7358800," to kill my computer right oh it's it's not gonna the renderer is going to crash it even further yeah like"
7358800,7368480," even before that god damn yeah so because a renderer is kind of limited so it cannot render more than"
7369360,7377680," like six hundred thousand of vertices so if i try to render more it's going to just basically crash it"
7377680,7384240," so this is in safety value i'm going to work on extending it and see how how fast we can go anyway"
7384240,7389920," i'm not worrying about the performance right now i'm just figuring out what i'm what i need to do"
7392720,7402480," okay so i need a simple function i need a simple function which takes the hex code right so hex to vec"
7402480,7408560," for f right so you insert it to t color"
7408560,7412560," very simple function"
7418000,7426080," and what we're going to do so we're going to start with red so red we're going to parse it the"
7426080,7432880," following way because i'm going to be typing it manually red red green blue a so that means i have"
7432880,7441360," to shift it by three bytes three multiply by eight so i'm shifting there and then i'm masking it uh taking"
7441360,7446960," this entire thing so i've got red then i want to take the green it's kind of similar by shifting"
7446960,7454320," by two bytes then blue by one byte and then a is by zero bytes right i'm just masking it like that"
7454320,7464560," so i have rgba uh cool so to convert r to value from zero to one what i have to do i have to divide it by"
7464560,7471920," 255 but in floats right and that's basically the result uh all right so the result is this"
7471920,7486160," result x is going to be this y z uh is it i don't remember actually uh what are the"
7487920,7498000," it's w okay so it's done so and then we just return this thing cool cool cool cool cool"
7498000,7504960," now what i can do is"
7504960,7514240," switch token so here uh i can just assign the point thing so we have a preprocessor"
7514880,7522000," and for the preprocessor what do we use for the preprocessor preprocessor we're using darker quartz"
7522000,7528720," quartz and the value of the darker quartz is this one so this is what we use for the preprocessor"
7528720,7531680," so that means i can go"
7531680,7538560," and just convert it hex to vector f and there we go"
7540160,7548160," i want to use something like this so this is preprocessor uh for the keyword we use the yellow"
7548160,7554240," color and the yellow is this one so now i can just like directly take those things uh and use them"
7554240,7565200," hex to the back to f uh right x like this cool comment uh as far as you know comment is brown uh this"
7565200,7575840," brown color in here hex to back to f uh cc boom okay so we're already using colors from the uh from my"
7575840,7583120," theme it's not really my theme but i adapted it to the uh color theme of thingy okay so i was complaining"
7583120,7591600," about unknown back for f in a common h okay so what i just need to do i just need to include la which"
7591600,7601600," stands for linear algebra uh it also doesn't know anything about std int so i mean"
7603040,7610240," what does it say unknown type you insert it too so that means i want to include std int"
7610240,7621920," because there are type depths if i'm not mistaken yeah okay okay so this is this is cool actually right"
7621920,7626320," so this is pre-processing uh huh then"
7626320,7632080," uh so the background is kind of off"
7632080,7640080," okay uh to do hello world"
7642480,7650560," yo this is so cool holy shit okay so where do we set the background uh yeah the background is off okay"
7650560,7658960," so let me try to do the following thing uh back for f background and i know for a fact that the background"
7658960,7664400," is this right um let's go bg"
7664400,7677920," um bg x bg y bg z bg w so we set the clear color like this"
7679520,7686880," uh okay okay okay can we compare this shit now"
7686880,7693360," okay well i mean it doesn't handle this part"
7693920,7697760," i know them it doesn't handle this part but it's kind of"
7697760,7704400," it's so cool"
7704400,7710400," so it does look now like my editor"
7710400,7716400," so we can have"
7719200,7719760," print"
7719760,7721760," print hello world"
7721760,7723840," all right so print hello world"
7723840,7728720," print f strings we're not supporting strings god damn it"
7728720,7729600," okay"
7729600,7739200," uh oh let's take a look at the this thing uh the rainbow doesn't really look that great on"
7739200,7741680," this background"
7744880,7747760," okay okay just a second uh so you want to try this on"
7747760,7753840," with the high refresh rate monitor just just a second i'm going to finish i think the thing we"
7753840,7758000," need to do we need to add support for the strings all right so we're not going to have the"
7758000,7762320," what is it called oh my god"
7762320,7767920," the escaping right but that's fine i can edit layer"
7769120,7779680," uh okay so if l content l cursor is equal to this thing"
7779680,7786160," um what why why emacs okay"
7786160,7791760," um string"
7793600,7798960," token string should also handle uh escape sequences"
7798960,7805760," and uh one of the things i probably want to do here as well is just chop one"
7805760,7810720," then while i'm going to keep copy pasting this thing"
7810720,7818800," while this thing not equal to this thing again we're going to keep doing that and then we're going"
7818800,7819360," to return"
7819360,7825200," all right i think that that's that's that's it actually"
7825200,7830800," okay it is working and now in the editor"
7830800,7837280," we're going to have a string and the code for the string"
7840720,7850400," is this it's green right it is green so now let's go ahead and try to write a hello world"
7850400,7852400," let's write a hello world"
7852400,7856560," so it's gonna be that"
7856560,7861520," so this is that print f"
7865520,7870160," uh hello world"
7870160,7875760," right so that didn't really work well but i wonder why"
7875760,7893600," uh okay so let me think let me think let me let me think why is it like that though is that because of"
7893600,7897120," the new oh i think this is because of the new line yeah"
7897120,7903680," not equal to this thing and not equal to the new line"
7903680,7906400," first tripod yeah"
7906400,7912080," i think this is because of the new line although it is not particularly correct to lex it right now"
7912080,7918880," like that but we're not lexing to compile anything we're lexing specifically to uh highlight things"
7918880,7922160," and this is kind of a different purpose and this is kind of a different purposes for the lexing in my opinion"
7922160,7924720," in my personal stupid opinion"
7926000,7943920," So printf ""Allow World"". So..."
7943920,7953440," Don't particularly know what is so wrong with all of that."
7956000,7960000," So we set the position in here."
7960000,7968000," We set the position in here."
7986000,7992000," Ooh, yes. That explains this shit."
7992000,7994000," Okay, brother."
7994000,7996000," I feel like..."
7996000,8002000," I feel like we have to compute the length differently."
8002000,8010000," Something like ""token_text_len"" should be equal to"
8010000,8018000," ""el_cursor"" minus the beginning, but we also have to keep track of the beginning, though."
8018000,8018000," Right?"
8018000,8032000," So I can do something like ""el_content_el_cursor_pointer"" minus ""token_text""."
8032000,8038000," And that way I never have to actually increment length, like this kind of thing."
8038000,8042000," And since they're one byte, so that should be fine."
8042000,8044000," But I mean, it's pointless."
8044000,8058000," Oh, I'm an idiot."
8058000,8064000," Though, I actually did it for the comments, which might not be a bad thing for the comments."
8064000,8066000," So I'm gonna keep it like that."
8066000,8070000," I feel like I have to do that for everything."
8070000,8075000," For all of these stringy things."
8075000,8081000," So by stringy things, I mean right now preprocessor, comments, strings."
8081000,8085000," Like everything that has this variable weird length."
8085000,8088000," I think I have to do this kind of stuff for all of them, right?"
8088000,8091000," So essentially, I know the beginning."
8091000,8093000," And I know where it ends."
8093000,8095000," And I just subtract one from another."
8095000,8098000," And that way I don't have to worry to forgetting to increment something."
8098000,8099000," You know what I mean?"
8099000,8102000," So that's kind of a good thing."
8102000,8106000," That's kind of a good thing."
8106000,8111000," Okay."
8111000,8126000," Okay, so this works."
8126000,8128000," This still works, right?"
8128000,8134000," And that was kind of weird why it was highlighting those things."
8134000,8140000," It looked kind of nice, but I mean, this is not what I wanted."
8140000,8145000," At the end of the day, at the end of the day, that's not what I want."
8145000,8146000," Uh-huh."
8146000,8147000," One, two, three, four."
8147000,8148000," Return."
8148000,8149000," Zero."
8149000,8150000," Right."
8150000,8152000," So hello world."
8152000,8154000," And then I'm gonna do printf."
8154000,8155000," Hello."
8155000,8156000," World."
8156000,8157000," New line."
8157000,8158000," Boom."
8158000,8161000," Isn't that poggers, my dudes?"
8161000,8162000," Isn't that poggers?"
8162000,8165000," I think that's pretty fucking poggers."
8165000,8170000," So let's go ahead and commit that."
8170000,8171000," I suppose."
8171000,8172000," Let's go ahead and commit that."
8172000,8174000," So this is basically it."
8174000,8180000," And we have a mechanism to which we can keep adding more and more different kinds of tokens."
8180000,8181000," Right."
8181000,8182000," Right."
8182000,8185000," And eventually implement the whole tokenizer and stuff like that."
8185000,8189000," We can color open and close patterns, for instance."
8189000,8190000," Right."
8190000,8193000," So we can go ahead and color all of these things."
8193000,8194000," Right."
8194000,8197000," Not everything in here is particularly useful, I think."
8197000,8200000," But maybe some of these things are useful."
8200000,8201000," So let's see."
8201000,8202000," All right."
8202000,8208000," So there's some stuff that probably needs to be cleaned up in here."
8208000,8213000," Because, for instance, we don't need this stuff anymore."
8213000,8214000," Right."
8214000,8218000," Rendering based on substrings and stuff like that."
8218000,8223000," I'm gonna keep it in here because there's some things that I have not finished yet."
8223000,8225000," I would like to finish them."
8225000,8228000," I hope I didn't remove anything important."
8228000,8229000," Yeah."
8229000,8230000," Okay."
8230000,8232000," So I didn't remove anything important."
8232000,8234000," Let me see."
8234000,8238000," Let me also open this thing in here."
8238000,8239000," Right."
8239000,8242000," So here's the code."
8242000,8245000," And it supports the strings."
8245000,8249000," It's gonna break if I try to do something like this."
8249000,8250000," As you can see."
8250000,8251000," Right."
8251000,8256000," So the proper tokenizer has to take these kind of sequences into account."
8256000,8257000," Right."
8257000,8260000," And it should continue tokenizing this thing until the end."
8260000,8262000," But it's relatively easy to add."
8262000,8264000," But I'm not gonna do it right now."
8264000,8265000," So, yeah."
8265000,8266000," That's pretty cool."
8266000,8268000," I really like where it's going."
8268000,8270000," And it feels like my text editor."
8270000,8271000," Almost."
8271000,8276000," Maybe we can even use Yozefka or something like that."
8276000,8278000," So, let me find."
8278000,8282000," So, we even have something like fonts."
8282000,8283000," Oh, yeah."
8283000,8284000," Here's Yozefka."
8284000,8285000," Term."
8285000,8289000," So, what kind of stuff do we have?"
8289000,8290000," We have a regular."
8290000,8291000," Oh, regular ."
8291000,8292000," Okay."
8292000,8295000," I'm gonna copy paste Yozefka to here."
8295000,8296000," Right."
8296000,8300000," And I'm going to just use it."
8300000,8302000," I'm in the text editor."
8302000,8303000," So, Victor."
8303000,8304000," Uh-huh."
8304000,8305000," Where is that?"
8305000,8306000," Okay."
8306000,8307000," Oh, bruv, bruv."
8307000,8308000," Okay."
8308000,8309000," I wonder if it's going to work."
8309000,8311000," We're about to find out."
8311000,8326000," Where is that? Okay. Ooh, bruv bruv. Okay, I wonder if it's going to work. We're about to find out. It does work. Look at that."
8333000,8335000," It's so cool."
8360000,8371000," Yeah, so there's a little bit of weird stuff with the cursor alignment. I'm aware of that. I'm just like, don't care about it right now."
8371000,8378000," Yeah, that's cool. Man, this is so cool."
8380000,8385000," So if we go to here, I think I'm going to leave a . I think it's kind of cool."
8385000,8391000," This is a shell. Ooh, yeah, now the strings work in shell as well."
8391000,8398000," There we go. So the shell script. You can already kind of use it because a lot of languages use double quotes for strings anyway."
8398000,8408000," All right, so it kind of works for bash as well. But in bash, we don't have fi, right? So we could probably add fi to list of keywords."
8408000,8414000," We can probably make a configuration option where you could say, okay, for this language, these are the keywords."
8414000,8427000," And it's going to basically treat this array as dynamic array. And maybe user can just add or remove things from here, like for different forms, for different systems, different languages and stuff like that."
8427000,8429000," Right? Just like different ideas."
8432000,8451000," Oh, yeah. So the previous highlighting, yeah, this is actually kind of funny. So the previous highlighting considered combination of characters door as a separate keyword because you had the keyword do and or, and they were basically glued together to form a door."
8451000,8461000," We can even take a look at that, right? So I think if I stash whatever I have in here, we have a previous version, right? And yeah."
8461000,8473000," So a new keyword in C just dropped called door. So our new tokenizer, like highlighting system actually takes that into account. So you can't have door anymore."
8473000,8482000," Right? So you can have do or, but you can't have door. So only that."
8482000,8490000," So that's what it was all about, my friends. That's what it was all about. So let's do a committee committee."
8490000,8495000," And maybe possibly even pushy-pushy because people are urging me to commit that and push that."
8495000,8498000," I'm going to also commit this thing. Okay."
8498000,8504000," Implement Lexa-based syntax highlighting."
8504000,8507000," There we go. I'm going to push that right into the repo."
8514000,8519000," What's the RAM usage for your text editor? Who cares? Just buy more RAMs. It's 2023. Come on."
8519000,8522000," So it's dirt cheap."
8522000,8523000," Freaking dirt cheap."
8523000,8540000," So almost ready to work on the editor itself. Yeah. So before I can use this editor to develop itself, I think I need to fix the problem with the camera."
8540000,8544000," Right? Because the camera is kind of like vomit inducing."
8544000,8548000," I am aware of that. Right? So I'm aware that's a little bit of vomit inducing."
8548000,8553000," And I need to think about like a better AI for the camera."
8553000,8558000," I don't know. That's the trendy word everyone uses these days regarding like whatever it means."
8558000,8564000," Right? We need to have a better AI for the camera so it's not that vomit inducing."
8564000,8576000," So then I can work on that. So for instance, I don't like the fact that the camera is centered at the cursor because you have like an empty half of the screen."
8576000,8581000," It's kind of cool that it follows you around, but then half of the screen is not visible."
8581000,8586000," It's cool when you only start typing. You know what I mean? When you just do that."
8586000,8590000," It's cool when you have nothing. It looks cool."
8590000,8600000," But as soon as you have something and that something is actually significant enough, the camera should actually kind of like minimize the amount of empty space or something like that."
8600000,8607000," You know what I mean? Right? So the behavior of the camera should be more sophisticated than it is right now."
8607000,8610000," So to make it look interesting and good and stuff like that."
8610000,8619000," For instance, for now, it's kind of totally fine that it's centered at the cursor, but then later as you have more code, it becomes like unusable."
8619000,8629000," Right? Because if you open like something actually reasonable, right, so the source code itself is just like I don't see half of the code and half of the screen is empty."
8629000,8634000," How is that cool? It's not cool. It's only cool when you have no code."
8634000,8641000," It's a text editor that makes your code look cool when you have no code, right?"
8641000,8646000," That's pretty interesting."
8646000,8652000," It already looks kind of nice with the highlighting and stuff like that."
8656000,8659000," So I had also a couple of interesting ideas for animations, right?"
8659000,8667000," For instance, it would track, keep track of the current token that you're currently typing out."
8667000,8672000," For instance, like it keeps track of this current token and this token is symbol right now."
8672000,8681000," But as soon as this token becomes keyword, it would just like make the token sort of explode with particles."
8681000,8688000," It's like, oh, you made a token, you completed the fucking sequence, holy shit, an achievement pops out or something like that."
8688000,8699000," And for instance, it would keep track that you're currently on a keyword and you remove a character that transitions that from a keyword to being a symbol."
8699000,8702000," And it's not going to go to white right away."
8702000,8704000," It's going to slowly fade out."
8704000,8707000," You lost the power of the keyword."
8707000,8708000," It's not a keyword anymore."
8708000,8710000," And it's just like, it just fades away."
8710000,8714000," So just a regular, regular, boring symbol."
8714000,8717000," So that's basically the idea."
8717000,8722000," It's just like there's particles and particles have, have a gravity and they just fall down."
8722000,8723000," It's like, holy fucking shit."
8723000,8725000," I just guessed a keyword."
8725000,8726000," My God."
8726000,8730000," So that's kind of weird shit I have in my head."
8730000,8731000," I don't know what shit I have in my head."
8731000,8732000," I don't know."
8732000,8733000," I don't know."
8733000,8734000," I don't know."
8734000,8735000," I don't know."
8735000,8736000," I don't know."
8736000,8737000," I don't know."
8737000,8737000," I don't know."
8737000,8738000," I don't know."
8738000,8739000," I don't know."
8739000,8740000," I don't know."
8740000,8741000," I don't know."
8741000,8742000," I don't know."
8742000,8743000," I don't know."
8743000,8744000," I don't know."
8744000,8745000," All right."
8745000,8748000," So I think that's it for the day."
8748000,8750000," I'm already streaming for three hours."
8750000,8751000," Holy fucking shit."
8751000,8753000," How am I supposed to put that on YouTube?"
8753000,8755000," Nobody's going to watch three hours on YouTube."
8755000,8761000," I mean, people barely can watch five minutes of YouTube shorts this day."
8761000,8762000," Right."
8762000,8766000," So how do you expect people to watch three hours of just me rambling?"
8766000,8767000," Anyway."
8767000,8773000," We need RTX render for this editor."
8773000,8776000," Well, I don't have a graphics card for RTX with RTX."
8776000,8778000," Probably will never have."
8778000,8790000," Deadmau5 is streaming something on a science and technology section."
8790000,8791000," What the fuck?"
8791000,8795000," Oh, he's also a programmer, isn't he?"
8795000,8800000," He's just like writing his own shaders for like effects and whatnot."
8800000,8801000," I don't know."
8801000,8803000," I don't know what he's doing with that."
8803000,8804000," Yeah."
8804000,8805000," I think."
8805000,8806000," I think."
8806000,8807000," I'm not sure."
8807000,8808000," I'm not 100% sure, but maybe."
8808000,8813000," Should we rate him?"
8813000,8814000," I don't know."
8814000,8817000," Probably not."
8817000,8819000," Anyway."
8819000,8820000," The..."
8820000,8821000," Yeah."
8821000,8822000," It's some sort of a shaders."
8822000,8823000," Yeah."
8823000,8824000," Some shaders shit."
8824000,8825000," Okay."
8825000,8826000," Anyway, that's it for today."
8826000,8828000," Thanks everyone who's watching me right now."
8828000,8829000," Really appreciate it."
8829000,8830000," Have a good one."
8830000,8832000," And I see you all next time."
8832000,8833000," Love you."
8833000,8833900," Love you."
