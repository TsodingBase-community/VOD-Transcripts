start,end,text
720,5860," Are we live? Looks like we're live. Hello everyone and welcome to yet another"
5860,11720," recreational programming session with Azuzi. How about that? Let's make a little bit of an"
11720,19960," announcement and officially start the stream. So yeah, let's do the usual red circle, right?"
19960,26240," Red circle live on Twitch. And what are we doing today on twitch.television website?"
26240,33160," Today, we are implementing alternative neural network visualization."
33160,41180," I'm going to give the link where we do know that on twitch.tv slash Azuzi and I'm going to ping"
41180,46760," everyone who's interested in being pinged. And there you go. The stream has officially started."
46760,54040," So today we're going to continue working on our deep learning framework in PRC called nn.h. You can"
54040,59340," find this thing here. I'm going to copy paste it in the chat for people who are watching on YouTube."
59340,64760," It's going to be in the description, hopefully. Where is the description? I didn't even open the"
64760,71360," description file. So here it is. Yeah, it's going to be in the description. Right. So and let's take a"
71360,77560," look at what we have so far. We have a couple of demos you can run, right, that are implemented with"
77560,82680," this deep learning framework. And part of the framework that we have in there is actually"
82680,89640," some sort of like a UI system, right, that allows you to sort of like throw some widgets together"
89640,96820," just to visualize different aspects of the state of your model, right, and stuff like that. So one of the"
96820,103480," models that we have is image to nn, where you have to provide two images. So we have some like subset of"
103480,109160," nice database, we can provide two numbers in here, just a second, I won't be able to see this kind of"
109160,114120," stuff. So training eight. And this is the second one. And if you run it like this, this is basically what"
114120,120440," you have. This is a simple neural network that is trained to behave like, well, I mean, like two images"
120440,126040," in here. So I suppose to actually use six in here instead, there we go. So now we have two separate images,"
126040,132440," right. So this is the images that it's supposed to behave as. And this is its current behavior,"
132440,138360," right. As soon as we start training, as you can see, it starts to like slowly converge towards behaving"
138360,144040," like these two images. And then what you can do is basically, you know, interpolate between these two"
144040,150120," images. So we do that with neural networks, right. And so in the middle, you can see the actual"
150120,156200," visualization of the neural network that we use for that specific thing, right. That's like"
156200,161320," literally the entirety of the state of the neural network that we use for that. It's not really a"
161320,167800," state, but it's specifically visualization of the weights and biases of the neurons for this entire"
167800,176040," thing. And as you can notice, it's fucking useless, actually, right. So essentially, purple means a"
176040,182120," negative value, and green means a positive value, right. And gray obviously means something like in"
182120,188840," between, it's zero, right. So basically, like this bias is dead, right. And because this is a fully"
188840,195160," connected neural network, each neuron is connected to every neuron to the next layer, it becomes a huge"
195160,202200," mess. Like, what the hell is this? Like, how am I supposed to even see anything useful in here? It was"
202200,208680," okay when we had like very small models, right. For example, Zor, right. So this is a very small,"
208680,213400," simple model, and you can clearly see how things are going on in here, right. And it's like, yeah,"
213400,219320," it's useful, right. So these are the inputs, this is like a hidden layer, this is the outputs,"
219320,224920," here are the positive connections, here are the negative connections, and so on and so forth. It makes"
224920,228920," sense. But as soon as you have something more complicated, it's just like, what the hell is that?"
230120,235800," And the more complicated it becomes, the more useless it becomes, actually, right. So if we go"
235800,243240," to image2nm, right, and we add more layers in here, right. So let's actually make it a deep,"
243240,249480," dark neural network, right. And that will require recompilation of this entire stuff, right."
249480,257560," So it becomes deeper, and like, you can't really see anything useful in there. And that's a huge problem"
257560,264680," that I've been ignoring for quite some time, because at least this entire thing serves as a pretty picture"
264680,270040," to show on the stream. And showing pretty pictures on the stream is very important, because that's why"
270040,276120," we are programming. Aren't we? Like, we're not programming to just see some numbers on the screen,"
276120,281960," we want to see some things moving around, because it feels like magic. That's literally the reason we all are"
281960,290200," programming to make, you know, to make our computers do fart noises and whistles and stuff like that."
290200,295400," We feel like magicians and stuff like that. So that's why it's very important to have something cool on the screen."
295400,303080," Right. But here's an interesting thing. This visualization, this visualization is not that useless."
303800,311000," On one of the previous streams, when I was exploring my mistake that I made during the explanation of"
311000,317000," backpropagation, I noticed that this kind of visualization is useful, is useful to demonstrate"
317000,327480," under utilization, under utilization of some parts of the neural network. Right. So as you can see,"
328120,333240," when I'm not using the traditional backpropagation approach, you can instantly see that this part"
333240,338600," of the neural network is underutilized. And this part of the neural network is overutilized."
338600,345000," Right. So, and that's kind of a problem. Right. So that's kind of a problem. And you can instantly see"
345000,353640," that on the visualization. Right. So that means these kind of visualizations are useful. Right. So, and I was"
353640,361000," actually thinking, can I make it, you know, not as much of a mess, not as much of a mess, but still"
361000,367240," retain its usefulness, uh, when it comes to just instantly seeing what parts of the neural network"
367240,375080," are overutilized or underutilized and stuff like that. And I think, I think I came up with a pretty"
375080,381400," interesting idea. So let's actually, let's actually, uh, take a look at this very simple example. Right."
381400,386200," Let's take a look at the very simple example and I'm going to call it simple. I don't know. Right."
386200,393960," So I just want to start like over, uh, right. And here is a simple application in here. Right. So here"
393960,401800," is the simple application. And if I try to print something like, hello, uh, semen, uh, right. And"
401800,407560," then let's just build this entire thing. So this one is going to clank simple, simple.c, and then I'm"
407560,413560," going to run this entire thing. And there you go. It says, hello, semen. So let's plug in our neural"
413560,419720," network, uh, framework. Right. So it's going to be nn.h. Uh, right. And we also have to define"
419720,425320," nn implementation, right. And then implementation. And I'm going to rebuild this into, I think,"
425320,431160," of course, it tries to use, uh, a bunch of, uh, things, uh, which is kind of weird. Um, well,"
431160,436600," I mean, I implemented, oh, I just need to link all of that with the math library. Yeah, that's right."
436600,442680," So I need to link. Yeah, there we go. So now it works. So let's allocate a simple neural network,"
442680,449160," right. So let's do nn. And I'm going to do nn log. And what I have to do here, I have to provide the"
449160,455960," architecture and architecture is basically a sequence of integers. It's a sequence of integers. And these"
455960,462920," integers are the sizes of each individual layer. So we can say that input layer has two neurons,"
462920,468920," right? So we have two inputs. Then the hidden layer may have three neurons. Then the next layer"
468920,475000," can have four neurons, uh, right? Four neurons. And the next layer is going to have a two neurons."
475000,481560," So, and this is the architecture of our neural network, right? So, uh, we described that in,"
481560,488280," in the terms of like, uh, the sizes of the layers, right? So we feed that architecture into an analog."
488280,492840," And also we have to provide how many numbers we have in here. So we have to do array lengths to get the"
492840,497880," length of that specific array. And that thing should, uh, allocate that neural network for us,"
497880,503320," right? So, and we can also print this entire thing, right? And there we go. If we try to run this"
503320,509640," entire thing. So this is a neural network and it consists of a sequence of matrices, right? So it"
509640,517080," consists of a sequence of matrices, which are actually pairs of matrices. So the first matrix is the weights"
517080,522520," of the first layer, right? All of the weights of the first layer. And this one is all of the biases"
522520,528760," of the first layer. And this is basically the, all of the weights of the second layer and so on and so"
528760,533400," forth. So all of that is zero initialized, obviously, right? All of that is zero initialized. We can"
533400,537800," actually randomize this entire thing to make it a little bit prettier, right? Let's actually fill it"
537800,542920," with, uh, values from minus one to one and all of that thing is going to be, you know, randomized and so"
542920,547800," on and so forth, right? So it looks a little bit better. It looks a little bit interesting. So"
547800,556200," essentially, um, what all of that means, right? Uh, what all of that means, uh, maybe it would be nice to"
556200,563880," actually see, uh, this neural network as well, uh, right? Maybe it would be nice to visualize it"
563880,570280," somehow, but I'm not sure if I want to start, uh, RayLib thingy, right? But maybe it's worth actually"
570280,576440," starting the RayLib thingy. So let's actually quickly do that. Uh, right. I'm going to include RayLib, uh, super"
576440,583240," quick, uh, right. And of course it doesn't have a RayLib. Uh, so let's go into the build, right? So this one"
583240,590680," is going to be essentially the build, uh, and let's put a simple in here, right? And, uh, if I try to"
590680,594840," build this entire thing, I think it's, I think it's still going to complain about, no, no, it's actually"
594840,600840," fine because I'm, I run everything in the correct environment, right? So which is super nice. All right."
600840,609720," So in here, what we can do, uh, we can, uh, initialize the window, right? We need to window, um, so 800 by 600."
609720,615080," So this is a simple thing. Uh, and do I want to do anything else? I think no, right? So let's actually"
615080,622760," start, uh, the event loop. Should a window, uh, should close. I don't quite remember. Image to an end."
622760,631160," Uh, yeah. Window should close. Window should close. While window should not close, we begin drawing,"
631160,637560," we begin drawing, and then ending drawing, right? And also let's actually clean the background with"
637560,644120," maybe black color, right? So this is going to be black color. And let's actually render our neural"
644120,649960," network, right? So I'm going to go to nn.h, and I think it was something like gym, uh, render, yeah,"
649960,656760," gym, render, and then, and, uh, this thing accepts the neural network that we just allocated, and the"
656760,661320," rectangle within which we want to render all of that. So what I want to do, I probably want to render"
661320,666760," within, uh, the window itself. So let's actually factor out, uh, the width and height of the window,"
666760,672920," right? So something like this. So this is going to be height. So this is width. This is height. Uh,"
672920,679800," right. And let's actually use the collateral, right? Uh, and let's put the following thing. So we're going to"
679800,685240," start at 0, 0, which is like the, the left top corner, and then wh, and there we go. So that thing"
685240,691880," should basically, uh, render the neural, the neural network that we just allocated, uh, right, on the"
691880,697240," screen. So we're going to have a window, uh, gym erect, and this is because we need to enable gym,"
697240,704840," right? Enable, uh, gym. So this is basically how you can start working with our, uh, basically framework,"
704840,709560," right? So all of these things are part of our framework. You can just allocate the neural network,"
709880,715320," then using RayLib, you can create a window, and then using the gym widgets, you can render this"
715320,720200," entire thing, and we're going to have a lot of these kind of widgets that allow you to visualize different"
720200,724920," parts of the state of your model and stuff like that. So this is basically like a sort of like a"
724920,731320," quick tour of the, uh, of the framework, right? So it's a quick tour of the framework, uh, if that makes"
731320,737160," any sense. And there we go. You should get this kind of thing. So this is the neural network that we just"
737160,742760," allocated, right? And as you can see, it's basically the widget that we used in, uh, in the previous"
742760,748280," models, in previous demos. So it's literally the same widget. So the idea that I'm going for actually"
748280,754440," is that you have a lot of these small little widgets that you can throw into the own window,"
754440,759400," right, in different orders, right, depending on the needs of your model, right? And then when you're"
759400,764040," done with your model, you can basically quickly assemble another application that uses different kinds of"
764040,769640," uh, visualizations because depending on what exactly you're doing, you may not want to visualize certain"
769640,774760," things in a certain way, right? So that's basically the whole idea. So here I need to quickly just"
774760,780280," visualize some, uh, neural network, right? So, and I just use this standard visualization and this is the"
780280,788360," thing I got, right? Uh, this is the thing I got. So, and also we are simultaneously printing the weights and"
788360,793640," biases, the weights and biases of the neural network and also rendering its visual state. I just want to"
793640,798600," have these two things side by side. So this is basically why I was spending some time doing all"
798600,806360," right. So here is the input layer, right? As I already said, we have 2, 3, 4, 2, right? So if you just count"
806360,815960," them, uh, so this is a 2, 3, 4, 2, 2, 3, 4, 2, precisely. So if you put something like, uh, 10 in"
815960,820760," here, uh, right, obviously it's going to be completely different. So as you can see, it actually affects"
820760,827960," things, uh, right? So as you can see here on the previous, uh, layer we have 10 of them, right? So it"
827960,834600," automatically does all of that stuff for us, uh, right? So let's actually go back to 4. Um, okay."
834600,843560," Okay. So essentially you can see that we have two elements, uh, two neurons in here and three neurons"
843560,851880," in here and each neuron is connected to each of the next one. So this one is, uh, has three connections"
851880,861000," like this. And this one has three connections like this, right? So, and this entire mass of connections"
861000,873160," is described with this matrix. So this connection has, uh, a weight this, this connection has weight this,"
873160,881240," and this connection has weight this, right? And as I already said, green is positive and purple is negative."
881240,886520," So as you can see, these two are positive. And because of that, these two are green and this one"
886520,891240," is negative. And that's why it's purplish, right? So you can clearly see that it's actually closer to"
891240,896360," gray because it's not that strong, right? So the more the negative, the more purple they become,"
896360,901720," the more they're positive, the more green they become. So it also shows the intensity of these connections."
901720,909640," And correspondingly, this connection is this one, this one is this one, and this one is this one. And as you can"
909640,917080," see the signs also preserved, right? So, and this mass of connections is described by this matrix, right?"
917080,923800," So we have three and four. So that means the matrix is three by four, uh, right? So, and, uh, this mass of"
923800,930360," connection four, uh, by two, right, is described by this one, right? And these are biases. These are"
930360,935960," additional things that are added to the activation of the neurons, right? Nothing special. So as you can see,"
935960,942920," right, uh, this is basically side-by-side comparison of the actual representation in the memory and how we"
942920,949480," visualize it, how we as humans think about these neural networks. Uh, right. So, and here is an"
949480,956520," interesting thing. So you can think about connections between neighboring, um, neighboring layers"
956520,965080," as sort of like a rectangular image. You can think of it as sort of rectangular image, right? And you can"
965080,973480," literally see all of that. So this is the image two by three. And this is an image three by four. This is an"
973480,985320," image four by two, right? So what if we take these matrices and turn them into texture, right? Where each pixel,"
985320,989640," where each pixel corresponds to the weight of the connection."
989640,997080," And that way, and then we take all of these, uh, textures and we stack them, uh, top to bottom,"
997080,1004360," right? We literally stack them top to bottom, right? And each pixel in that texture represents"
1004360,1010280," one single connection. And as the neural network learns, each pixel is going to basically highlight"
1010280,1014600," either green, purple, they're going to change and so on and so forth. And we're going to literally see"
1015320,1020440," what parts are underutilized, uh, what parts are overutilized and stuff like that. But we're not"
1020440,1027240," going to have this mass that obscures each individual connection. We actually sort of taking all of this"
1027240,1034120," mass and we're rotating it facing forward, right? So at us and each pixel is the connection. We actually"
1034120,1041000," see more, right? So we'll be able to actually see more connection in their values and it's going to be"
1041000,1045960," actually way better. I think this is hypothesis. I never implemented visualization like that,"
1045960,1051400," but this is my hypothesis, right? And it's going to be very valuable when your neural network is going to"
1051400,1058200," become something like this, right? So, right. If you have something like this, uh, each sort of like"
1058200,1062440," interconnection matrix is going to be like very valuable. Like how are you supposed to read that"
1062440,1070920," shit? Like how is it like, you need to like take this entire stuff and turn it into image, right? And if"
1070920,1075400," we take a look at, uh, how it actually printed all of that, yeah, there you go. So these are the"
1075400,1082280," mattresses of each individual layer in here. These are literally the mattresses. They're begging to be"
1082280,1090040," turned into a texture and displayed as a texture, right? So, and that's what I want you to do today,"
1090040,1095000," right? So I'm not going to remove the current visualization because I think the current visualization"
1095000,1102280," is very useful, again, when you have very small models like XOR. In XOR, it's actually extremely"
1102280,1107400," valuable. It is extremely valuable because like you can literally see that, but as it becomes more and"
1107400,1113720," more, uh, complicated, like we have adder in here and here in adder, I'm sorry, you've seen a secret"
1113720,1119640," terminal that you're not supposed to see. Uh, right. So it's already kind of complicated, right? So it's"
1119640,1126680," already kind of complicated. So this is basically a table that contains numbers 0, 1, 2, 3, 4, 5. And"
1126680,1131240," basically this is the sum of these numbers on the intersection of row and column. And it just like"
1131240,1137800," verifies that the adder, uh, works correctly, right? So the adder works correctly. So as you can see,"
1137800,1142920," you can literally see how the, the results rearrange, uh, right? And purple, by the way,"
1142920,1147880," means overflow, right? Because it can add only four-bit numbers, right? So I think it's not four,"
1147880,1154680," it's, it's actually five bits, right? It's not four, it's five bits. Uh, right. So, but that's basically"
1154680,1161240," the idea. That's basically the intro. That's the plan for today. Sounds good. Sounds Gucci. Sounds"
1161240,1166360," at Hamaguchi. Okay. So let me take a look at it. Anyone actually subscribed while I was doing the"
1166360,1175640," intro, right? So it was 20 minutes intro. God damn it. Uh, 20 minutes intro. Like, uh, I think I'm gonna"
1175640,1182120," start doing the, like, one hour intro at some point. Uh, so, all right. Thank you so much, uh, horizon,"
1182120,1186280," uh, horizon. Uh, I hope I'm pronouncing your name correctly. Thank you so much for Twitch Prime."
1186280,1192360," And for decking, uh, thank you so much for Twitch Prime as well. A thank you. A thank you. A thank you."
1192360,1199720," Okay. So, uh, let's go. So let's actually go back to our original smaller neural network,"
1199720,1207160," right? So, and I'm gonna try to rebuild this entire thing. So this is the simple, uh, and when we're"
1207160,1213400," building, we're only building the simple, right? So, okay. That's cool. That's pretty freaking cool."
1214840,1220920," So one of the things I want to do, I suppose, uh, I think I want to have a function which is going to"
1220920,1228200," accept the gym rect, uh, gym rect, and it's going to render the neural network within this entire thing."
1228200,1235240," Right. Maybe for now, maybe for now, I actually going to accept only one matrix, right? Only one"
1235240,1240200," weight matrix. And I'm going to try to render only one weight matrix. I think that sounds like an"
1240200,1247880," interesting idea, right? So gym, uh, render, uh, weights, gym render weights. We're going to accept"
1247880,1253800," the slot within which we are rendering this entire stuff. And we're going to accept the matrix, the"
1253800,1259320," single matrix, and we're going to try to render all of that stuff within that matrix and see how all of"
1259320,1266120," that goes. Uh, right. So this is going to be render. This is going to be M. And you know, what's interesting"
1266120,1273480," is that I can now use our layouting system that we implemented on the previous stream to actually,"
1273480,1279640," uh, display the previous visualization of neural network and new visualizations side by side"
1279640,1286360," without compromising anything. Right. So, and it should be super easy. So essentially one of the things I did"
1286360,1295080," of screen, right? So on the previous stream, you had to create gym, uh, layout stack, right? And, uh, it was"
1295080,1299080," using like dynamic allocation and stuff like that. And you would have to pass it every time you push"
1299080,1305880," something into that stack. What I did, I noticed that you probably never going to have more than one,"
1305880,1312760," uh, layout stack in your entire application. So what I did, uh, in the, uh, in the framework,"
1312760,1320280," I just created a global static, uh, layout stack called default gym layout stack. And I created a"
1320280,1326600," bunch of macros, like layout, begin, layout, end, which basically push layouts to that default thing."
1326600,1331240," So you never have to like create your own thing. You, you just do the following thing. You just say,"
1331240,1338920," okay, gym layout begin, right? Gym layout begin. And I'm going to basically allocate layout on the"
1338920,1344840," entirety of the screen in here. Uh, right. So then I have to provide, uh, the orientation, right? So"
1344840,1350840," gym layout orientation, and let's say the orientation is going to be horizontal, right? So this is that,"
1350840,1354920," then the rectangle, then I have to decide like how many elements I'm going to have there. I'm going to"
1354920,1361000," have two of them and let's not put any gaps in here, right? So, and when I'm rendering the neural network,"
1361000,1366440," I'm going to be taking a layout slot out of the current layout, and I'm going to render this thing there."
1366440,1377160," Uh, right. And here I'm going to do, uh, layout end, there we go. And then here I'm going to do, uh,"
1377160,1387400," render weights, right? Gym, uh, render weights. So, and in here I have to provide the gym layout slot,"
1387400,1392200," right? So this is the slot and the matrix, a single matrix. So we're not going to render the whole thing,"
1392200,1398680," only the, the current matrix. Excuse me. So, and essentially what we can do, we can just take,"
1398680,1404360," uh, one of the matrix in here. In fact, yeah. So basically the first weights matrix, just, just the"
1404360,1410520," first weights matrix. Uh, right. And let's try to recompile this entire thing and see how it's going to go."
1410520,1417800," So it complains about some stuff. Uh, so wh, uh, too many arguments provided. What?"
1419320,1428040," Um, this is a very useless. Too many arguments provided to function. Oh, okay. I see. Uh,"
1428040,1435480," I see. I see. So the count is supposed to be this one. Uh, I think I've fucked up the argument. So"
1435480,1447240," orientation, rectangle, count, and gap. Uh, right. So I'm confused. This is probably okay. I think I know"
1447240,1456440," what the hell is going on. That's kind of dumb. Uh, if that's the reason, that's kind of sad. Uh,"
1456440,1462200," this is because I actually wrap the arguments with parentheses. Maybe this is something that I should not"
1462200,1469800," do, but I do that just in case, but since you can't really pass commas in here. Yeah. So I think"
1469800,1475880," wrapping that in parentheses is not particularly great idea. So, uh, I was just doing that just in case,"
1475880,1482280," just to be safe. But apparently, yeah, you can't really pass easily a comma into a macro anyway,"
1482280,1489800," because comma is used as a separation of arguments for the macro. So you're not gonna just pass extra stuff"
1489800,1495720," in here. I think that makes sense, actually. I think that makes sense. Uh, int parameter. Right. So this one"
1495720,1502840," goes like this. Right. C macro, basically. C macro. Okay. So as you can see, it actually, uh, allocated a"
1502840,1506680," little bit of space on the right. Right. It allocated a little bit of space on the right. And to demonstrate"
1506680,1513560," that we can actually use that space, I can do something like draw, uh, draw a rectangle. Right."
1514840,1523400," Rectangle. So R, uh, X, R, Y, uh, R, W, R, H. And this is red. Right. So, and we'll try to run this"
1523400,1531800," entirely. So, yeah, as you can see, we basically have two sides in here. Right. So we have two sides in"
1531800,1538760," here. That's pretty boggars. Okay. That's pretty cool. Uh, so how are we gonna be rendering it? So what I'm"
1538760,1545560," thinking is that we can just basically split the whole rectangle into like cells, uh, and the,"
1545560,1550920," the resolution of the cells is going to be the size of the matrix and just like render them with the"
1550920,1555880," rectangles. So that's the first approximation that we want to go with. Right. And because of that,"
1555880,1564440," I'm going to just do simply like size T, uh, right. So, and, uh, we're going to be iterating rows. Right."
1564440,1575000," So this is going to be basically rows, uh, right. For, uh, size T, J, zero J, um, calls, plus, plus J,"
1575000,1584440," plus, plus J. And I'm going to take a matrix at, uh, I, J. Right. And this is the value that I have to visualize."
1585240,1593000," Uh, right. So the value we need to transform that value into a color. Right. So, and how do we do"
1593000,1600360," that? Uh, if I remember correctly in the original visualization, right. So Jim, uh, render and then,"
1600360,1606360," right. So if we take a look at Jim, render and then, so we have two colors, like a low color and high"
1606360,1613080," color. So I think we can, uh, basically copy paste this entire thing. Uh, right. And how do we do all of that?"
1613960,1622200," How do we do all of that? I suppose. So we basically blend them together. Uh, right. We blend them"
1622200,1634280," together. So the low color, but where is the alpha? I don't see the alpha actually. Oh, okay. So we set,"
1634280,1643640," all right. I see. So this is the value of the matrix. We shove it into a segmoid. Right. So, and the segmoid is"
1643640,1649400," actually very interesting because it's a function from zero to one. Right. And the more negative you"
1649400,1656360," function, the, uh, more, the closer it is to zero and the more positive it is, the more it's closer to"
1656360,1661960," one. So it maps the range from minus infinity to plus infinity to the small range, uh, from zero to one."
1661960,1667080," And this is what we're using here. So here we basically transform it to zero one and we use that thing"
1667560,1675240," for the alpha. Right. For the alpha. And we simply blend the colors according to that specific alpha."
1675240,1680840," So that's very dumb way to do that. Uh, but that's how we do that. I'm not sure if it's a good way to do"
1680840,1687400," that either. Right. So, uh, right. So let me quickly do that. So this is more of an alpha,"
1687400,1693320," right? So, and essentially we'll probably want to do that in here. Right. So we probably want to do that"
1693320,1700600," in here. And I'm going to shove it like that. So this is the alpha. So then we set that specific alpha"
1700600,1708760," to the high color. So we set it to high color. And, uh, then essentially we just blend together"
1708760,1716360," two colors, low and high color, and we get the color of the thing. So what we have to do now,"
1716360,1720840," we have to just render the rectangle, right? We have to just render the rectangle. So let's go ahead and do"
1720840,1727320," that. Uh, right. So we need to do draw rect. So, but the position of the rectangle is going to very much"
1727320,1735080," depend on i and j. So, and to do that properly, we need to know the width and height of the cells of i"
1735080,1740840," and j. Right. So that's what we need to do. So essentially what we need to do, we need to take"
1740840,1748440," the width of the rectangle within which we're trying to fit, uh, this entire stuff. And we need to divide"
1748440,1754120," it by the columns of the matrix and we get the cell width, right? So we can even do something like float,"
1754120,1764120," a float cell width and the cell height is going to be correspondingly, uh, h divided by rows. There we go."
1764120,1774520," So h divided by rows. So in here, what we can do, uh, right? So i is actually y and j is actually x because"
1774520,1780520," rows, right? So rows go like that. So that means it is y. So I think it would make sense for me to call this"
1780520,1788360," thing y, right? And columns are this thing. So that means it's x, right? So this is basically x. And we"
1788360,1794840," address the matrix y, x. That's how we do that. So that means now, uh, what I have to do. So x is going"
1794840,1802440," to be x multiplied by cell width, right? Uh, y is going to be, uh, y multiplied by cell height, right? And width and"
1802440,1809080," height of the cell is cell width, uh, and cell height. And what's the color? We already, uh, computed the"
1809080,1816520," color so we can, uh, shove the color in here like this. Uh, and that's basically right. So we split the"
1816520,1822600," whole rectangle into the cells elements of the matrix and we just like render them with their corresponding"
1822600,1827080," color, right? So this is just one single matrix. So let's take a look at how it's going to look like."
1827080,1833800," So this is not really a value. This is more of an alpha. And I wonder if we can just like compress"
1833800,1841240," all of that stuff to this, right? So why not? Why not just compressing that thing to a single stuff?"
1841240,1847160," Uh, I don't see any reason not to do that. There we go. So, and that is very weird because"
1847160,1853480," why did it render in the first slot and not in the second one? So that's a very interesting question."
1853480,1861960," Uh, all right. So because we've got this thing and it would, oh, I know why. I know why. Because"
1861960,1868040," we don't take into account the x and y of the rectangle. We only take into account the width and height."
1868680,1876360," So I forgot to do the following thing. Rx plus, uh, right. And ry plus, right? So that's basically"
1876360,1882440," what we have to do in here. Uh, it's not kind of particularly visible what is going on in here."
1882440,1887480," So maybe I'm going to do the following thing. So width and height and the color. Uh, right. So there"
1887480,1896280," we go. We can finally see this kind of stuff. Uh, and, uh, yes. So there we go. So this is basically"
1896280,1903800," representation, uh, of this entire thing. Right. So this is a representation of this specific layer"
1903800,1910840," of connection. So three, uh, two by three. So three and another three. So, and these are basically the"
1910840,1916680," connections. So this row of connection is this connection. So you can literally see by the colors."
1916680,1922760," And this row of connection is these connections. Right. So that's basically what's going on in here."
1922760,1929800," Basically. Uh, all right. So that's kind of interesting. I wonder if we can"
1929800,1938520," actually do an interesting thing. Uh, right. So this is a very dumb, you know, implementation of this"
1938520,1944120," entire thing. It's kind of stretchy and that's totally fine. We are experimenting. We are trying to see"
1944120,1949960," like what would be the best visualization. Right. So it's kind of difficult to, I would even claim that"
1949960,1956280," it is impossible to just come up with absolutely awesome visualization from scratch in your head,"
1956280,1963480," sit down and call it in one try. Right. So for, at least for me, for me, very dumb developer who"
1963480,1970040," doesn't kind of do shit. It's very important to just try something dumb and see what works and just work out"
1970040,1974920," starting from there. Maybe some of you geniuses can do that in first try in their head. I can't do that."
1974920,1978200," I really apologize for that. Uh, so"
1980360,1991320," All right. So what I'm thinking is that what if, um, we create something like, uh, Jim render. Um,"
1991320,1999080," I want to call it NN, but NN is already taken. Right. So, uh, we need to come up with the name"
2000600,2008440," for this kind of visualization. Right. For, for the name of this kind of visualization. So it's sort of"
2008440,2017320," like, um, you have these layers that you stack on top. Right. Maybe it's a cake. I mean, it's a cake"
2017320,2025720," visualization. Uh, we can do something like, all right, Jim render. And then as cake, I think that's,"
2025720,2029560," that's a good name for this entire thing. So we're going to accept the rectangle within which we're"
2029560,2034680," rendering all that. And we're going to accept the, the neural network. Right. So we're rendering the"
2034680,2041320," neural network as a cake. Right. So, and what's interesting is that since I want to just stack"
2041320,2047240," those things on top, uh, I can just use the layouting system. Who said I can't do that? Why? I can do"
2047240,2055800," something like gym, uh, render actually layout begin. Right. This is the layout begin. Uh, and what I have"
2055800,2060120," to add, I'm going to, we're going to be static, stacking them on top. That means it's going to be"
2060120,2065480," vertical thing. Right. So we're going to use vert, uh, as the slot, we're going to use the R that we've"
2065480,2072360," provided in here. And how many elements we're going to have in here? Basically as many, uh, as many as we"
2072360,2078520," have, uh, uh, like weights, right. And how many, uh, we have weights. I think we have just NM count, but I"
2078520,2090680," don't quite remember. Uh, right. Okay. So count is the amount of weights, right? So, uh, the amount of, uh,"
2090680,2099160," we guess, and BS, uh, matrices. Right. So this is basically what it is. So that's basically how many things we're"
2099160,2104440," going to have in here. And then I'm going to do gym layout end, uh, and, uh, and essentially what we're"
2104440,2113720," going to do, we're going to iterate, uh, right. All of the rows, size T I, uh, right. So, and then rows"
2113720,2125240," plus plus I. And, uh, so what we're going to do gym, um, render weights, right. Gym render weights."
2126120,2133400," So, and here we're going to use the slots, right. So this is going to be gym, uh, layout slot, uh,"
2133400,2142040," and N, uh, W S I, and that's it. Right. So that should do all of that scheisse automatically. So that"
2142040,2146360," didn't work because we also have to provide the gaps, which could be useful for this specific thing."
2146360,2153560," It could be useful for the cake. Uh, right. So, and then, uh, count. Yeah, that's right. So this is NM count."
2153560,2157720," And let's take a look at the visualization of this entire thing. And it didn't work because we never"
2157720,2162520," called this function, right. We never called this function. So here, what we have to do,"
2162520,2169400," we have to do gym render, uh, and then as cake, right. So, and, uh, what do we accept in here?"
2169400,2176200," So first is the slot, right. So first is the slot and then the neural network."
2176200,2185560," Okay. And that's the cake. So the problem with this cake is that like, it's not clear"
2185560,2193320," where things end and start. And this is why we introduced the notion of a gap. We can introduce a"
2193320,2198840," little bit, a little bit of a gap between those things, right? For example, like 10 pixels maybe,"
2198840,2207160," right? Let's actually put 10 pixels in here. Uh, yep. And that is basically it. So there is a, yeah,"
2207160,2214040," there is a three mattresses in here, which is probably interesting, right? So yeah, that's, that's good."
2215000,2221080," Uh, maybe we can even, uh, make it more, uh, gappy, if you know what I mean. Is that even a word in"
2221080,2226760," English? I don't speak English. It's, it's, it's a gap. Uh, that's pretty cool, right? Isn't it?"
2226760,2233080," So there is a little bit of a gap in here within a single layer of the cake. And we had a similar"
2233080,2239400," problem when we were developing a layout and this is because of how we around the elements, right? So this"
2239400,2244040," is because how we're around the elements. So to fix this problem, we have to do seal, right? So we're"
2244040,2253160," going to do a seal. Uh, and so this is a, yeah, so I think doing a seal is actually valuable in here,"
2253160,2258840," right? So now they're not going to have these sort of like gaps that are not supposed to be there."
2258840,2266120," Uh, yep. There we go. So this is this three layer cake, three layer cake. So this is for the,"
2266120,2272760," uh, for the first sort of layer. This is for this layer and this is for this layer. So this is like a first"
2272760,2278840," approximation of how we can visualize all of that. Of course, it would be kind of cool if they were"
2278840,2284680," proportional to their actual actual size, because for instance, here is you have three columns."
2284680,2291720," This is three columns, but here you have four of them, right? So, and I suppose the upper one has to"
2291720,2300040," be smaller than the bottom one. That would make sense, right? And, uh, yeah, this one has even like two"
2300040,2305160," columns. This one should be even smaller than this one. So all of that is kind of disproportional,"
2305160,2310760," but it works. It kind of works. Uh, right. And we can add more layers in here. What if the one of the"
2310760,2319880," layers was like 10, uh, right? So, and I think it would be visible on the visualization, right? So yeah, so that"
2319880,2326920," resulted in this thing having 10 columns, right? And what if we have a lot of layers, uh, like deep neural"
2326920,2337640," network like this, right? Uh, we'll be able to see anything at all. Um, there we go. So here, this is"
2337640,2346040," unreadable mass, but this one already kind of makes sense, right? So yeah, so this one can be actually read"
2346040,2355800," somehow, somehow, right? So, and each pixel pixel, right? So each pixel is basically one single"
2355800,2363800," connection that you're incapable of even seeing in here, right? So it would be kind of cool to, uh, so"
2363800,2368920," of course this is not a final visualization. This is a rough approximation, right? I would like to actually"
2368920,2374280," work a little bit more on this entire thing. And as already said, just adjust different sizes,"
2374280,2380520," make them different sizes. So it's instantly visible which layer is bigger, which layer is smaller,"
2380520,2385400," because it's quite, quite important. It's important to see this sort of architecture, right? But I already"
2385400,2392120," want to see, uh, I already want to battle test it and see how it highlights and dims up as you training"
2392120,2401240," this entire thing, right? So to do that, uh, I think I want to move this entire stuff inside of the"
2401240,2405160," framework, right? We're going to move it inside of the framework and we're going to modify one of the"
2405160,2412600," existing, uh, demos to actually use this visualization instead of the previous one, right? Uh, so let me,"
2412600,2421160," let me see. Okay, cool. I'm going to go to, uh, nn.h, right? So, uh, and then, um, I think it was something"
2421160,2426920," like Jim Aranda and then, yeah, there we go. So this is basically where we're going to have, uh,"
2426920,2433240," all of these things and we're slowly just like moving all of that stuff in there. So I would like"
2433240,2443800," to maybe call this and I think, um, something like cake layer. Is that a good name? Right. So weights,"
2443800,2451160," uh, cake layer, right? So render and then as cake and you render a single, uh, cake layer."
2451160,2458280," Maybe it should be actually called something, uh, something differently, right? So render"
2459000,2464280," matte because we're accepting matrix in here, uh, and like render matte, uh,"
2464280,2469160," as"
2469160,2479400," cake as well. Why not? Why not? That's a good name. So render matte as cake."
2482920,2490120," So, and let's move that stuff into the declarations, right? So here we're going to have declaration and"
2490120,2495960," somewhere down below where we have implementation, we're going to move the implementation. So here is"
2495960,2503640," the entire implementation. It moves, uh, here, right? So let's go back to the declarations and in the"
2503640,2511560," declarations, we're going to have, uh, and then as cake, right? And, uh, in the implementations down there,"
2512200,2518760," we're going to copy paste that entire implementation. Uh, all right. So it's inside"
2518760,2523400," of the framework. So I'm going to try to rebuild simple, right? So I'm going to be rebuilding simple."
2523400,2529640," Uh, and it seems to be working, right? So that's pretty cool. So let's go to ZOR, right? So let's"
2529640,2537560," take a look at the ZOR example. So here we have the layout, right? So here we have a plot and here we"
2537560,2542920," render the neural network, right? So one of the things we can do now, we can start another layout."
2542920,2548200," Uh, so which is going to be vertical this time, right? So this is the vertical. Uh, we're going to be using"
2548200,2552760," the slot, uh, the current slot. How many elements we're going to have in here? We're going to have two"
2552760,2562040," without any gaps, right? So, and one, two, three, four, gym layout end, right? So we rendered the neural"
2562040,2569640," network in a classical sense, and then we try to render and then as, uh, as cake, right? And for some"
2569640,2579640," reason, I did a very stupid mistake, man. Uh, right. Yeah. So render and then accepts and then first and"
2579640,2586520," then rectangle, but here it's the other way around because I'm a dummy dum-dum. Consistency. The"
2586520,2593320," consistency of this API is top notch. Holy shit. I think we need to fix that. I think it needs to be"
2593320,2599800," consistent. We like nowhere in here. We really pass the slot within which you have to render as the"
2599800,2607080," first element. I don't think it makes sense. I didn't think it actually makes sense. So let's actually"
2607080,2615240," quickly fix that. Uh, right. So let's put this stuff in here. Uh, let's put this stuff in here, right?"
2615240,2623000," Okay. Okay. Okay. Okay. Okay. I'm sorry. Uh, so in here we have to do a similar thing."
2623720,2628280," Though I could have just like let the compiler do the work, right? Because we're not programming"
2628280,2635640," in a toy scripting language with dynamic system, uh, where you can't modify shit without unit tests."
2635640,2640440," Here we are programming in the chat statically typed language. And if you modify something,"
2640440,2648760," the compiler is going to be, bro, you need to fix that place. There you go. I helped you, right? So"
2649400,2656840," it's a bro statically typed programming language, not some toy dynamic thing. That's whining all the time"
2656840,2659640," that you need to unit tests to modify anything."
2665800,2672280," there are some, uh, useful things with dynamic languages as well. I'm just joking. Of course. I'm just joking."
2672280,2679320," Of course. Kappa. So, uh, let's actually go through the compilation errors. Uh, so what do we have in here?"
2679320,2685960," So it complains about, yeah, yeah. So now we have to modify all of these places, right? So in the places"
2685960,2695720," where we actually call all of that stuff. So, and also we have to modify that in here, right? Do we have"
2695720,2702760," to modify anything else? Uh, okay. That's pretty poggers. Okay. So let's go here and I'm going to be"
2703720,2706840," uh, working only with Zor. Let's try to compile Zor."
2706840,2713400," So it's taking some time to come. Yeah, there we go. Doesn't it look cool?"
2713400,2723240," That looks cool. This is quite shit. Holy fuck. But I mean, we're going to fix that. So right now,"
2723240,2731640," what I want to see is how those things highlight. It's not that. There we go. So when we can literally see,"
2731640,2737640," I would like to actually, yeah. So there is a obvious problem in here is that when they become"
2737640,2745560," the same color, it's kind of difficult to see that these things are separate, uh, cells, right? Let's"
2745560,2752840," try to fix that. And we have a tool for that in our layouting system. We implemented gaps, right? We"
2752840,2760840," implemented gaps, uh, especially when we are rendering this entire thing as a kick, right? So, oh, this one"
2760840,2768840," is interesting. We're not using layouting system for, uh, the metrics as a kick. What if we, what if we do?"
2768840,2774040," That's interesting. Like, why am I implementing a layouting system in here"
2774040,2781240," when they already have it implemented? You know what I mean? Like, why I just, like,"
2781240,2785240," re-implemented the thing that they implemented in the previous stream? What the hell is wrong with me?"
2788840,2796840," Okay. So, okay. Let's go ahead and try to do that. I don't know. So, uh, we can do, uh, so the vertical"
2796840,2802840," thing, right? So we're doing the vertical thing. So it's going to be Jim, uh, layout, begin. And I keep"
2802840,2808440," forgetting the order of this argument. God damn it. So, and this is going to be the vertical one. So this is the"
2808440,2816440," vertical one. And then we provide the rectangle. Um, then we provide in the count, but this has to be the amount of rows,"
2816440,2822440," right? So this is the amount of rows and the gap. Let's say, let's say gap, right? So, and then we're going to customize"
2822440,2828440," this entire thing. Let's say 10 for now, but maybe then later we're going to modify that. And we won't need this shit. We just"
2828440,2836440," won't need this shit anymore because the layouting system is supposed to do all of that for us. Uh, right? So Jim layout"
2836440,2846440," and yo, uh, and in here we're going to do another one, uh, but this time a horizontal one, right? And here we're going to have columns"
2846440,2854440," also with the same gap, uh, and in here we're going to do this kind of thing. There we go. So, and essentially what we're"
2854440,2861440," doing in here, we're drawing a rectangle, right? But we have to draw the rectangle within the, uh, within the slot."
2861440,2874440," So that means we need to do something like Jim, uh, erect slot, Jim layout slot. Uh, all right. So slot X, slot Y, uh, slot W,"
2874440,2902440," slot H, slot H and then the color. There we go. Cool. Uh, so that way we don't really have to do any math, any layout in math and we get the gaps automatically, hopefully. Uh, right. So, and that makes sense. Does it make sense? It doesn't make sense. Why there's only two."
2902440,2908440," So this is supposed to be four by four. I think I did a fucky-wucky and potentially oopsie-doopsie."
2908440,2917440," Um, so let's try to look at that one more time. So something, something went horribly wrong and I don't really know what exactly."
2917440,2926440," Uh, so we supposed to have two of them, right? So this is two by two. This is straight up two by two, but it doesn't look like two by two."
2926440,2942440," Right. Um, okay. So, uh, uh, uh, uh, uh, so I'm iterating all of the rows. I said the rows. So then the columns."
2942440,2960440," So, and as a cake in here, uh, that is weird. That is weird. Um, so."
2960440,2976440," Maybe, oh, I see what the fuck is going on in here. We have to do slot. So that's pretty, very easy to make a mistake."
2976440,2982440," Maybe we should have a separate begin, but to be fair, I'm not sure how we do that properly. Yeah."
2982440,2991440," Fucky walkie. Oopsie doopsie. Yeah. Now, now that makes sense. Right. So that's actually very cool."
2991440,3003440," Okay. So we can see those things, right? It doesn't look particularly great with small, uh, models and maybe it shouldn't be used for small models anyway."
3003440,3012440," Um, right. So I would like to actually make the gap maybe even smaller, like five. So maybe something like five."
3012440,3016440," Mm-hmm. And that makes sense."
3018440,3031440," Right. So also, um, the sigmoid hits zero and one too quickly. In my opinion, I think it hits zero and one too quickly."
3031440,3039440," Uh, right. So, because there's not that much difference between, uh, the value of 10 and 100. They're literally the same color."
3039440,3046440," Right. So there's not that useful information out of the sigmoid. So maybe at some point we're gonna change sigmoid to something else."
3046440,3050440," Right. We may want to change the sigmoid to something else."
3050440,3060440," Uh, right. But what I want to do now, what I want to do now, I want to try to test it on a bigger model, right, with more weights."
3060440,3065440," Uh, for example, something like adder. I think this one is going to be interesting because look how many weights you have in here."
3065440,3070440," And it's already kind of useless, right? It's already kind of difficult to see what the fuck is going on in here."
3070440,3077440," And I think the cake visualization, maybe there is a better name for this kind of visualization. Maybe there is a official name."
3077440,3082440," And I think the cake visualization is going to be actually very useful in here. What do you think?"
3082440,3086440," I think, I think cake visualization is actually perfect for this kind of case."
3086440,3090440," Right. So let's actually go ahead and add this kind of stuff to the adder. Right."
3090440,3096440," So let's add it to the adder. Right. So in adder, we have this kind of thing. Right."
3096440,3103440," The gym layout begin. It's going to be vertical and we're going to be taking the slot."
3103440,3107440," We have two elements in here and this is going to be zero. Right."
3107440,3113440," We're going to put this stuff in here. One, two, three, four. As cake. There we go."
3113440,3120440," And of course, before we run this entire stuff, before we run this entire stuff, let's build everything."
3121440,3128440," Cook the cake visualization. Yeah, exactly. What the fuck. Excuse me. Why it didn't freaking work."
3128440,3136440," This is because I'm not building this. I should be building that. Where are the biases?"
3136440,3141440," That's a good question. We're going to add them at some point. Right. Okay. As you can see."
3141440,3148440," Yeah. So there is a problem here. It becomes like some of them may become too thin. Right."
3148440,3155440," So maybe for this specific visualization, what I want to do is to probably get rid of the classical visualization."
3155440,3160440," Right. So let's actually just render and then as a cake. Right."
3160440,3166440," Just render it as a cake. And maybe I'm going to put a little bit of a gap between the high level widgets here as well."
3166440,3172440," Right. I think it will make sense. When it's too small, you can discard the padding."
3172440,3178440," But the padding is really important for, you know, visibility of separate elements in here."
3178440,3180440," Okay. So let's see."
3180440,3186440," So, yeah. You can literally see how they highlight now."
3191440,3198440," I think the right name is Heatmap as pointed out by somebody else. Yeah. Okay."
3198440,3200440," So thank you so much, Drokka. Right."
3200440,3206440," So I don't know who was someone else, but I trust Drokka87 because I know he works."
3206440,3210440," Like his work related to machine learning and artificial intelligence and stuff like that."
3210440,3215440," So I believe him. Right. So I should probably call it Heatmap."
3215440,3218440," Though, yeah."
3218440,3221440," It's actually kind of cool. I really like that."
3221440,3229440," So the bitrate is actually fucky-wacky, right?"
3229440,3231440," So the bitrate is too fuckish."
3231440,3233440," It's too wackish."
3233440,3234440," Okay."
3234440,3236440," So that's cool."
3236440,3238440," But you know what's interesting?"
3238440,3242440," I'd like to also see Image2NN."
3242440,3243440," Right."
3243440,3246440," So let's try to see Image2NN."
3246440,3248440," Means Training6."
3248440,3250440," There we go."
3250440,3253440," So I think Image2NN is going to be rather interesting."
3253440,3259440," Because in one of these things, in Image2NN, at least in the original Image2NN."
3259440,3260440," So I modified it."
3260440,3262440," Let me actually revert some of the changes in here."
3262440,3263440," Yeah, there we go."
3263440,3266440," So let's go back to the original Image2NN."
3266440,3269440," And let's, of course, rebuild this entire stuff."
3269440,3283440," It didn't..."
3283440,3284440," Yeah."
3284440,3285440," So..."
3285440,3287440," Sorry."
3287440,3288440," Just a second."
3288440,3289440," It's going to rebuild."
3289440,3290440," Everything's fine."
3290440,3291440," Everything's fine."
3291440,3292440," Okay."
3292440,3299440," So you see, we have these things, which are basically squares, something like 11 by 11."
3299440,3300440," Right."
3300440,3304440," So they are squares 11 by 11, according to the architecture."
3304440,3305440," Yeah."
3305440,3307440," So this is like a two squares 11 by 11."
3307440,3322440," Which makes me think, if we visualize it with a heat map, we'll be able to see the actual shapes of 8 and 6 within that heat map."
3322440,3323440," What if..."
3323440,3329440," What this neural network does, it literally imprints the images in its weights."
3329440,3330440," Would that happen?"
3330440,3331440," Would that happen?"
3331440,3332440," I'm actually really curious."
3332440,3333440," Right."
3333440,3334440," So..."
3334440,3338440," And if it will imprint those images, that means it just basically memorized those images."
3338440,3339440," I think."
3339440,3340440," Right."
3340440,3346440," I'm not a specialist on that, but I kind of expect to see an imprint of this, like, you know, numbers in here."
3346440,3349440," I think that's going to be interesting."
3349440,3350440," Right."
3350440,3351440," We'll see."
3351440,3352440," So let's give it a try."
3352440,3353440," Right."
3353440,3354440," Let's give it a try."
3354440,3356440," What we're going to do..."
3356440,3357440," So..."
3357440,3358440," Yeah."
3358440,3362440," The easiest way to do in here is to just do as a cake."
3362440,3365440," So we probably need to rename it to heat map, of course."
3365440,3366440," Right."
3366440,3368440," So let's just use the heat map."
3368440,3371440," All right."
3371440,3375440," It's not that big of the thing."
3375440,3376440," Right."
3376440,3377440," It's not that big of a thing."
3377440,3382440," So I hope the encoding is not that bad, but it probably is."
3382440,3383440," All right."
3383440,3384440," All right."
3384440,3385440," All right."
3385440,3388440," I can't see shit."
3388440,3391440," I don't think it's visualizes it like that."
3391440,3394440," I don't think it does anything."
3394440,3396440," That's interesting."
3396440,3399440," What if we give it more things in here?"
3399440,3403440," What if I say, okay, so it's going to be 28 by 28."
3403440,3407440," Exactly the size of the image from this database."
3407440,3408440," Right."
3408440,3412440," Which actually results in very small things."
3412440,3414440," So we kind of need to get rid of the gap."
3414440,3417440," We kind of have to get rid of the gap in here."
3417440,3418440," Right."
3418440,3420440," You kind of have to get rid of the gap."
3420440,3421440," We have no choice."
3421440,3423440," So let's actually set the gap to zero."
3423440,3424440," Right."
3424440,3425440," Let's set the gap to zero."
3425440,3426440," All right."
3426440,3427440," All right."
3427440,3434440," So it's not particularly zero, but it's probably something close."
3434440,3435440," But okay."
3435440,3436440," So let's try to train that."
3436440,3437440," And..."
3437440,3438440," Huh."
3438440,3448440," So it doesn't really use much information in here, in this particular part."
3448440,3449440," Right."
3449440,3449440," Right."
3449440,3453440," Because we're using non-traditional way of training this entire thing."
3453440,3458440," So it primarily changes these weights instead of like this stuff."
3458440,3459440," Right."
3459440,3461440," And these particular gaps are also..."
3461440,3464440," We probably have to get rid of them as well."
3465440,3466440," Yeah."
3466440,3468440," So that is working."
3468440,3469440," Kind of."
3469440,3470440," Mm-hmm."
3470440,3473440," So I see what we need to do."
3473440,3477440," What we need to do is basically make them proportional to their sizes."
3477440,3478440," Right."
3478440,3480440," So that would have been nice to like have that."
3480440,3483440," It's one thing."
3483440,3485440," And another thing would be to..."
3485440,3486440," I don't know."
3486440,3492440," Get rid of these accidental gaps that happen due to probably rounding errors and stuff like that."
3492440,3501440," And one of the ways I was thinking to do that is to probably maybe store all of these values into a texture."
3501440,3504440," Maybe into a texture and just render the texture."
3504440,3507440," But to be fair, it's probably not important."
3507440,3508440," Right."
3508440,3509440," Probably not important."
3509440,3510440," Oh, yeah."
3510440,3511440," Anyway."
3511440,3512440," So what I want to do."
3512440,3513440," I want to make a small break."
3513440,3514440," Right."
3514440,3515440," I want to make a cup of tea."
3515440,3522440," And once I have a cup of tea, we're going to try to tackle the problem of making the sizes of these layers proportional."
3522440,3523440," Right."
3523440,3527440," Making them proportional to their actual sizes."
3527440,3529440," And then we'll see how it goes."
3529440,3530440," Right."
3530440,3531440," We'll see how it goes."
3531440,3532440," So..."
3532440,3534440," All right."
3534440,3538440," So let's try to fix the problem when..."
3538440,3539440," Like all of the layers."
3539440,3540440," Right."
3540440,3543440," All of the layers on heat map have the same size."
3543440,3544440," Right."
3544440,3546440," So as already we demonstrated in here."
3546440,3548440," So what we're currently building."
3548440,3550440," We're building image to an end."
3550440,3552440," So let's actually work with image to an end."
3552440,3553440," Maybe."
3553440,3556440," But I'm not sure if it's going to be useful."
3556440,3557440," Right."
3557440,3558440," Right."
3558440,3560440," So here is the problem that we have."
3560440,3563440," Is that these different layers have to have different sizes."
3563440,3567440," But they have the same size because this is how our layouting system works."
3567440,3569440," And also it puts gaps in here."
3569440,3571440," Which is not supposed to put in here."
3571440,3572440," It still puts them."
3572440,3578440," Is that because I explicitly said that it should add the gaps."
3578440,3581440," Jim render mat as cake."
3581440,3582440," Right."
3582440,3584440," So let's take a look at this thing."
3584440,3585440," Yeah."
3585440,3586440," I actually said the gap has to be zero."
3586440,3587440," So it's not a..."
3587440,3588440," It's not a problem."
3588440,3589440," It's something..."
3589440,3590440," It's probably rounding errors."
3590440,3591440," Right."
3591440,3592440," So it's probably rounding errors."
3592440,3593440," Right."
3593440,3595440," So we probably have to abandon the layouting system."
3595440,3596440," Right."
3596440,3599440," Because the layouting system doesn't accommodate the thing that we want to do."
3599440,3600440," Right."
3600440,3604440," So I'm going to switch to simple example."
3604440,3611440," I'm going to switch to simple example because it has almost no distraction in terms of features."
3611440,3612440," Right."
3612440,3615440," So other demos have too many features that I don't want to look at."
3615440,3616440," Right."
3616440,3619440," So let's actually start with this kind of thing."
3619440,3625440," First, let's try to take into account the width of these things."
3625440,3626440," Right."
3626440,3627440," So how are we going to be doing that?"
3627440,3638440," We can basically go through all of the weight matrices and find the maximum width of the matrix."
3638440,3639440," Right."
3639440,3648440," And essentially we can say the matrix with the biggest width will take the whole width of the rectangle within which we're rendering."
3648440,3654440," So that means that the rest of the matrices should have a smaller width."
3654440,3655440," Right."
3655440,3657440," So we should have a smaller width."
3657440,3659440," And that's actually kind of easy to do, I think."
3659440,3660440," Right."
3660440,3662440," So let me open my pane."
3662440,3667440," If it will open, of course."
3667440,3668440," Right."
3668440,3669440," So this is the rectangle."
3669440,3675440," This is basically the layout slot within which we're trying to render everything."
3675440,3680440," And then we have the biggest layer."
3680440,3681440," Right."
3681440,3686440," And the biggest layer, as we already said, as we already claimed, has to take the whole width of the thing."
3686440,3693440," So that means the rest of the layers should be strictly smaller than the biggest one."
3693440,3695440," They should be strictly smaller."
3695440,3696440," Right."
3696440,3706440," So, and essentially what we can do, we can define the biggest width."
3706440,3707440," Right."
3707440,3708440," So the biggest width."
3708440,3712440," And we can take the current width and divide it by the biggest width."
3712440,3713440," We can say it's a maximum."
3713440,3714440," Right."
3714440,3715440," Or maybe Mx."
3715440,3716440," Maybe max."
3716440,3717440," Right."
3717440,3720440," So this is the max."
3720440,3721440," Right."
3721440,3723440," And that gives you the ratio."
3723440,3725440," Ratio from 0 to 1."
3725440,3726440," Right."
3726440,3727440," From 0 to 1."
3727440,3728440," So it actually could be equal."
3728440,3737440," By which we can, you can multiply the width of the slot within which you're trying to fit this entire thing."
3737440,3738440," Right."
3738440,3744440," So we have a width of the slot, of the layout slot within which you can actually fit this entire thing."
3744440,3748440," And by multiplying it by this sort of ratio."
3748440,3749440," Right."
3749440,3750440," The width of the maximum."
3750440,3761440," You effectively know the width of this matrix that you have to fit."
3761440,3765440," So that's, it's a fairly standard trick, I would say."
3765440,3767440," So it's just like linear interpolation."
3767440,3768440," Right."
3768440,3773440," But we have to repeat the same thing for vertical axis as well."
3773440,3774440," Right."
3774440,3776440," So that works for the x-axis."
3776440,3780440," And we have to repeat the same thing for y-axis too."
3780440,3782440," And that's going to be basically the idea."
3782440,3785440," So I think I'm going to start with just x."
3785440,3787440," And I'm going to disregard y."
3787440,3790440," And then we're going to see how it's going to go."
3790440,3791440," Right."
3791440,3797440," And maybe we can even just keep using the same function that renders the layout."
3797440,3800440," It's just, we're going to set its width differently."
3800440,3801440," Right."
3801440,3803440," So we're going to simply set it width differently."
3803440,3804440," Right."
3804440,3806440," Though we can try to update."
3806440,3807440," Maybe."
3807440,3814440," Maybe update the layout system, which allows you to add this sort of paddings in here."
3814440,3815440," Right."
3815440,3817440," So that sounds like a very interesting idea."
3817440,3818440," Sort of."
3818440,3819440," Yeah."
3819440,3824440," For that specific slot, just like allow to add this margins."
3824440,3828440," And we can keep using the current, the current layouting thing."
3828440,3830440," This is actually a very interesting idea."
3830440,3831440," Right."
3831440,3838440," Because we can then compute this padding, this margin based on like our calculations and stuff"
3838440,3839440," like that."
3839440,3840440," Hmm."
3840440,3843440," That's a pretty cool idea, I think."
3843440,3852740," so we can have something like a margin left margin right and so on and so forth so uh i don't really"
3852740,3871580," know um margin left and margin right okay so uh let's go um so cake so i've already established"
3871580,3877120," it's not really about the cakes right it is not about the cakes it's a heat map right so maybe i'm"
3877120,3882960," gonna do a query replace i'm gonna replace cake with heat map right so render mat as a heat map"
3882960,3889160," and then as a heat map right so this is a heat map stuff so and let's go through all of the examples"
3889160,3896600," and recompile all of them and just like fix the compilation errors accordingly so this is the heat"
3896600,3899300," map anything else"
3899300,3910680," right it is building does it stop after each of those things yeah it does in fact stop after each"
3910680,3915340," of those things all right so maybe it would be easier to just like go through them manually"
3915340,3923680," uh right because we use all that stuff everywhere so this is the simple here's the simple and this"
3923680,3933340," is the heat map and in the layout in the layout we don't even use any of the widgets because it's not"
3933340,3942220," about uh machine learning or neural network or anything like that so we get a sub from uh sun coast uh"
3942220,3947800," software i thank you so much for tier one subscription six months or tier one subscription about that um i still"
3947800,3954680," did a fakie wakie right i still managed to do a fakie wakie instead of like heat map i said heat"
3954680,3964040," uh right am i gonna do this process anyway even though i went manually problem"
3966920,3977580," uh okay okay so seems okay"
3977580,3991580," uh let's go into an n.h and then heat so the first thing we want to do we want to iterate through all of"
3991580,4001240," the uh layers and take the max width uh right so let's do max width uh it's gonna be um it has to be"
4001240,4009160," the minimum value right so i wonder if there is a size max or max size uh i don't quite remember how"
4009160,4015400," this entire thing called but i mean um so we can put zero in here since we're trying to find the maximum"
4015400,4025320," uh we can just put zero right so we can just literally put zero though as soon as we found okay this one is"
4025320,4037400," interesting as soon as we found max we can just treat the entire thing as a grid all right we can treat"
4037400,4044200," the entire thing as a grid and okay so i'm not gonna actually jump ahead of my uh of myself i'm just gonna"
4044200,4053800," try to implement something and then uh i'm gonna keep evolving the solution as as it goes right so if uh max"
4053800,4062120," max width is smaller than whatever we found right so in the width is the amount of columns"
4062120,4071640," right so it's the it's the amount of columns uh right i'm gonna reassign and then ws columns"
4071640,4082120," like so there we go and i have a max width so after that uh we are iterating through all the matrices as a heat map"
4082120,4090440," all right and one of the things we can say we can pass the maximum width"
4090440,4097320," in here that's a very interesting thing that we can do believe it or not that's a very interesting thing"
4097320,4104440," we can literally pass that stuff into this function and this function is going to decide like how much"
4104440,4111560," space is going is it going to take right so let's do max width so we're just basically passing that"
4111560,4118440," information into each layer right so because here the layers are rendered independently so they don't"
4118440,4125560," really know anything about each other and through that parameter we can make them communicate with each"
4125560,4131880," other so they know relative to what size they have to actually uh they have to actually be rendered right"
4131880,4138840," i think that makes a lot of sense uh so that's already kind of useful actually if it was or not"
4138840,4146680," because what we can do um right how do we organize the width and height in here"
4146680,4154760," all right for now we can abandon this specific layouting system we can try to implement our own"
4154760,4160440," layouting without any gaps or anything like that uh right and what's going to be the slot"
4161160,4169640," in terms of x that slot is going to be essentially x multiplied by cell width right so the usual stuff"
4169640,4177480," that we had before right then cell height right so this is going to be cell height uh then cell width"
4177480,4186920," and cell height of course so height and of course it has to be offset by the left top corner of the gym"
4186920,4194440," rectangle right like the left corner of the gym rectangle like this so there we go uh that's pretty cool"
4194440,4208760," so how do we compute the cell uh height so size t cell height is basically going to be height divided by"
4208760,4215320," the amount of rows right for now because we're not really computing the relative sizes vertically only"
4215320,4225000," horizontally right and here's cell width cell width is not really this because the actual width is smaller"
4225000,4235080," the actual width is actually this factor that we were talking about but that factor uh that factor is"
4235080,4243800," essentially the matrix columns divided by the max width so that's what it is uh that's what it actually"
4243800,4248760," is so here we're talking about integers actually right we're talking about the integers but we can do this"
4248760,4255480," kind of stuff in integers right it's not that big of a deal uh right first we multiply it and then we"
4255480,4263320," divide it by this max so that way we don't really lose any necessary information and after that we divide"
4263320,4268600," by columns to just um get the amount of calls but i'm not quite sure"
4270680,4273560," right so i think that specific stuff has to be"
4273560,4281720," freaking neighbors just spooked me a little bit uh right"
4281720,4289960," so all right so i suppose that has to be false right so here we have that uh we multiply it's going"
4289960,4294440," to be full so i assume that multiplication and division they go from left to right because they"
4294440,4302280," have the same precedence so we don't have to worry about this kind of stuff uh all right so all right"
4302280,4307160," all right all right all right all right though interestingly"
4307160,4317560," so there are different ways we can do that so i think for now uh we can just like go with that"
4318280,4323160," so all right let's do the simple thingy right let's do the simple thingy"
4323160,4328360," so i should have probably also simultaneously run this stuff"
4328360,4334280," i will get this up i didn't notice that i'm really sorry uh amaya you can already see that"
4334280,4341160," it kind of worked uh all right so just a second uh amaya thank you so much for uh"
4341160,4346040," tier one subscription for four months already thank you thank you thank you no messages this time right"
4346040,4351960," so everyone is resubscribing all right and everyone has an opportunity to tell me something right to"
4351960,4357240," say some sort of a message or whatnot and nobody's saying any messages for some reason i really know"
4357240,4366200," why uh but yeah thank you thank you thank you amyra okay thank you thank you for correcting me uh all right"
4366200,4373080," so that's basically what we have in here so but this is specifically uh horizontal"
4375400,4385560," right specifically horizontal and are there width and heights the same width there have the same widths"
4385560,4392040," that's for sure they have the same widths you can't argue with that right they have this they have the"
4392040,4400120," same widths uh but do they have we now have to do something with heights here as well"
4401640,4408440," you have to do something with heights so i also want you to um align this stuff if you know what i mean"
4408440,4417560," right somehow align this entire thing to actually align uh the the things i need to know their full"
4417560,4423800," uh width right i need to know their full width which makes it very interesting so"
4424600,4434920," right so the full width is essentially cell width multiplied by m calls right so it's multiplied by m calls"
4441800,4451000," uh so i'm just thinking maybe i should actually uh pass the whole width in here um but i'm not quite"
4451000,4461800," sure right so uh full width so this is a full width and essentially if you replace right if you replace"
4461800,4469400," this thing like so you have two things that cancel out in here right so these two things cancel out"
4469400,4476200," uh right so you have a full width in here and the reason why i want to have a full width"
4476200,4484280," right is to update the offset right so here is the x uh here's the actual x and what i want to do i want"
4484280,4491960," to add half of the width of the whole thing but subtract uh half of the food food"
4497000,4503480," so all right all right and uh so as you can see this thing is aligned now this entire thing is aligned"
4503480,4512200," now man i wish we could like somehow get rid of these uh gaps i quite don't of this is because i got rid"
4512200,4516280," of the sylph that's probably why uh sylph"
4521000,4535800," so that's probably the reason because i don't have any sylph in here"
4535800,4541640," okay so"
4543880,4551880," uh okay so there is no yeah so it's it's totally fine now and this is basically the the layers that"
4551880,4558280," we have in here okay i want to take a look at how now it looks with image 2 and n right so with"
4558280,4565800," image 2 and then i think it's gonna look a rather interesting"
4578520,4586760," uh all right"
4586760,4593080," cool so this is how it basically looks like uh all right all right all right"
4593080,4597320," and it's taking some time i wonder why"
4597320,4600440," right"
4603080,4608040," man this is incredibly slow why is it so slow right now it's probably because of the temperature"
4608040,4609320," in the in the room"
4609320,4616600," all right i don't know oh it's actually it's pretty cold outside i really like this"
4616600,4619240," um it's pretty cool outside"
4619240,4627240," um okay so this this heat map is actually useful when you set the proportional sizes accordingly this is"
4627240,4635960," actually super useful i think uh yeah it's it like makes sense i wonder if it's uh still have artifacts"
4635960,4640760," it's probably still have artifacts right it's probably still have artifacts but i think"
4640760,4645480," yeah having it like that is actually super useful really like that"
4645480,4653880," so but the question is how can we make it vertically proportional as well and should we make it vertically"
4653880,4662600," proportional i'm not quite sure i also like how it just basically funnels right so so you can see that"
4662600,4671240," this is the input right so this is the input and this is the output uh right so we can clearly see all"
4671240,4678840," that man it's already cool this way like i don't know if i want to continue uh right i'm not sure if i"
4678840,4682760," want to continue like improving it because that's already kind of cool and kind of useful"
4683560,4693080," uh right if you just like align it properly uh yeah i like it actually uh even though they're not"
4693080,4699240," exactly like square or anything uh okay so let's take a look at some other things in here right let's"
4699240,4704680," take a look at some other things maybe the adder uh what about the adder just a second"
4713240,4718040," all right so let's take a look at some other things in here we have a look at some other things in here"
4718040,4719880," all right so that's the editor looks awesome actually"
4719880,4721560," yeah i really like that what the fuck"
4721560,4724440," oh that's so cool"
4724440,4733720," man i love it all right the heat map is yeah heat map rules"
4733720,4734920," what the fuck"
4740920,4747080," yeah so that's way better uh visualization for this kind of stuff right and as we go more and"
4747080,4755800," more complicated um it's going to become increasingly more useful right so yeah essentially throughout our"
4755800,4760600," way of learning new models we also have to come up with different ways of visualization those models"
4760600,4769160," or of these models right so because as i think visualizing models is super important it is extremely"
4769160,4776520," important because it's like interpret interpretability right so right so you've got some results but"
4776520,4781880," you also need to interpret them as a human being right so to understand them and visualizing is"
4781880,4788920," understanding right so for xor i'm not sure if for xor specifically i want to use a heat map"
4788920,4796360," since it's more of an educational thing uh i think having like a fully connect connected classical is way better"
4796840,4801400," right and that explanation is very important yes i do agree with that"
4801400,4808040," where are the biases i didn't uh draw them so that's where they are i didn't draw them"
4808040,4815000," i'll add them probably off screen right"
4815000,4821880," because adding the biases is the same as adding weights if you if we figure out how to add weights"
4822840,4828280," just like you know throw biases there as well and that's it uh right"
4828280,4838840," uh just throw biases there as well so i'm really not sure why the hell image 2 and then so slow in"
4838840,4846440," there uh not quite sure it's probably because i'm streaming but uh usually it's not that slow when i'm"
4846440,4851720," stream streaming it's probably because it's really hot in the in the room and this entire thing is just"
4851720,4862040," like really throttling um oh i think i know yeah because i actually increased the size of the model"
4862040,4867400," yeah the size of the model is actually very much increased so uh one of the things we probably want to"
4867400,4874600," do i'm gonna go back to the original uh original architecture the biases are not going to be that"
4874600,4880200," impressive a typical typically they don't change or change very little yeah i can see that plus"
4880200,4887080," there the biases are the biases are literally a vector so that means instead of this uh rectangular thing"
4887080,4888920," they're going to be literal just like a strip"
4888920,4898520," so we can add them as the last row in here maybe something like that"
4904200,4913560," actually i want to enable a traditional way of learning for this thing so um backprop traditional"
4913560,4921080," because it util it basically supposedly utilizes all of the parameters universally i think i don't"
4921080,4927240," i don't know actually so i'm talking out of my ass uh right so but our approach actually like"
4927240,4934840," modifies very heavily the the input parameters this one should actually be more calm and hopefully"
4934840,4937160," yeah so then all right"
4937160,4946520," so as you can see so they touch these two like widgets they touch each other so one of the things"
4946520,4953320," we probably want to do is maybe add a gap on the higher level of those widgets uh some sort of a gap on"
4956520,4965400," yo you know what i just got we can actually highlight activations as well"
4965400,4978360," so what if we have a second visualization somewhere on the right right and then when i hover"
4978360,4985560," over one of the pixels in the output image in here it would take the coordinates of this pixel"
4986280,4992520," and feed them into the neural network and then visualize the activations in this specific style"
4992520,4999000," right and as you hover and you change your position in here it's gonna like re-highlight"
4999000,5003400," these things showing yeah this is how the neural network looks for that specific pixel"
5003400,5007480," that would have been actually kind of cool"
5008600,5015720," uh but that's"
5015720,5021800," i'm not sure so the activations are gonna be so if you're gonna be shown activation"
5021800,5027240," activations are just rows right so activations are just rows"
5028840,5034760," so yeah this one could be could be interesting"
5034760,5048680," so essentially essentially we can even try to do that right now interestingly enough we can even try"
5048680,5057320," try to do that right now so if i go to nn dot h right if i go to nn dot h and essentially instead of"
5057320,5066760," instead of ws i'm gonna use as so because we store activations within the neural network"
5066760,5073880," right within the neural network we have pre-allocated matrices for the activations for the intermediate values of the activations"
5075240,5083000," uh right so essentially uh as we render in the heat map we can render those things"
5083000,5088040," and in fact uh it has to be plus one because the amount of activations here is plus one"
5088040,5094920," uh right and then we can do plus one in here as well and we're trying to find the maximum for the activations"
5094920,5097960," right for the activations so that means now"
5097960,5103480," what we're going to be rendering so it's probably going to go all all over the place because these specific"
5103480,5109320," activations may contain intermediate values okay so this is overflow and yeah"
5109320,5116280," this is precisely the reason why i implemented that overflow system right i added plus one in here"
5116280,5123160," right but they forgot to add plus one in here and it crashed and it also told me where exactly that happened"
5123160,5126920," it's so goddamn convenient and now i know oh i just have to do plus one"
5126920,5134920," so i didn't waste time implementing the system that actually keeps track where you call the layout slot"
5134920,5141240," it just saved my ass right because i predicted that because i have experience in software development"
5141240,5147560," i've been there so many goddamn times right i know how it goes i know this kind of"
5147560,5156200," should can bite you in the ass and it did did but this time my ass was protected that's right software"
5156200,5164120," developers protect your ass all the time that's very important that's what separates juniors from seniors"
5165960,5179800," as protection so anyway what was what i was saying um so probably this thing is going to be flickering"
5179800,5184200," right because it depends on what kind of stuff we have in here"
5185720,5196280," yeah so that makes sense um oh yeah it's actually so cool so look look look so the first this is the"
5196280,5205400," input uh this is the input the third neuron is the uh is this slider as i change this slider as i change"
5205400,5210680," the slider this neuron actually changes its value and you can see how corresponding things in here also"
5210680,5218520," change their value and by the way we're using sigmoid uh for interpolating between value and sigmoid"
5218520,5223800," cannot be negative that's why those things are never purple right they are never purple but you can"
5223800,5231480," actually kind of see so if we let it just train let's let it cook just let it cook let it cook let it cook"
5232360,5244920," let it cook let it cook oh let it cook all right so and we we see how the activations change right so"
5244920,5253240," some of them are just like changing like that that's pretty cool so if we change the um the activation"
5253240,5261480," function that we use uh they may become negative right so let's actually say and then act uh no not act"
5263000,5272840," um um it's gonna be act a relu so we're gonna be using the rather so this thing may make the"
5272840,5282520," activations negative right yeah it may because it's a leaky relu so it still has a little bit of a negative"
5282520,5290520," side theoretically at least so but we have to train it slightly slower right because it's very leaky very much"
5290520,5297160," leaky uh leaky leaky ediki um is it doing thing okay"
5297160,5302040," uh it's not becoming negative though"
5302040,5304760," surprising"
5306760,5314360," oh yeah i remember for uh relu i actually have to make like bigger inner layers otherwise it just"
5314360,5318440," can't learn anything uh otherwise it just can't learn anything"
5318440,5325240," rare singing moment i actually sing quite often i think at least at least yeah so as you can see"
5325240,5332360," they're jammed and the cost became then right so with a leaky value you have to make the learning rate"
5332360,5335000," actually like small otherwise it just basically jams"
5335000,5343960," okay let's let it cook for a little bit"
5343960,5349400," and it's kind of interesting how it does all that"
5349400,5360600," oh yeah so so far we are capable of modifying only this neuron right but we want to be able to i want to be"
5360600,5368600," able to modify the x and y and the x and y could be basically when we hover over this thing so that"
5368600,5375640," will require modifying something in here right and i wonder how can we even do that"
5375640,5379400," that's kind of cool"
5382520,5392760," all right all right so uh let me see image to nn so we're rendering the preview textures three right"
5392760,5397160," so we have three preview textures right we have three preview textures"
5397160,5410680," just a second so this is preview texture one this is preview texture one this is preview texture two and"
5410680,5416680," this is preview texture three the third one is basically a combo between the first one and second one"
5416680,5426120," that's what they are so that means what we have to do in a render texture in slot"
5426120,5436360," right so within this specific function we have to take the mouse position and see if the mouse position is"
5436360,5444760," within the texture and then grab the coordinate uh of that thing on that texture and feed it into"
5444760,5456520," into the final thing and feed it into the final thing so here's where we render the um the heat map"
5456520,5462040," and this is uh and this is maybe where we have to do all of that stuff right so this is probably where we have"
5462040,5470360," to do all that stuff so we have to do like an extra forwarding for the neural network so an extra forwarding"
5473320,5486440," but we may not know uh this the place for the texture slot before in here so we may not actually know that"
5486440,5495960," that's a very interesting thing so maybe this entire stuff is going to be lagging one frame right so essentially"
5495960,5507080," we can have a global variable for like jim rect so preview uh three slot right so initially it's just zero zero"
5507080,5521160," whatever um and what we can do we can say preview three slot preview three slot right so and since we know"
5521160,5527160," previous three slot so we already have a previous slot that we use oh that's actually very interesting we"
5527160,5533560," already do kind of similar trick to place uh the slider but that's besides the point anyway so we have a"
5533560,5539480," like a previous three slot but it's lagging by one frame but we don't really care i think that's totally fine"
5539480,5545480," uh right so in here what we have to do we have to get the mouse position right so we get the mouse position"
5546200,5554760," uh vector two right so this is the uh mouse position right let's call it mouse so that's the mouse so"
5554760,5563480," and we have a preview slot but previous slot doesn't really tell us exactly uh the boundary of that texture"
5563480,5569240," because within that function all right i'm going to scrub this entire idea there should be a better idea to"
5569240,5577640," do all that maybe it should be up to this thing to actually return that information for us uh"
5577640,5583880," how can we even do that how can we do that we can try to return vector two which is basically the"
5583880,5589640," coordinates within the texture when you hover over textures something like that uh right because"
5589640,5594680," at the end of the day right we have the position we have the scale we can kind of"
5595640,5604280," figure that out and we can return here we can return the coordinates right we can return the coordinates"
5604280,5611240," so this is the left top corner this is not the mouse position it's a left top corner"
5611240,5622840," and essentially we can grab grab not grab grab um the mouse position right the mouse position get mouse"
5622840,5634520," position in here uh get mouse position so now i need to construct the rectangle of this entire thing right"
5634520,5638440," i need to construct the rectangle of this entire thing so we have a position"
5638440,5647480," uh all right and the width is basically okay so rectangle"
5649080,5658760," uh uh hitbox we can call it hitbox so x and y is basically position x and the position y right so this"
5658760,5669480," is x and y and width is texture width multiplied by the scale uh and then texture texture height multiplied"
5669480,5675640," by the scale as well so that's basically uh what we have in here then we're rendering this entire thing so"
5675640,5683960," that's that's that's basically it and then we can simply return uh whether we're inside or not so"
5683960,5689320," mouse position maybe mouse position is not that important in here maybe it's important somewhere here"
5689320,5698920," all right so that's basically what we can have uh all right so ray lib so let me let me see here ray"
5698920,5708120," maybe include uh so there was something about collision uh collision so let me see check"
5708120,5715560," uh-huh so collision rectangle point rex so that's what we want to do so this is the point track"
5715560,5721560," so this is the mouse position the hitbox if we are within the hitbox what we want to do we want to"
5721560,5730200," return something though we don't really have to do that what we can do we can just take mouse position x and"
5730200,5740760," divide it by the uh heat box right so mouse position mouth minus position x right so we just offset this"
5740760,5750600," this entire thing and then we divide uh by the hitbox width right and we repeat that for y as well"
5750600,5757800," uh this one has to be i think width and this one has to be height right and this gives us the coordinates"
5757800,5765080," right that we probably can return um out of this function telling the relative position of the mouse if we"
5765080,5771960," are interested in this entire thing right if we are interested um so let's give it a try"
5771960,5782120," let's give it a try though all of that stuff relies on the position which is available after all of this"
5782120,5789480," stuff so we can actually move this stuff in here right uh so and what we're going to be returning we can"
5789480,5796280," return collateral uh vector two right and we can just put this stuff in here"
5796280,5802200," and just return that stuff like this"
5802200,5813480," right and in here okay so essentially when we render the texture it also returns us the relative position"
5813480,5819240," within the mouse and if it uh basically out of bounds it's going to be either less than zero or greater"
5819240,5825240," than one and that's how we can basically distinguish this entire stuff so that's totally fine in my"
5825240,5832680," opinion right that's totally fine uh and uh where is the while so this is a previous slot whatever"
5832680,5839080," and we need to have a position that keeps track of the position on the preview uh we can say preview"
5839080,5846360," three position or something uh maybe even mouse right so that's basically mouse and every time we"
5847560,5856760," render preview three every time we render preview three uh we say preview three mouse so with a little bit"
5856760,5865800," of a lagging with a little bit of lagging for one frame we have value from zero to one uh well from zero"
5865800,5871720," to one that tells us the position of this and that stuff so that's kind of cool so when we're rendering the"
5871720,5880520," heat map uh what we need to do we need to take this uh preview three x and we need to kind of clamp it"
5880520,5890680," between zero and one uh so if it is less than zero we're gonna set it to zero if it's greater than one"
5890680,5898120," we're going to set it to one and we're going to repeat that for y as well which kind of hints me that maybe"
5898120,5907320," this stuff has to be part uh of that thing it can't be easily part of that thing because that means i"
5907320,5915720," have to save that uh right so let's keep it like this okay and then here uh what i have to do essentially"
5915720,5925080," i have to set the inputs accordingly right so this is and then uh the input of an n matrix at the row zero and"
5925080,5933960," the column zero so here we're going to set the preview x the perry x to that and then preview one"
5933960,5941640," it's y and two is going to be the scroll value uh right so how do we use the scroll value so we"
5941640,5948040," literally yeah so we literally set it to here so this is the scroll and then we do a single forwarding"
5948040,5954440," just a single forwarding for that neural network and only then we visualize the activations as a hitman"
5954440,5962280," right so only then we uh do this kind of thing so we don't have a scale uh we can set we can define the"
5962280,5970600," scale outside of this condition all right we define it outside of this condition uh is it going to work what"
5970600,5979640," what else do we have in here so this is not image three this is preview three what was that mouse"
5981240,5990120," right so let's preview three uh mouse there we go so what else do we have in here preview three"
5990120,6001080," so let's put that slot in here uh we're almost there"
6003880,6012680," okay so i think it's gonna work so essentially as you can see uh as i move this thing around"
6012680,6020920," uh this stuff it changes the activations so let me now uh restart this entire stuff"
6022600,6032040," and that's the cool part all right so if i'm on the white part this look at this activation this is the"
6032040,6040120," output activation this is the output activation so if i'm on the black it stays gray if i'm on white it"
6040120,6047720," becomes green can you see that so basically as i scroll through the pixels it feeds the activation of"
6047720,6054360," these coordinates and this thing in here into the neural network and shows the activation okay i can"
6054360,6060760," stop the learning right i stopped the learning and as i go around these are the activations i'm sort of"
6060760,6065400," tickling the neural network as you can see i'm sort of tickling the neural network"
6065400,6074360," right so that was i was trying this is what i was trying to do because the way we uh construct this"
6074360,6082520," image our neural network has three inputs x and y right and the z sort of like the index of the image"
6082520,6088680," that we're trying to reconstruct and essentially we go pixel by pixel and we feed x and y's into the"
6088680,6093960," neural network and the neural network speeds out the uh the brightness and we just use that brightness"
6093960,6099960," for the pixel and to see the activations as we feed different coordinates uh i just feed the coordinates"
6099960,6103640," uh into the neural network uh into the neural network and this is how it activates depending on those things"
6103640,6109160," right so these are the activations of the neural of the neurons so that's what i was doing"
6109160,6115400," uh essentially right that's kind of interesting so that's kind of an interesting experiment"
6117880,6128600," uh yes yes right but uh this is this could be an alternative way of rendering this entire thing"
6128600,6136360," i think we can think of it as an alternative way um all right let me see if i go to nn.h"
6136360,6144280," right so here we render and then as a heat map right but essentially depending on what exactly you render in"
6144280,6151160," here right what exactly you render in here uh either activations or weights it serves different purposes"
6151160,6159240," so if we render weights we sort of um render the like static model right the static parameters of the"
6159240,6167400," model if we render activations we are rendering the like what actually happens within the neural network"
6167400,6173880," when you pass specific parameters to that so i feel like this has to be two separate functions"
6173880,6182200," uh so we probably should have something like and then like gym render and then weights as heat map"
6182200,6190680," and the second function that we have to have is an activations uh activations you know what i mean"
6190680,6195720," right and depending on like what we want to display in here we're gonna just like call different function"
6197560,6205160," uh right so here i'm gonna say not weights but this is activations right so this is active but it's such a long name"
6205160,6215640," uh right so render and then activations heat map right so and then and then weights heat map"
6215640,6226280," uh so that's basically the idea does it make sense does it make sense all right so and i'm going to also copy paste this entire thing"
6226280,6233720," uh right i'm going to say uh right i'm going to say and then weights heat map so here we're probably not"
6233720,6242440," going to have plus one so this is going to be a w and this is not going to be plus one and this is going to be a w"
6247800,6251480," uh right uh right and depending on what we want to render in here we're going to just do"
6251480,6264360," ran uh do different things right so let me go back into image and then uh and uh i don't really know"
6264360,6269960," if i want to keep the activation rendering it's kind of interesting but i think it needs a little bit more"
6269960,6275640," work right so i'm going to remove that and i'm going to be rendering only the weights right so we're going to be"
6275640,6282680," rendering only the weights for now and then weights heat map so that's basically what we're going to be"
6282680,6287080," rendering uh all right and let me go back in here"
6287080,6294840," so we don't use this variable anymore right so because we didn't do that and this is basically"
6295560,6300200," uh the stuff that we have uh the stuff that we have right"
6300200,6310920," for some reason it takes some time to learn this so we can make it a bit more crazy yeah there we go"
6310920,6313320," please learn something"
6320680,6329800," right right so i suppose yeah that's basically the result of today's stream i think i'm going to work"
6329800,6336760," more on this visualization and make it more like pretty uh right so maybe i'm gonna look into making"
6336760,6344280," the uh vertical stuff also proportional right though making horizontal stuff proportional already kind of"
6344280,6349880," makes it look good enough in my opinion right and i think that's going to be our goal to"
6349880,6358360," visualization in in the future what's interesting is that uh i plan to have uh like different layers of different types"
6358360,6365320," uh in the future so this is a fully connected thing but we may also have um convolutional neural networks"
6365320,6369880," networks right and with the convolutional neural networks we can uh display convolutional layers"
6369880,6375000," as just like a bunch of convolutions and we can also see how they activate maybe we're going to"
6375000,6383080," also display activations of the convolutions and stuff like that so i think this is a pretty pretty"
6383080,6388360," useful experiment this is a pretty useful experiment that we've done in here what do you guys think"
6389320,6397640," that's actually kind of cool i really like that"
6397640,6406520," that's actually a specific example actually really cool uh all right so that's it for today"
6406520,6412280," i've been streaming for two hours already thanks everyone who's watching me right now i really appreciate"
6412280,6416680," that have a good one and i see you all on the next recreational programming session"
6417480,6421880," all right and we're going to come up with some interesting stuff i have a lot of plans"
6421880,6426200," regarding like different models that i want to train some of them are going to be actually"
6426200,6435640," even useful i would say i want to train a useful model that uh we can use in a bot yes i have plans"
6435640,6440840," like that but it will require maybe um a little bit of a preparation and probably several streams"
6440840,6446520," but eventually we're going to have some interesting ai model that can be used in in a bot"
6447240,6452120," so yeah that's it for today thanks everyone uh i love you"
