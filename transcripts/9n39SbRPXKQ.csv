start,end,text
400,6400," looks like we're live hello everyone and welcome to yet another recreational programming session"
6400,12560," with a mr azuzin let's make a little bit of announcement and officially start the stream"
12560,18160," as usual as usual live on twitch uh with a red circle of course and what are we doing today on"
18160,25840," twitch dot at television website today we are implementing ai paper in c how about that finally"
25840,30240," so i'm going to give the link to twitch.tv/serving the place where we're doing all of that and i'm"
30240,34800," going to ping everyone who's interested in being pinged and there we go the stream has officially"
34800,42560," started the stream has officially started so a couple of streams ago we were implementing um k"
42560,50640," means clustering algorithm right so um and um like i'm gonna put the link to to the playlist in the"
50640,56560," description as usual and k means clustering a very cool algorithm i really enjoyed implementing it"
56560,64400," and i implementing it was implementing it because i thought it is used in this cool paper that i wanted"
64400,73200," to implement for quite some time right but then i looked closer into the abstract of this paper and"
73200,81920," apparently it uses k nearest neighbor rather than k means clustering so for the past two streams i've"
81920,88000," been doing the wrong thing all right but i mean implementing k means clustering was actually kind of"
88000,94080," fun right so i do not regret that and i'll still recommend to watch those streams uh but that means"
94080,98000," that we're going to be doing a completely different things today right so we're going to be doing a"
98000,103840," completely different thing uh right so essentially what is a k nearest neighbor classifier it's rather"
103840,111520," an interesting thing uh right so let's actually google it up and in fact it is simpler it is in fact"
111520,120880," simpler than k means clustering right it is way simpler so essentially uh essentially uh what do you have"
120880,126000," imagine that you have a bunch of like uh points right so some sort of a data set"
126000,133840," and each point has a class right so on this sort of image the class is denoted by the shape of the point"
133840,140800," right so we have uh squares and we have triangles so and essentially you have a new point and your goal"
140800,147520," is to classify that point assign one of the labels right so you have the circle which is unclassified you"
147520,155360," need to decide uh so what is it going to be is it going to be a square or is it going to be a triangle"
155360,163040," so the point of key uh nearest neighbor classifier is to basically consider k nearest neighbors right for"
163040,171680," example we can consider it uh three nearest neighbor and assign a class to this point uh that is most frequent"
171680,180160," among these k nearest neighbors right if you pick a k3 uh the the class is going to be triangle but if"
180160,186720," you pick k5 the class is going to be square right because it's the most frequent one that is it"
186720,196160," that is freaking it mathematicians mathematicians are at it again seriously right giving a fancy name to a"
196160,201120," very stupid dumb idea of course it has to be key nearest neighbor classifier"
201120,210960," if i can yeah well it's it's literally that so and essentially it's more boring than uh"
210960,216560," gaming's cluster knowns the gaming's question is way cooler but i'm gonna give the link to this thing in"
216560,222960," the description uh as well so what's the idea of this paper what's the idea of this paper the idea of"
222960,230320," this paper is to classify documents right classify documents uh not only that but they wanted to"
230320,239680," demonstrate that a very dumb like absolutely fucking dumb approach is uh on par with the state-of-the-art"
239680,245040," ai language models and shit like that right they wanted to demonstrate that and as far as i can"
245040,253840," understand they managed to do that uh right so essentially you have um you know data set of text"
253840,260880," right so some sort of like a bunch of text and uh each individual piece of text has a class or a label"
260880,267920," associated with it right so and your goal is to given another new text that you've never seen before"
267920,274640," assign one of the classes basically k nearest neighbors right so but the way they compute"
274640,280960," the distances right for for these data sets for these data points is actually rather interesting"
280960,288400," right so you have a text and you need to compute like how you know close that text is to a certain"
288400,295280," uh to a certain thing right so uh let's actually go to the formula so this is like the only thing we need"
295280,302960," in here actually the only thing we need in here is this formula right so uh the distance is so called"
302960,312000," normalized uh compressed distance normalized compressed distance and uh x and y are the texts right so"
312000,319600," you have two texts and uh you compute normalized compressed distance and you are doing k nearest neighbor"
319600,326720," on that normalized compressed distance so how you compute that you concatenate x and y"
326720,336720," and you compress the concatenation of x and y with gzip literally with gzip and you take a length of that"
336720,344000," so this function c is basically compressing the input and taking the length of that that is it then you"
344000,351040," subtract a minimum between c of x and c of y so you take the concatenation of them and subtract the minimum"
351040,357920," of them separately and then divide by the maximum of them separately that's it"
357920,367520," that is and then you do k nearest neighbor uh and that classifies very accurately your text"
367680,375120," and it it works they demonstrated that this shit actually works the the question is why the"
375120,381520," does it even work it's it's really bizarre it's really bizarre why the something like that would even"
381520,393360," work so essentially um c is not like a random choice like using gzip is not like a random idea that they got out"
393360,400560," of the expression it's an approximation it's an approximation of kolmogorov's complexity"
400560,407600," right so originally they would like to use kolmogorov's complexity instead of the length of the compression"
407600,412640," but they couldn't because as far as i can understand uh computing kolmogorov's complexity over text"
412640,421920," is an p-hard problem so they couldn't do that and what is a kolmogorov's complexity this is a concept that i"
421920,428800," never heard before reading this paper because i am that ignorant i am that uneducated my university"
428800,433760," was shed i'm really sorry um it's kind of it's kind of embarrassing for a russian to not know what"
433760,439600," it's coming of complexity but but anyway let's put that aside so let's actually google up it's a really"
439600,444720," fascinating concept actually uh kolmogorov complexity"
444720,453200," so it's let's take a look at the definition"
453200,460720," kolmogorov complexity of an object such a piece of text is the length of the shortest computer program"
461360,467360," uh such as piece of text is the length of the shortest computer program that produces the object as the"
467360,476640," output so kolmogorov's complexity is the length of the smallest program that produces the text"
476640,484720," right so and as far as i know finding this kind of uh thing automatically is like np hard problem like"
484720,492240," that's why they couldn't do that but that starts to make sense that starts to make sense because uh"
492240,504640," right look um so essentially you can view compression algorithm as an attempt to produce a program that"
504640,515120," while evaluating uh produces the original text you can view a compressed text as a program and uncompressor"
515120,522800," as the interpreter as the interpreter that then produces the the original text you can actually view"
522800,529040," that right and since uh gzip is not like perfect right it's not going to be the kolmogorov's complexity"
529040,534160," it's going to be approximation of kolmogorov's complexity and it's going to be something that is super"
534160,540160," close to kolmogorov's complexity like maybe not super close but pretty close right so you can use it as"
540160,547760," an approximation and because of that like the better compression algorithm you use the better overall"
547760,554880," approach this approach is going to be so it's not like necessarily uh about gzip maybe in the future"
554880,560640," people will find a different like a better compression algorithm and you can you can just plug it in in"
560640,567840," here it will still work and it will work better right and why does it even work i didn't fully read the"
567840,574800," paper the only part i read is the essentially i think up until the experiments right so i basically read"
574800,580880," like all of these things up until experiments and specifically uh our approach right this section"
580880,587280," our approach is the most interesting section so why does it work so i think it has something to do"
587280,596880," with maybe x and y having common parts you know what i mean you know what i mean so if x and y"
597520,607040," have something in common the concatenation of them is going to be way shorter if they have nothing in"
607040,617360," common you know what i mean right so essentially if they are very very close to each other the"
617360,623600," the concatenation the compression the concatenation is going to be unexpectedly shorter which overall"
623600,629360," may result in a shorter length this is my hypothesis i didn't fully read it"
629360,637280," uh right but this is how i probably understand it right so does it make sense maybe it does make sense but"
637280,645040," um yeah so i think i will need to put the Kolmogorov's complexity to to the description as well and"
645040,650560," here is an interesting thing you can think about the Kolmogorov's complexity as a compression algorithm"
650560,658720," in fact Kolmogorov's complexity is the best compression that you can ever have right if you"
658720,663040," will have a program that computes somehow Kolmogorov's complexity you have the"
663760,674080," ideal compression algorithm perfect compression algorithm which is fascinating isn't it right and"
674080,683520," yet again this kind of demonstrates somehow um connection this weird connection between compression"
683520,693600," algorithms and ai right so because to produce a very good compression for"
693600,705280," example of a text you need to understand it i don't know like the better you understand the text the"
705280,712560," better compression algorithm you can produce which kind of goes into the area of ai and stuff like that"
712560,719520," so i don't know but anyway uh what i want you to do i want you to basically implement that right so i"
719520,724160," want you to implement that uh they already have implementation so interestingly enough that's"
724160,730400," they put the entire source code of the algorithm that they use in the paper and they formatted it horribly"
730400,734320," fucking horribly probably intentionally right so"
734320,744000," freaking ai scientist right so here is our entirety of our code enjoy right and some of these things like"
744000,745680," it's like it's completely fucking unreadable it's just like"
745680,754640," but in any case it's very simple uh but i would like to implement it purely in c right so like to"
754640,762240," implement it purely in c uh right and see how it will go and see how it will go they also talk about"
762240,769680," the data sets that they used uh right so for example they used a very diverse set of data sets uh"
769680,781360," so for example ag news right it it basically data set of 120 000 of uh article titles and descriptions"
781360,789760," they didn't take like the full articles uh they only took titles and descriptions right 120 000 for the"
789760,796080," training right and for the test the data set has seven seven thousand and six hundred right and it has only"
796080,801440," four classes maybe we're gonna just take this data set right so these data sets and we'll try to"
801440,809680," replicate uh the the algorithm on it and see how well it classifies these 7 000 test things among the the"
809680,815520," four four classes and stuff like that so yeah that's basically the plan the idea for today's stream uh"
815520,820800," right so we'll see how it goes we'll see how it goes all right so let's go ahead and try to implement"
820800,826080," these shy so we'll probably need to get these data sets somehow so as far as i know it's like all of"
826080,833120," these data sets are like open source and publicly available so we can google up ag news data set uh"
833120,839360," so i remember that ag news specifically was somewhere on github uh so there is of course hugging phase and"
839360,849600," stuff like that but i remember specifically this one was on github uh right so maybe it's that one maybe we have"
850800,859600," the google uh the google uh so this is just a topic text classification ag news uh so"
859600,863840," it's this one it's it has one star"
863840,872080," it's probably not the right one but i think i think it's that one isn't it so the data"
873360,882320," yeah there we go so you have a test uh which has some stuff right so yeah so here they are so you"
882320,887520," probably have seven thousands of this mother flippers yes look at it seven thousand and six"
887520,894640," hundred exactly uh exactly the amount that they listed in here so and this is for the test right i think"
894640,899920," that's the uh the set that they used i'm pretty sure that's the set and the training is probably yeah"
900960,911120," it's too huge uh you know 120 000 lines of text is impossible for the modern software to display"
911120,914640," at all it is impossible for the modern software to display"
914640,922160," uh right so let's go ahead and maybe just just clone this thing so and see how it is going to go"
922160,930160," so i'm gonna probably doing all of that in the k means folder right so even though it's not about k means"
930160,934720," i already kind of have like an infrastructure building here so i have a build system"
934720,940480," already i have a bunch of libraries downloaded uh as well so i might as well just roll with that"
940480,947280," so why not so let's actually go ahead and clone this thing um how many commits does it have does it have"
947280,954800," to me or only 13 commits so that's totally fine so uh let's just go ahead and do that easy peasy i lemon a squeezy"
959360,965200," so how's it going everyone mine the phone so it's already done so yeah"
965200,975120," uh text classification uh so here's the data and let's take a look at the train uh even emacs is afraid"
975120,984880," of 27 megabytes of of text what the is we what the with software these days i swear to god i mean like"
984880,992400," okay okay so i'm gonna say yes uh and there we go see it wasn't that hard okay so this is uh 120 000 so"
992400,1000480," that's exactly what we wanted in here so and this is basically csv and we have different classes in here"
1000480,1009440," though i'm not sure like what are the classes right so the problem with the classes is that they're just"
1009440,1018800," numbers and uh we don't really know what the classes are so there's some models in here um so i'm not sure"
1018800,1029040," if i care about that keg cargo right so maybe there's something in there class index class index"
1030720,1039680," where is that one world uh two sports three business so far okay so uh let me let me see so"
1039680,1049280," this is gonna be classes uh right so txt so i'm gonna just put it in here uh right so and i'm gonna just put"
1049280,1060000," this stuff in here uh yep so maybe yeah by the way so i probably need to i probably need to"
1060000,1063840," put that in the description right there we go"
1063840,1069200," uh so classes"
1072480,1077520," uh so do you ever create data no i didn't create the data so let's actually move that stuff in there"
1077520,1082880," and where is the classes classes yeah i'm gonna put that in here"
1082880,1089920," uh wait what okay that was weird so for for a second classes disappeared i don't know what the"
1089920,1096080," fuck happened in here but but anyway so i'm gonna remove this thing and uh so let's actually start"
1096080,1103200," with uh maybe uh maybe creating a separate file here uh right so i'm gonna call it knn right so this is"
1103200,1111680," going to be knn uh right and i'm going to just do something like this uh right i'm gonna just do"
1111680,1124320," something like this there we go uh print f hello world right and then in uh here we're gonna do knn"
1125760,1142800," okay and then let's see let's see so i'm gonna do knn just to see if it says hello world and it"
1142800,1150080," in fact says hello world so we need a way to actually you know parse the csv parsing this csv in"
1150080,1154800," particular is going to be a little bit more difficult than the something like leaf"
1155440,1159920," uh right something like leaf where we don't really have any special characters in the field"
1159920,1166240," so we can literally just separate everything by a comma right so we can just do that in uh this"
1166240,1173200," specific case in the data we don't uh we have a lot of special stuff right in fact we have a lot of"
1173200,1182240," special stuff um so we have uh quotes and stuff like that and yeah so what the fuck is this slash"
1185120,1195440," this data sucks holy shit uh like um so is that supposed to be like a new line or something um so"
1195440,1203360," i should have actually like downloaded from kegel but i can't download from kegel because it literally"
1203360,1210560," requires me to be logged in and i'm not even sure if i have a kegel um you know account and i'm not"
1210560,1215840," creating an account on this specific setup right now right so i should have done that right before the"
1215840,1224160," stream um so yeah i think that's their messed up new line oh my god so slow yeah so this is what i"
1224160,1234160," think so as well uh so but do they have like escaped oh my god they they do have escaping and also scuffed"
1234160,1238400," new line and also sometimes there's a double oh my god"
1242640,1250720," jesus christ bro the the fuck is this um so it would be nice nice maybe to download the download"
1250720,1256800," that from kegel but again like i need to register and i just like can't easily do that so apparently"
1256800,1262320," we'll have to deal with this kind of shit so it is what it is and it isn't what it isn't so yeah"
1262320,1269920," anyways so let's go ahead and just like try to read uh the the entire data right so reading how much"
1269920,1275440," megabytes like how many megabytes uh do we have in here like 28 megabytes for a computer for a"
1275440,1283760," modern computer is actually not that hard so uh so it should be pretty fast um uh okay so i'm going"
1283760,1291680," to do knob.h and i'm going to just define knob implementation uh let it go and let's just go ahead"
1291680,1302000," and read an entire file right so just read entire file and let's create a buffer into which we're going"
1302000,1311680," to be reading the contents right so this is going to be something like that uh right so path uh const char"
1311680,1319280," const char file path so this is going to be data um so this is going to be the training so we're going to"
1319280,1324640," load up the entire file into the memory right so that's what we're going to do so this is going to"
1324640,1330880," be file path and we're going to just give the pointer to the content and if it fails of course we're going"
1330880,1342560," to just exit with your exit code and in here we can just log knob info uh size of s is z bytes right so"
1342560,1349040," file path and we're going to just take the content count there we go so let's compile this entire thing"
1349040,1357200," and see how it goes all right so yeah so it read the entire thing it read the entire thing"
1357200,1369360," look at that so this is how quickly um at 10 years old laptop can load 28 megabytes into memory"
1372560,1378080," let's just just load it into memory github isn't capable of displaying this file at all"
1378080,1388400," let's just like less than 100 milliseconds loaded into memory and then unload it"
1388400,1394880," all right so how are we going to be approaching this entire stuff right so"
1395920,1403360," we could spend some time maybe parsing this entire thing we could spend some time maybe parsing this"
1403360,1414160," entire thing but what if we simply just split um the class and the rest of this stuff"
1414160,1422480," right because how would they classify this entire thing so i have a title and a description right if i'm"
1422480,1429360," gonna gonna gonna gonna be g zipping i'm probably gonna gzip concatenation of both title and description"
1429360,1437280," because that makes sense right so and if some of these special characters like commas will slip into"
1437280,1444160," into the jzip i think it's gonna be fine right there's nothing wrong with that so and there's definitely"
1444160,1452080," no special characters in the class so what i can do is basically split by the first comma right separate"
1452080,1459680," class and the rest of the stuff and do g zipping on the rest of the stuff that way i never have to"
1459680,1467680," even parse this i never have to parse the csv or anything like that so sounds like a cool hack"
1467680,1475680," maybe at some point i'll have to write like a csv library for for c right so there's already some csv"
1475680,1485280," libraries for ca like i know that csv c uh right so i'm going to pure c but all of them they're like"
1485280,1492400," like lip csv like they're proper libraries and shit like you're supposed they have configure scripts and"
1492400,1497760," make files and stuff like that you're supposed yeah there you go right look at that like a configure"
1497760,1503280," make file and it probably produces like a statically linked library you have to link it and stuff like that"
1503280,1512640," dude this is a problem for a single header library dude like why the does it have to be like that this"
1512640,1522000," is such a such a simple problem like what it's just like no no it has to be a proper library like with the"
1522000,1529520," proper documentation it's just like it's like that's what happens when java developers start a program in c right"
1530720,1539280," um so yeah that's kind of weird and so is there no stb csv i i don't even know honestly i don't even know"
1539280,1548480," maybe there is but i mean ah so it's it's not a really difficult thing to implement it's just like i"
1548480,1554480," don't want to do it right now right because what i have to do i have to just handle the quotes right so"
1554480,1563360," basically escaping within the quotes so that doesn't really matter okay guys so uh let's go ahead and"
1563360,1569520," maybe start working on all of that stuff so we can start with basically splitting everything by lines"
1569520,1575760," right so let's introduce something like uh while contents uh count is greater than zero right so we're"
1575760,1582480," going to be simply consuming the lines right so this is going to be a knob string view this is going to be the"
1582480,1592800," line and sv uh chop uh let me actually go there so a knob sv chop by delimiter that's the thing i want to"
1592800,1599200," have in here right that's the thing i want to have uh not the thing i deserve but the thing i want to have"
1599200,1603840," all right so and we're going to be providing the content and the delimiter is going to be"
1604480,1613120," the new line the new line and let's go ahead and just maybe print all of that stuff knob info and so"
1613120,1624560," the usual thing i like to do um so it's not really s it has to be sv fmt sv arg uh sv arg yeah come on"
1624560,1633760," bruv line boom let's just go ahead and recompile and run this thing uh okay segmentation fault"
1634480,1645120," yes that is absolutely freaking epic and surprisingly yeah i know why all right because"
1645120,1649120," i haven't yeah so why the fuck did it compile it's not supposed to compile"
1649120,1658320," wait what like i put in a completely incompatible pointer in there and that's just a warning"
1659760,1668000," in c i mean probably yeah i guess like i so used to actually like very strict warnings from other"
1668000,1673840," languages that i sometimes forget that in c yeah that that could be a thing uh right so"
1673840,1680640," that's kind of funny so maybe i'm going to just rename this thing to sb right and then i'm going to"
1680640,1692480," construct string uh view and i think there should be something like knob sv from parts where i can do sb"
1692480,1700960," items sb count and that constructs the content so that should probably work there we go so as you can"
1700960,1706640," see we are just doing that so it just spits out all of these things it's pretty slow but it doesn't"
1706640,1714080," really matter honestly uh it doesn't really matter so we can not even print them right so which is going"
1714080,1722160," to be extremely fast one of the things we can do we can just count lines uh count lines uh maybe lines"
1722160,1732080," count and essentially in here we can say plus plus one and we can just do knob log uh knob info"
1733360,1743520," so s contains lines right so this is going to be file path lines count lines count there we go lines"
1743520,1749280," count so how quickly is going to count the lines so it counted the lines relatively quickly so we can"
1749280,1755360," even measure the time so that's how quickly you can count the lines well i mean that includes also"
1755360,1762480," loading the entire thing into the memory so we loaded the entire thing into the memory the entire thing not"
1762480,1767840," stream read it or anything like just loaded everything into the memory and iterated through"
1767840,1770800," the entire thing counting the amount of lines that's how quickly you can do that"
1770800,1778800," which is a little bit too slow i think like it could be faster uh right so i think my read entire"
1778800,1785760," file is a little bit too slow right so that's how fast your computer is and again github is incapable"
1785760,1792480," of just displaying this right it can't do that uh it's unsolved problem yeah i see so"
1792480,1801440," my reading file is slow right so essentially i was so lazy to implement like a proper reading of the"
1801440,1810240," entire file that i'm basically reading it in chunks of 32 kilobytes right so the better way would be the"
1810240,1817040," better way would be to actually um like measure the size of the file right get the size of the file"
1817040,1825280," and allocate in one like in one batch uh everything and just like read everything that would be faster"
1825280,1831520," that would be even proper way to do that uh maybe we should do that how about that that's that's actually"
1831520,1839360," sounds interesting and then compare the uh compare the performance right so huh because as of right now"
1839360,1846160," uh right it's just like 100 megabyte uh 100 100 milliseconds and that already feels sus because i"
1846160,1855280," remember reading this entire stuff was way faster uh and map that but i mean when i start iterating"
1855920,1864480," over m map it's going to be basically reading it right so i don't know so i don't think it's going to"
1864480,1872640," make it like that much faster maybe it will but at the same time i also want to keep that implementation"
1872640,1879280," cross-platform and m map is not cross-platform unfortunately right so and if i'm going to start using"
1879280,1885920," m map that means i'll have to have separate implementation for windows right and uh yeah"
1885920,1891360," this thing also supposed to compile and work on windows right so if i if you take a look so there"
1891360,1899360," is a windows including here um so every time you suggest to do something for knob keep in mind this"
1899360,1906640," must work on windows it must work on windows right so i have projects that use knob and they must compile on"
1906640,1912560," windows so that's like a hard requirement uh right people suggest all sorts of cool but does it work"
1912560,1916880," on windows right so if it doesn't work on windows that means that for windows i have to do a separate"
1916880,1924240," implementation um if it's a sequential reading using m map is not very beneficial and not worth the risk"
1924240,1930960," importability exactly yeah i don't think it's it's worth that so um honestly there is a little bit of a"
1930960,1938800," problem i ran out of tea i ran out of tea and i would like to make a small break and refill my tea"
1938800,1943920," right and especially considering that my sleeping schedule is a little bit up so i'm a little bit"
1943920,1949760," sleepy right now i need extra tea i need extra tea so i really apologize for that but i need to make a"
1949760,1956800," small break so quickly make a break and we'll be back soon all right so let's go ahead and maybe try to"
1956800,1964480," speed up this mother flipper how about that how about that so read entire files so how and i wonder if"
1964480,1973600," it will actually speed it up um so interestingly the way i want to speed it up um i'm gonna just wrap it"
1973600,1982320," around in this uh you know macro that will allow me to flip flop between different implementations of this"
1982320,1993520," entire thing uh something like that so in here uh right in here i'm supposed to kind of like append"
1994320,2003440," right so yeah so in here i'm literally appending this entire thing um so maybe that's why i decided"
2003440,2010960," to implement it the way i implemented it but that's totally fine um right so let's go ahead and just like"
2010960,2019440," open the file so there we go we opened the file and then uh we checked if this file opened successfully"
2020000,2025040," so we also need some sort of a deferred section right some sort of a deferred section where we're going"
2025040,2032240," to be returning all of this stuff we don't really have a buffer anymore but we do have a file so there's"
2032240,2038160," also result uh variable that is very important because that's the thing that we're returning here and that's"
2038160,2045680," the thing that is set by the return defer um okay so and the first thing we need to do we need to figure out the"
2045680,2052960," the size of the file so the way you figure out the size of the file is by basically using fc right"
2052960,2061440," so essentially you set the the point uh the the cursor of the file to the end uh right so like so"
2061440,2072080," so as far as i know you do that by just setting whence to seek uh seek end right and it effectively sets"
2072080,2075840," the cursor to the end of the file the cursor to the end of the file and of course this entire operation"
2075840,2083520," may fail uh right it may fail so it may return something like negative zero uh i think let me"
2083520,2090240," double check so negative one not negative zero i mean it's not floating points so if sick just returns"
2090240,2100320," minus one and sets error no and stuff like that um so we could simply maybe not return defer but i feel like"
2100320,2108480," it is also responsibility of this function to say that something happened right so uh we can do knob log"
2108480,2120560," knob error um so essentially uh error uh well i mean it's already error right so we can do maybe knob"
2120560,2129440," read entire file s and then another s error no so this is going to be path uh str error error no"
2130080,2143680," right we can also maybe say fc right um something like fc um so we know at which stage it actually"
2143680,2152640," failed so after we set it to the end we should try to get the value of the cursor right we should try to"
2152640,2159760," get the value of the cursor and since the cursor is at the end it is going to be equal to the size of the file in"
2159760,2164560," bytes uh all right and what's interesting is that m is going to be the size but if it's"
2164560,2168080," if it failed it's going to be negative right so we have to check for that as well"
2168080,2174160," uh yep so this is going to be more like a uh"
2174160,2183120," f tell right and after we've done that we have to reset the thing back right we have to reset it back"
2183840,2192720," uh like so we have to reset it back but we have to do just basically set this is the second set"
2192720,2204000," hmm you know what you know what so there's too much uh you know reading in here maybe i could do the"
2204000,2212480," logging at the defer section right i could do the login at the defer section somewhere in here and basically i can do"
2212480,2223920," okay if result is actually false only then uh only then do the error logging uh and we can say something"
2223920,2234480," like um right now read could not um could not read file could not read file yeah maybe without that could"
2234480,2242560," not read file s because of s right so and because of that we don't really ever have to log anything we"
2242560,2250080," just have to return false and if an error has happened it will automatically log everything i think it's going"
2250080,2257440," going to be way better right like it makes the code more compact right which i which i like right which"
2257440,2266800," i kind of like so and maybe we can even align all of that by that and look at this does the code look good"
2266800,2274240," right for a language without exception i think it looks okay i think it looks okay it's just like an error happens"
2274240,2279600," in one of the separations and it short circuits in here right and automatically closes everything"
2279600,2285680," and stuff like that i think i think it's quite good i think it's quite good anyway right we can put it in here"
2285680,2291120," and essentially we know the size of the file we know the size of the file but we need to sort of extend"
2291120,2293760," the knob string builder"
2293760,2303680," so um the entire thing is supposed to like append this thing in here uh but i don't quite remember"
2303680,2312640," do we have uh this kind of stuff like noob um so because it was way easier to just append things"
2312640,2323280," right it was way easier to just append things so i suppose we can do sb uh capacity right so sb capacity"
2324960,2336800," and simply uh extend this entire thing because you you can just have a count right so you can have a"
2336800,2343040," count and you can say okay the new sort of count has to be this right so this is more of a like a new count"
2343040,2350960," all right this is a new count uh and then uh you need to check whether it's you know fits into the"
2350960,2358400," the capacity right so if new count is greater than sb capacity you need to extend the capacity so it"
2358400,2364320," becomes the new capacity how would you extend that well you would take the items right and you would"
2364320,2371680," reallocate them right so realloc with the new capacity new count and you just reassign this thing"
2371680,2380640," like this right so this is dead and then you say okay uh this is the capacity now right so new count"
2380640,2386800," a new capacity so we sort of like stretched this entire thing so now everything should fit in there"
2386800,2392880," and now we should be able to read everything in a single swoop right so something like f read"
2392880,2399600," but i don't remember how to use this piece of choice uh so let me copy paste this entire thing"
2399600,2407280," uh so this is f read of course so there's that so and uh how we are supposed to read this entire"
2407280,2412160," stuff so it's going to be items but we have to read it sort of like at the end so it's going to be sb"
2412160,2419840," the plus sb count right so and how many uh things we want to read in there well we want to read m"
2419840,2427600," bytes right so this is the size of the single element and we uh so this is a single sort of like a buffer and"
2427600,2435840," we want to read only one of these buffers right and we are reading that from uh from f right so and that's"
2435840,2441600," basically it so the thing about f read is that if it errors it doesn't really return you negative or"
2441600,2450000," anything like that right so it basically sets f error right if f error has happened uh right we just do"
2450960,2458240," knob return defer false and that's basically it so after that after we read everything we should set"
2458240,2465440," count to new count and that is basically it that is basically the new implementation that just like"
2465440,2472080," figures out the size of the file pre-allocates enough data and it just like reads everything in the"
2472080,2478240," singles the single you know what i'm talking about chat you know what i'm talking about"
2478240,2492800," so that should be cooler that should be cooler i think so uh and uh yeah and it also acts like it"
2492800,2500160," pans uh to to this buffer so the idea here is the following right so you can have uh knob string builder"
2501200,2509680," something like this and then you can do knob read entire file uh file one txt into that builder"
2509680,2517520," right and of course it can fail uh right so it can fail but then if you do it like this instead of"
2517520,2523760," cleaning up the string builder it will append the second file into the same builder it should act like"
2523760,2530480," that so you can concatenate a bunch of files if you want to like this and basically you just concatenated"
2530480,2536960," five files into a single buffer right so that's why i was spending some time with this new count"
2536960,2545200," like old count and stuff like that uh right so does it make sense does it make sense i think it does in"
2545200,2551680," fact make sense okay let's try to compile this thing and see like where it's going to fail okay so i forgot"
2551680,2559920," that this entire chat is actually uh a pointer thank you so much see very cool i cannot believe that we"
2559920,2567680," still program in this language in 2024 2024 yeah today is 2024 uh right but we do we don't have a better"
2567680,2577200," alternative i know what you about to say we don't have a better alternative for c c occupies c occupies a very"
2577200,2585680," specific niche and there's no language today that kind of kicks out c out of that niche"
2585680,2594400," i know what you about to say no no no no no no no no no no c is about simplicity c is about simplicity"
2597120,2608560," pascal pascal pascal was a good candidate to kill c actually right pascal was a good candidate to kill c"
2608560,2617680," i don't know all right is it going to compile it seems to be compiled so we managed to compile"
2618640,2629280," all right so yeah uh i hope we didn't make any mistakes uh so let's just go ahead and yeah could"
2629280,2637920," not open file for reading could not read for reading yeah uh so and let's do k and then um"
2637920,2646560," all right it it worked actually okay okay and then uh yeah it still works okay let's see if it actually"
2646560,2656560," speeded up nah surprisingly it didn't surprisingly didn't right so it doesn't really matter if you"
2656560,2663280," like read it in chunks of 32 kilobytes right i can actually switch the implementation right so let's do"
2663280,2670480," knob right i i'm switching the implementation uh right so i switched the implementation uh and"
2672000,2680080," yeah it doesn't matter surprisingly right so it's around uh 150 and 200 just it fluctuates around that"
2680080,2686880," so i suppose it really doesn't matter it really doesn't matter huh that's surprising"
2686880,2695120," all right that's funny but we're going to be using new implementation i want you to have this"
2695120,2701680," implementation anyway um right so i suppose it's more like on average"
2701680,2715120," though i'm just repeating it never goes beyond 250 right look at that there is not a single 250 or"
2715680,2724080," more not a single 250 it's with the new implementation uh with the old implementation"
2724080,2728320," all right how quickly we can do 110"
2730000,2743760," 50. all right so suppose the difference is negligible the difference is basically negligible"
2743760,2751120," uh the difference is basically negligible anyway so let's actually continue doing actual work right"
2752480,2759760," let's continue doing actual work so after uh that right so what we want to do we want to get the class"
2759760,2766080," right so we want to do sv chop by delimiter and we want to chop the line right so uh we're going to be"
2766080,2774800," chopping by this thing so and in here we're supposed to have the class right so god damn it okay so it's called"
2774800,2785360," class and the class and the class i would like to convert that class to uh to a number knob sv uh there was a way to"
2785360,2798960," to convert to u64 but i don't quite remember so is there any way to convert things to sister"
2799600,2808080," append sister uh yeah oh yeah you can do aster dupe you can yeah i think we can do a sprint tab"
2808080,2814960," right so anything i want to do i want to do a to i right a to i i swear to god i remember there was a"
2814960,2822720," way to convert to u64 but i think i didn't import that operation from from the sv.h i think i just didn't"
2822720,2828000," do that so i probably have to do a to i right so this is a to i but to be fair"
2829200,2836720," the class is one two three and four aren't they yeah one two three and four so that means i can do"
2836720,2846720," class uh item or maybe even data that minus zero and that's the class isn't it basically"
2846720,2856720," uh so then i can maybe have some sort of like a frequency analyzer uh classes right so i have four"
2856720,2864560," of the classes and all of them are zero so that means i can do something like uh classes like this plus one"
2864560,2877360," right and uh contains uh points let's call them points and uh in here i can do four uh size of i"
2878560,2889600," knob less than knob array len so this is going to be class says uh plus plus i and then we can do uh print"
2889600,2900080," f with print f knob log knob info so this is going to be z u and then we're going to have the amount of"
2900080,2906480," those things right so this is going to be i but plus one because they counted from one starting from one and then"
2906480,2912720," uh it's going to be class says i there we go and let's actually see how many classes of these things"
2912720,2922320," we have uh all right so this is going to be key and then uh yep oh that's kind of funny so we didn't"
2922320,2932480," have a single one class that that doesn't make any fucking sense i swear to get um so yeah i'm pretty sure"
2932480,2940080," remember that in the data train in the data train in the data train at the beginning of the uh of the"
2940080,2948560," row we had at least one in here we had at least one so that means i did if i i know what kind of"
2948560,2954640," fucky-wacky i did because i'm supposed to do minus one here as well yeah if i'm going to be doing it like"
2954640,2961840," that right i also have to do minus one right because they start from from one uh all right so we have"
2961840,2971840," exactly 30 000 of each class which is kind of funny isn't it which is kind of funny so we can also check"
2971840,2976480," the test uh but to do the test i think we need to start accepting file path of the parameters so let me"
2976480,2988000," quickly do that uh like argv uh so we can do const char uh program right so knob uh shift i think it's"
2988000,2996080," shift args right so it's going to be like this uh argv and then in here uh what we're going to do if arg c"
2996080,3001680," greater uh less or equal than zero so that means you didn't provide enough arguments so we're going to do"
3001680,3006480," knob log error no error i said no error"
3006480,3021200," usage s input txt maybe input csv that is even better and then we can say error no input is provided as"
3021200,3030640," usual and then we can exit with non-zero exit code and then we go so on in here uh knob shift i'm gonna"
3030640,3041120," take that uh there we go and here i have file path so maybe uh to save on time i should not"
3041120,3046800," rebuild these things right so we're only going to be rebuilding this stuff so program is not used okay so"
3046800,3056000," that's fine let's use it okay so no input is provided let's provide the data uh train right so we have data"
3056000,3063680," train csv uh and what about test csv yeah it's kind of funny how they're like there's equal amount of all"
3063680,3071440," classes it's kind of it's kind of fun okay it is what it is and it isn't what it isn't sure sure sure"
3071440,3081600," so um for each class for each class now we need to compress each individual class actually we need to be"
3081600,3095840," able to gzip them right to do that i suppose one of the things we have to do we have to uh learn how"
3095840,3109600," to use zlib right so as far as i know gzip uses zlib uh right so there's this library z lib and it's really easy to start using this thing it is really easy to start using it because"
3109600,3119280," um you just want to um i suppose link with lz right so just link with lz"
3119280,3125200," right so just link with lz and that's it so you have the library yeah there we go so as you can see"
3125200,3136640," so that's basically it so the main trouble is to how you even use that uh excuse me um i think it's like zlib"
3137920,3146480," and it's not even trivial to use so it seems to be compiling so uh zlib.h yeah there we go interface"
3146480,3160400," of zlib general uh purpose compression library okay so let me see zlib pure c example um zlib compress"
3160400,3170080," string prc example and then decompress and then decompress a string with zlib"
3170080,3172400," all right"
3172400,3182320," that could be a thing that we actually need in here please hold up for the uncompressed okay so please hold up for the"
3182320,3190880," compressed deflate so um they call compression deflate and uncompression inflate which i guess makes sense"
3190880,3197040," okay so the thing you're supposed to do you're supposed to create so-called z stream"
3197040,3206000," right so you assign a bunch of things like z alloc z free opaque so i suppose it has something to do so you"
3206000,3214560," can provide your custom allocator in here uh right so and then you just like define what's available and"
3214560,3222880," then some other stuff and it just compresses this thing so then you do deflate init with the best"
3222880,3234480," compression then you deflate with z finish and then you do deflate end and i suppose in b you're going to have"
3236000,3243920," noob string so we should give it a try that's kind of a weird thing but yeah let's give it a try"
3243920,3254640," so key on then uh so um deflate sv so i think that's a good idea generally i think that's a good idea"
3254640,3264400," so it's going to be a knob string view right knob string view and you're going to be accepting uh sv here as well"
3264400,3270960," i think that makes sense uh so where are we going to be allocating where are we going to be allocating"
3270960,3277520," stuff for the compressed one we can allocate that in a temporary uh buffer right so temp yeah tempo log"
3277520,3285920," so essentially we can just pre-allocate stuff in there so sounds good sounds gucci sounds tamaguchi and"
3285920,3292400," as soon as we manage to do that so using this thing should be relatively straightforward hopefully uh i don't"
3292400,3298640," know i don't know we'll see we'll see so z stream um let's just allocate this thing in here"
3298640,3304800," shouldn't we actually like you know fill it with zero i think that would make sense and that would"
3304800,3310400," like yeah if you just allocate it like that you don't have to do these kind of things right so because"
3310400,3315200," they're automatically going to be zero right so i think i think that's worth it i would like to take a"
3315200,3321040," look at the definition of z stream uh right so here is the z stream there's a lot of shit in here look"
3321040,3330880," at that so used to allocate the internal state used to free the internal state um so if i put void"
3335120,3342000," anyway uh so private data object a pass to zero okay so that's kind of funny so you you can just use"
3342000,3349280," like a custom allocator and stuff like that that's kind of funny uh all right so that means i don't have"
3349280,3361200," to do that but what i have to do in here uh right i have to pre-allocate some stuff so the length"
3361200,3370240," size of input string plus terminator but we don't really have a terminator that's what's funny about"
3370240,3376800," this kind of thing uh we just have a count right maybe i have to cost this thing in here but i mean"
3376800,3383760," it feels a bit unnecessary uh input characters is just that right so this is the data what's going"
3383760,3389120," to be the outputs like and how do we know that the output is going to be smaller than the inputs"
3389120,3396800," how do we know that i'm not i'm not really 100 sure honestly uh cannot just allocate it for us"
3397440,3404160," like look we are providing allocators right we're providing allocators can it just like allocate the"
3404160,3414720," output for us uh next output byte will output byte will go here uh remaining free space at the next out"
3414720,3421280," uh total number of bytes output so far so yeah"
3424000,3429440," available in so it's sort of like this api is sort of designed to like sort of stream"
3429440,3438400," the the entire thing right so it's designed to stream um so it's rather complicated actually it's"
3438400,3448080," rather complicated um so what i can try to do i i can try to just like do knob uh temp uh allocate and"
3448080,3454560," i'm going to just allocate twice as much as much as much as i have in there right so um this is going"
3454560,3456960," to be like the output like this"
3456960,3467840," output char array um all right so the size is going to be basically sv count multiplied by two"
3467840,3474000," right so this is the output and that's the that's the output i suppose um"
3475280,3482640," bit bizarre if it's compression shouldn't by definition be smaller than the original i don't"
3482640,3489760," know honestly right so sometimes you have small files uh right very small files like i don't know"
3489760,3498880," something like echo hello hello txt uh right so and it's a very small file like six bytes and then"
3498880,3507120," you try to gzip this file right so you're trying to gzip and you end up with uh 36 but we can you can"
3507120,3513920," argue that maybe it's something some metadata of the gzip format i don't really know right so"
3513920,3523200," it's just like what exactly why exactly it became bigger like is that because of how gzip works on a very small data"
3523200,3529680," or is that because like i don't know like why so should we also account for that"
3529680,3537280," uh how do we account for that like why do we even have to account for that if maybe we should can ask"
3537280,3542480," the uh the library to allocate all that stuff like i don't know like how do i handle that i"
3542480,3549760," no idea right so that's why i just allocated twice as much hoping for the best so that's that's"
3549760,3555680," that's what i'm doing uh just hoping for the best because there's so many unknown like parts that i"
3555680,3562000," can't predict uh so i probably need to read the commentation but it will take some time i don't freaking"
3562000,3571280," know anyways so we want to do deflate and then uh yeah we'll do this kind of thing and"
3573120,3578800," so they're doing a little bit of a sus thing in here they're doing a little bit of a sus thing in"
3578800,3587520," here they're using esterland for b and that doesn't look good that doesn't look good yeah so people even"
3587520,3594560," mentioned that so so they suggest to use total out they're basically suggest to use total out and"
3594560,3603120," this is something that we can use we can just do knob sv uh knob sv uh from parts so this is the output"
3603120,3612320," and then we can do z stream uh total total out right so total out sometimes so we can try to do it like"
3612320,3621360," that right so we can try to do it like that and again it would be super nice if i could tell zlib just"
3621360,3626800," use the allocator that i provided to you and just like allocate all of that for me"
3626800,3635600," all right just like like why do i have to do that uh will never remain space at the next output so yeah"
3635600,3643440," anyways uh so anyways anyways anyways anyways um"
3647040,3657200," so maybe yeah how can we even test that how can we even test that how can we even test that we can"
3657200,3667440," try to take one of the lines right so we can start let's limit uh like how many lines we handle in here"
3667440,3676480," let's try to handle um maybe first 10 of them right so first 10 of them so we have a class in here"
3677040,3691600," uh we have a class in here and maybe we can do class index and we can put that stuff in here so line"
3691600,3703440," count line count i think it could be useful actually it could be useful and funnily enough instead of i we could have used"
3703440,3710880," the line count right so we could have just used line count lines count lines count"
3710880,3719920," lines count so we didn't have to do plus plus at the bottom in here so we have a limitation and we also count"
3719920,3732320," the amount of lines and stuff like that so okay we have a class right so we have not even yeah so this is the class and within the line we have the"
3732320,3739760," the data that we want to compress the data that we want to compress so maybe we want to print"
3739760,3743040," some interesting stuff in here right so it's going to be knob info"
3743040,3752560," uh we're going to say class so this is zu then uh uncompressed len it's going to be one thing and then"
3752560,3759600," compressed uh compressed uh len is going to be the second thing uh so here i'm going to just provide the class"
3759600,3768720," uh like so so uncompressed length is going to be a line count and then um so what was the i think it was"
3768720,3778640," deflate sv right so deflate um sv we provide the line and we take a count of that so and then at the end"
3779200,3788480," we can simply do knob temp temp reset which deallocates the allocation that we did inside in here right it"
3788480,3797200," will automatically deallocate this entire thing um so and yeah so we're going to just handle first like 10"
3797200,3808720," lines and see how much it compresses their uh their descriptions pro plus titles so maybe we can even uh print the line count"
3810000,3818720," right lines count and let's just go ahead and try to run this entire thing something is really weird"
3818720,3827040," going on right so let's go ahead and do that so there's some stuff in here z stream so this is the def def stream"
3827760,3833440," okay so uh-huh so uncompressed len"
3833440,3842240," went completely haywire all right that's it and okay so something is definitely wrong in here so let me see"
3843520,3846640," okay okay so lines count class um"
3846640,3860080," uncompressed comp that is bizarre straight up that is straight up bizarre um so why line"
3862480,3872080," one two two three four one two three four all of them are z use so i don't really know"
3872080,3880800," very effective compression indeed i do agree with that very effective compression"
3883440,3896320," um so yep yep yep yep yep yep yep so line does it fuck up something i literally don't understand why it is like that"
3897120,3905920," um so because i just did chop by and class worked perfectly"
3905920,3916240," uh so knob in four z u line count"
3919760,3928560," it's totally fine it's totally fine it is in fact totally fine okay so if we don't compress this in"
3928560,3932240," okay there's a new line in here so maybe the new line actually fucks it up"
3932240,3937200," excuse me so let's remove that stuff"
3938320,3946240," yeah so what the fuck is going on in here what the fuck is going on that is weird"
3946240,3955280," something with the printer specifically i feel like there's something specifically with the printer"
3955280,3963840," so um if we just do line count if we just do line count it's totally fine"
3966000,3969200," uh okay so what about class index"
3969200,3981920," um so class index oh i was using class in here so that's what okay i should have used class index"
3981920,3987280," okay so this is the problem with the custom custom printers like that that's the problem with the"
3987280,3993360," custom printers and on top of that like what the fuck is this shit well yeah so one of the things we have"
3993360,3999680," we have to do actually we have to skip um the first line we have to skip the first line if"
3999680,4006080," because the first line if we take a look at the training right it contains the the header"
4006080,4012400," right so one of the things we can do lines count equals zero just continue right so we get the first"
4012400,4020720," line uh right it's the first line just just ignore ignore the header okay so this is the class and this"
4020720,4028320," is the actual class index and uh so on and so forth so class index like this so i see what was going on"
4028320,4037200," all right so uh lines count all right so we haven't compressed length and stuff like that so everything"
4037200,4047440," seems to be okie dokie uh compressed uh lem is going to be zero so deflate sv deflate sv i set line"
4047440,4055360," count how many things we can even compress in here and uh there is a little bit of a compression if you"
4055360,4062880," look at that so for example uh we can yeah we can say how much compression how do you compute compression by the"
4062880,4070080," way how do you compute compression you divide compressed one on uncompressed one what is the compression rate"
4070080,4076960," compression rate definition what's the definition then remember uh data compression ratio is just like a"
4076960,4086160," compressed over uncompressed and okay so uncompressed size uh compress size okay so uh we have a line"
4087280,4100800," uh after that uh after that we can have knob string view uh compressed line and we can just take that so here's the compressed line"
4105360,4111200," all right compression ratio uh all right compression ratio it's going to be f"
4111200,4121600," so we take uncompressed so just the line but that has to be flowed and we divide it by uh compressed one"
4121600,4133920," so let's see so and yeah uncompressed size um so i think we're most interested in"
4136080,4146320," save saving space right so because of that we probably want to swap this value swap this value and do"
4146320,4156080," minus one and say save the space because that's interesting right so 20 of the saved space usually"
4156080,4162640," right in average so it does compress some stuff it does in fact compress some stuff it's pretty cool"
4164160,4170800," uh it does in fact compress some stuff mother flipping stuff all right so"
4170800,4178080," and usually the result is smaller than than the other thing right so we can take a look at maybe"
4178080,4186160," thousands of them and yep yep yep yep yep yep yep yep so uh what i'm interested in what i'm interested in is"
4186160,4192400," how quickly it can compress like all of them uh how much time does it take for to iterate through all of them"
4192960,4199520," pretty fast pretty fast pretty fast i really like that i actually ironically like that so and"
4199520,4206240," this is only test okay so it took almost 200 milliseconds to go through the test file"
4206240,4214880," though test file what about training because to classify a single test sample a single test sample"
4215920,4220240," we have to do so we have to iterate through all of the 120 and compute the normalized distance"
4220240,4231280," on top of that we'll have to then sort by that normalized distance and do the uh like k or something"
4231280,4244640," um so yeah so let's go ahead and do the training uh training csv uh that was fast as well actually what the hell oh wait okay okay okay okay okay okay okay okay okay okay okay"
4244640,4250160," that's easy it's it's it's thousands of them this is because it's thousands of them it's it's easy"
4250160,4256400," okay so let's actually do 10 uh 10 thousands so it may slow okay"
4256400,4262160," it starts to getting slower so it's just like one second"
4263200,4270800," one okay okay so let's remove the limit let's remove the limit and like see how much time it"
4270800,4274080," will take to to compute all that stuff so i suppose it's going to be around"
4275520,4283120," maybe half a minute to yeah to classify a single thing interesting interesting interesting interesting"
4283120,4291680," so it's taking some time yeah okay so um almost 20 seconds almost 20 seconds to iterate through each"
4291680,4301920," individual thing um but what's interesting is that we'll to classify a single sample uh to classify a single"
4301920,4307680," sample we'll have to also do several compressions um"
4307680,4320400," several compressions so yeah that's very interesting okay okay okay okay okay"
4324960,4333120," i kind of want to do another break because i need to refill my cup of tea again uh right because i"
4333120,4342640," literally ran out of tea again so let's make another small break right so um all right so uh what we"
4342640,4346240," want to do what we want to do what we want to do do we want to actually maybe"
4346240,4354800," collect all of these things into sort of like a maybe separate collection right so because we need"
4354800,4363440," to keep both training set and the testing set in memory right so we need to keep them both in there so"
4364240,4372320," maybe we need to keep them in there so maybe we need to keep them in there so this is going to be"
4372320,4372880," the class"
4372880,4378240," and the data right so maybe the text let's call it text"
4378240,4388640," so and that's going to be a sample about that that's a good it's a good way to call it i think that's a good"
4388640,4395040," way to call it and uh we also probably need these samples right because we're going to be collecting"
4395040,4403840," um them right into a dynamic array because then we'll have to sort that thing um so yeah that's"
4403840,4409360," going to be interesting so this is going to be a bunch of samples uh so the sample is going to be"
4409360,4416240," items and then we have a count of these things and we have capacity of these things right so we have"
4416240,4424320," this kind of stuff all right so and then um as we parse all of that stuff all right so for now i'm"
4424320,4430640," not going to be doing compressing or anything i'm going to just i'm going to be collecting the samples"
4430640,4436000," right i might as well just do samples samples samples"
4438000,4450560," like this like this and knob knob knob da append i'm appending to samples and what i'm appending there is"
4450560,4453120," sample"
4453120,4460480," class class index and then text"
4463200,4473520," line right so we're just collecting those samples maybe maybe we could even factor out reading and"
4473520,4480320," parsing the file the csv file into a separate uh separate function so we could say something like"
4480320,4489760," read uh samples from file and of course reading stuff from file can fail so what we want to like to do"
4489760,4498000," ultimately um ultimately um ultimately we want to maybe um return an error but i mean"
4498000,4506080," yeah it would be better to actually split that step into two uh so let's actually do something like parse"
4506080,4514400," samples right so we're parsing the samples but what we're doing here we're actually passing the content"
4514400,4523840," right so passing the content uh so that's basically what we want to do so in here and here we are gonna"
4523840,4535600," do something like this uh yes yes i'm gonna just move this stuff in here and then we're basically parsing"
4535600,4543920," the sample so we have a content and maybe i'm gonna even do it like that i'm gonna just literally inline the"
4543920,4549520," this entire thing and the samples i have the train samples right so this is the train"
4549520,4558960," and honestly honestly i think um i think i need to start accepting two files in here right so"
4558960,4566240," train csv and uh test csv right so we're gonna accept both of them because we need to read"
4566240,4573280," uh both of them into into the memory and parse them uh right and we're going to be iterating the test"
4574000,4578400," samples uh samples and comparing them to the training samples to figure out the tests um"
4578400,4583200," category right so to figure out the test category i think it's going to be interesting"
4583200,4590480," uh so you know what i forgot to do i forgot to actually have classes somewhere the names for the classes"
4590480,4598240," so data classes it would be kind of nice to maybe have some sort of an array of those things"
4598880,4607040," uh right maybe even as strings maybe even as strings you know i've got an idea"
4607040,4615440," i've got a freaking idea what if we just like literally go to ag news right i hope my government"
4615440,4622880," is not going to kill me for showing some news some western news uh i'm joking they don't give a"
4622880,4625440," shit about what's going on in english um"
4627440,4631120," uh where's the ag news"
4631120,4639120," the what was the website why it doesn't show me that"
4641440,4648400," like it's so bizarre wait i think i'm pretty sure ag news was some sort of a website wasn't it"
4648400,4651200," i think i think it was a website um"
4653280,4660160," okay maybe i'm maybe i'm imagining it"
4660160,4667680," only i only know ap news as i said ap news okay"
4669840,4672720," why is it so oh my god my my laptop is fucking dead"
4672720,4676400," all right"
4676400,4689040," we can actually yeah so we can try to take one of the titles and descriptions from here for instance"
4689040,4692480," right and try to classify that"
4694000,4700560," given the existing dataset that would have been interesting that would have been interesting"
4700560,4704400," and to be fair this amount of classes is actually kind of limited in my opinion"
4704400,4706640," uh right so"
4706640,4709920," let's see we'll see"
4709920,4712320," anyways so uh"
4712320,4722880," for some reason like in 2024 like in in the modern years kind of it became kind of difficult to like find"
4722880,4726880," anything on the internet it's just like everything is so fucking filtered"
4726880,4733760," um and it's just like it feels very small in the internet it's just like"
4733760,4738640," anyway uh so class names"
4738640,4749360," the internet feels increasingly smaller and smaller and smaller you're being put into this small little"
4749360,4752960," cage into this bubble into this bubble it's very difficult to escape"
4752960,4766800," so ag news is antonio i think i confused it with ap news right i think i confused it with ap news i think that's what it is"
4769760,4778240," yeah all right all right all right so we have this kind of stuff so i want to say train path"
4778240,4783520," right so this is a train path so and in here we can say train"
4783520,4788000," um buffer or maybe train content"
4788000,4795600," right train content so this is a train content and uh this is the train samples"
4796480,4803040," train samples so then um afterwards we can kind of repeat"
4803040,4812400," uh train sample train file no train files is provided so in here"
4812400,4821120," we can say no test file is provided and we can kind of replace train with test in here"
4822560,4830400," all right and there we go we have two things train samples and test samples right and one of the things"
4830400,4837840," we can do we can just try to go through each individual test sample and try to classify this thing"
4837840,4844960," so it would be nice to even have a function uh that returns like classify classify"
4846640,4855280," sample uh all right so we can supply samples in here like a trained sample and then uh we could have like"
4855280,4865040," a text just simply classify this text you know what i mean uh like to do not implement it"
4865040,4870880," all right and that will basically go through each individual thing compute the"
4871760,4878800," ndc normalized distance normalize ncd normalize compressed distance and then do k nearest neighbor"
4878800,4886320," right so and afterwards right to do the k nearest neighbor you need another uh actually struct right"
4886320,4892160," you need another structure which basically contains the distance right and i presume it's going to be flowed"
4892160,4897840," because we're going to be doing divisions and stuff like that and it also has a class right so we can"
4897840,4903360," call it we can call it normalize ncd compressed distance is it is it how it's called i think i think"
4903360,4909840," that's uh normalized compressed this distance right so and uh you're going to have a bunch of those"
4909840,4916160," right so because we're also going to be sorting by them uh so that's kind of important and see this"
4916960,4924320," and see these nuts so these are the items and then we're going to have count and then we're going to"
4924320,4935200," have capacity and there we go we haven't seen this so and um yeah that's going to be very very important"
4935200,4940560," very very important but i mean i was just slapping the cook without even trying to compile any of the"
4940560,4947040," shit so it probably doesn't compile in the slightest so let's go to the compilation errors uh so what do"
4947040,4958960," we have in here knob uh passes two arguments um but takes two so is knob da append oh yeah it is in fact"
4958960,4967360," actually uh a macro so that's understandable so this is a knob string view what else do we have in here so"
4968320,4974320," uh some of these things are unused i mean it's not that big of a deal so let's just mark this"
4974320,4983120," shit as unused what else we have in here so this is a file path uh this is a train path and uh train content"
4983120,4991760," what else do we have in here uh train content there should be like a function to convert uh string"
4991760,4997600," builder into uh string view there should be something like that but i don't have that yet"
4998480,5007120," uh so i don't have that yet so test content that goes what else do we have in here so test samples and"
5007120,5013280," then use that is unused what else do we have in here so in here we have just a control that we have to"
5013280,5020640," return it like that so this is the samples boom what else do we have in here okay so that's cool uh we can"
5020640,5026320," try to now provide uh we didn't provide the test let's provide the tests uh and okay so everything"
5026320,5035760," was loaded and parsed right so we loaded and parsed both of the files uh which is super cool so the next"
5035760,5043360," thing we can try to do we can try to classify um maybe one of the texts right so that would be interesting"
5044080,5050080," so essentially we provide the train but the text that we want to provide in here is going to be"
5050080,5057360," essentially test samples let's just take the first thing from the test sample uh all right and a single"
5057360,5067200," sample is what it contains the text right um so let's maybe even put that into a separate sort of sample in"
5067200,5077200," here so we're just classifying uh right a predicted class right so this is a predicted class and we can"
5077200,5086880," try to print all of that stuff right so let's take a look at knob info uh text so we have text like this svfmt"
5086880,5102160," as we are so sample text and uh we can do knob log knob info uh predicted class it's going to be like this"
5102160,5110400," it's going to be even s uh we have class names right so uh class in class what was the"
5112480,5122080," class names yeah there we go class names uh class names so this is the predicted class uh and then actual"
5122080,5133280," class actual class is going to be sample class something like this there we go so train uh samples"
5136000,5142640," all right so uh assertion failed yeah so we need to implement finally implement the classify sample"
5142640,5149040," that's what we need to do uh predicated uh yeah predict"
5149040,5158000," predicted predicated huh that's interesting it's like one character away predicted"
5160960,5168800," predicted all right so the next thing we need to do we need to actually uh keep track on this uh all"
5168800,5175120," these ncds right we need to keep track of them uh since we're going to be iterating through the"
5175120,5183600," training set and finding the distance um we need to keep collecting all of that stuff we need to keep"
5183600,5199040," collecting maybe by the way we can have a function ncd knob string view a knob string view b right so let's"
5199040,5207600," actually go ahead and compute that so basically encode this formula so we want to have cx uh which is"
5207600,5212960," basically we need to compress this entire thing right so it's going to be uh maybe we can even do"
5212960,5224240," deflate uh sv right so we do deflate sv a uh and it's going to be simply count and y um let's do it"
5224240,5233360," like this so we have these things uh right but that's not enough also right so we need to concatenate"
5233360,5242160," two things so maybe we also need to have something like cab um and it's going to be deflate a b"
5243120,5249520," like so but now we need to construct a and b um should be pretty straightforward i think i think it should"
5249520,5257600," be pretty straightforward because one of the things we can do we can do knob temp um as printf and here we"
5257600,5267360," we can do s v fmt s v fmt uh and then maybe we can even put well i mean yeah we can just concatenate it"
5267360,5278960," like that s v arg a and s v arg b and there we go we've got basically a b but it's going to be c string"
5278960,5287120," right so as far as i know uh there was a way for me to construct a string view out of that so from"
5287120,5297520," sister yeah so it's relatively easy to do so uh so that creates knob string view a b so that's what it"
5297520,5305680," creates and now i have all these things in here so that is cool that is cool so and now i can do c a b"
5308240,5318960," uh c a b and i need to subtract minimum all right so maybe i can do something like float m n"
5321200,5328880," c a if minimum is greater than c b meaning becomes c b so that's basically the first thing and with a"
5328880,5340800," maximum uh c a maximum less like this so now i have minimum and maximum and i can just subtract minimum"
5340800,5346080," right and divide by the maximum and that's basically the formula that we have in here"
5347360,5354000," right so all of that does a bunch of allocations in the uh temporary buffer but that's fine because"
5354000,5362400," we're going to be cleaning up that buffer as we go um right so that is very very cool so let's go"
5362400,5369200," through the training set so this is going to be like this uh less than train so it's going to be count"
5369200,5383280," plus plus plus i and uh so let's just do ndc on those things uh right so we're gonna do train items i and"
5383280,5390560," then the text all right so and that gives us the distance that uses the distance and as soon as we can"
5390560,5395040," uh compute the distance we don't really care about the temporary data that we put in there so we can do"
5395040,5400960," the knob to temp uh reset right and it's very important otherwise all of these allocations are gonna"
5400960,5412240," like you know overflow our temporary buffer so we have a distance um and the class uh is the class of these things"
5412240,5430880," like so uh knob da append we're appending to ncds uh and so ncd is basically distance distance uh class train items"
5430880,5439920," uh class like so there we go and interestingly um"
5441600,5445520," that's it right so we computed all the all the distances and stuff like that"
5445520,5449440," so uh the next thing we have to do we have to sort them"
5449440,5455520," before we do them by the way we can try to maybe print them"
5455520,5458400," that would be interesting or at least print like first ten"
5458400,5464720," uh so maybe top five top cinco"
5467440,5472160," so tops the top top cinco uh ncds"
5472160,5479680," sorry means a permanent apparently permanently damaged my brain i really apologize for that"
5479680,5488240," uh okay so we're gonna do like five uh plus plus i and also i less than ncd's count"
5488960,5498640," and let's just like print them knob log um right class uh so this is the class and this is distance"
5498640,5505280," right so it's gonna be app um and cds items and this is class"
5508320,5520000," and this is like a predicted class not predicted actual class blah blah blah blah but that's going"
5520000,5526320," to be printed by the classified sample right so as of right now i'm going to put 69 because it's a"
5526320,5536080," temporary thing um right as well assert that this thing is not implemented yet like so to do not implement it"
5536080,5541440," let's try to run this entire thing and go through the compilation areas of course"
5542400,5554400," what else do we have in here items so this is i uh incompatible type one of ncd so this is bizarre"
5554400,5560880," right so because it's supposed to be string view all right so that means i supposed to put text in"
5560880,5567360," here that makes sense what else do we have in here uh huh i forgot semicolon is that what you want that's"
5567360,5577360," probably knob info boom what else do we have oh it's okay so it's going to be around 70 seconds so"
5577360,5587520," the problem with this thing is that um to classify a single sample we need to wait 17 seconds so that's"
5587520,5593840," kind of at least on my laptop while i'm also streaming right but we're not even parallelizing anything"
5593840,5600000," right we're not utilizing the power of multi-threading so maybe we can cut down the time"
5600000,5607360," is it going to be cut in four right if i do something like 17 divided by four"
5607360,5609760," right so four seconds probably not"
5609760,5621360," actually it will take more time because we're doing at least three gzips in here we're doing at least three gzips"
5623360,5630720," so yep i wonder how much time it will take it will take like a more than all right so that's cool"
5630720,5636320," so it took like a minute to classify a single thing"
5636320,5645760," uh right so but this is a very naive approach no prioritization and we're doing that only while"
5645760,5654240," i'm streaming while i'm streaming uh on a 10 years old laptop so yeah so that's i guess that's expected"
5654240,5661760," like i didn't put any effort into optimizing this entire thing so maybe i will maybe we'll see how it will go"
5661760,5670720," okay so the next thing we need to do right so we've got some distances and stuff like that right so that's"
5671440,5678960," that's totally fine that's totally fine so and one minute is okay right so we can wait for one minute"
5678960,5687360," in like uh on the string so this is bearable at least uh now what i want to do i want to"
5687360,5695440," uh basically sort this entire stuff right so we need to sort ncds by the distance right so because we need to"
5695440,5702240," need to pick the uh k uh closest ones and what's going to be the k though right so that's a very interesting"
5702240,5708320," question so what's what's the k you usually pick do they even mention what k they used"
5709440,5725360," do they give it like 10 100 so we have a lot of things maybe something like thousand k thousand could be"
5725360,5726000," could be a thing"
5732880,5740640," from the brief scrolling through the page it's kind of not obvious what kind of key do they use"
5740640,5754240," uh so it is really not obvious so i don't know okay so i suppose we're gonna pick something uh q sort"
5757520,5761040," um so let's do the sorting"
5761040,5772960," so the base we're doing uh ncds items so the amount of items we have is ncds count and the size of a"
5772960,5782880," single item is basically ncd items size of right so that size of and we need to have a function that compares"
5782880,5789600," ncds and cds right so let's have something like compare ncds and cds um"
5789600,5794720," and maybe i'm gonna take it like that"
5794720,5805600," so that's the function we need that's the function that's a really weird so size void"
5810160,5816960," okay as far as i know they're just like a void pointers right so this is going to be a uh this is"
5816960,5829600," going to be b um and so we just return an integer and um so we need to cast them to ncd uh right n a"
5829600,5839600," a and b b and we want to just compare those things so if an a distance"
5840160,5849920," is less than an n and b distance right um so it has to be less than zero so that means it's going"
5849920,5859600," to be minus one uh right if an a distance greater than n b distance is going to be uh one otherwise"
5859600,5866240," it's going to be zero it's very dumb approach but yeah so that's that should be fine so and we just"
5866240,5871280," sorted this entire stuff right so we just sorted this entire stuff and the question is what's going"
5871280,5876800," to be the k right so what's going to be the actual k in here so since we have so many samples in here"
5876800,5882800," maybe it makes sense to actually pick like thousands of them uh sounds like what do you guys think um"
5882800,5889600," k is equal to the number of classes no it shouldn't be like that we have only four classes and for"
5889600,5903520," can you pre-compute deflated uh length of the training and the test data and save it to the file"
5903520,5913600," i can uh but this is not the only thing that we need we also need uh deflated uh this deflated uh"
5913600,5916240," length of their concatenation"
5916240,5925200," so that means size of the training set multiplied by the size of the test set which makes it even bigger"
5926240,5933440," so i mean i have to pre-compete that off screen on a separate computer if you know what i mean so"
5933440,5944160," uh all right so okay class we need to have like a classes frequencies so we can do that but that's"
5944160,5952720," not for the stream uh that's why i don't do that right now class freq um so it's going to be four"
5952720,5964560," and this is going to be like a zero all right so let's do size t uh less than ncd's count uh plus plus i"
5964560,5977760," and also less than um k something like this and we can do class frequency um this frequency"
5977760,5984400," ncd's items i class"
5984400,5993440," plus one right so we take the class of this thing we increment the frequency and now we need to find the"
5993440,6000640," maximum among them we need to find the maximum among them and that's going to be the x like"
6000640,6009760," classified thing we might as well even pass k as a parameter all right so it could be literally a"
6009760,6021040," parameter because why not all right so how can i even do that so class um predicted uh dictate class"
6021040,6029200," is going to be minus one for now uh and i'm going to just iterate uh the amount of classes that we have"
6029200,6039840," ideally i would like to maybe even have class yeah maybe knob array length class names so we allocate as"
6039840,6047200," many as we have like names for these classes and we're going to be iterating as many as we have those names"
6047200,6060080," right so i think that makes sense uh right if uh predicate predicted class why do we have predicted class here as well"
6060080,6069120," where did they okay that's unacceptable honestly why does it start with c it's not supposed to start with c okay"
6070800,6078720," uh predicted class uh predicted class if predicted class is less than zero right so that means we are right away"
6078720,6085280," are doing uh predicted class equal to i"
6085280,6093040," which means that i could have just like done it like that all right"
6094800,6098400," uh so then uh so then uh i can do class frequency"
6098400,6109760," predicted class predicted class if it's less than uh class frequency of i"
6109760,6116640," then i just assign okay so that was easier than expected"
6118880,6125520," because we have to work on a level of uh indices so that's it that's the whole algorithm should be at least"
6125520,6129520," that should be at least the whole algorithm"
6129520,6135840," all right so uh that's pretty cool game"
6135840,6140960," okay let's give it a try let's go let's go at least through the compilation errors"
6140960,6151200," uh i think they are gonna be rather interesting okay so um what don't you like const okay sure i can mark"
6151200,6158560," them as const too not that big video of course uh i should not forget to do it like that"
6158560,6161440," of course"
6163520,6171680," what else uh compare ncds and declare really did i put compare with e uh you probably can't see that"
6171680,6177840," but i it was called like that and i just added e in here this probably was the wait how did they"
6177840,6186480," call that okay uh compare ncds so that's what i should have called uh classify example so let's put"
6186480,6194320," 1000 in here let's put one down okay so we have a thing that compiled right so we have a thing that"
6194320,6201600," compiled so let's go ahead and just try to um run it on the first sample from the test and see how it"
6201600,6208800," goes so yeah so we also have like class names and stuff like that it would be funny if it fails it would"
6208800,6221280," be really really really funny if it fails maybe it would make sense to print the progress of how many"
6221280,6227920," samples we processed i think that's a good idea actually so classifying sample um"
6230240,6251440," so um so we can do maybe a print f uh slash r all right so maybe yeah slash r um samples um classifying"
6251440,6261520," classifying z z u z u i train count something like that something that and afterwards we can just do"
6261520,6270160," something like this i think that's a good idea oh it's very flickering so that means it would be better"
6270160,6279440," if we just went there if we just went there and did all that choice soon in there"
6281440,6292400," uh that's very funny why is it flickering this much it's kind of funny but i mean it does the job you can"
6292400,6300160," kind of see uh slash r is supposed to basically go to the beginning all right so i don't know what's"
6300160,6309120," up with with this kind of shit but yeah we can at least see so it's basically almost halfway through now"
6309120,6320000," it is halfway through so another six uh 60 000 of them another 60 000 of them and we're about to predict"
6320000,6333520," we're about to predict the the class so i think we can we do a little bit too much of the um useless separation"
6333520,6343680," i think we don't have to recompute yeah so it failed on the first one instantly it's kind of fun uh all"
6343680,6353760," right so maybe okay so how can we speed it up we don't have to compute this thing all the time honestly"
6353760,6359840," right we don't have to compute it because we can pre-compute it once"
6360720,6367120," uh right uh right because it is the same all the time right it is the same all the time"
6367120,6370000," so what i'm thinking is that"
6370000,6381360," we can accept cb in here like like a parameter and then um here i can simply pre-compute cb"
6382880,6390400," as the text uh we still have to pass text in here because we need to pre-compute cab right concatenation"
6390400,6396960," of this thing and that's a separate thing but that may speed up the whole thing a little bit right so"
6396960,6404560," because we're doing one less uh deflate right so we're kind of doing the redundant deflate all the time"
6405520,6412880," so which is not particularly bueno in my opinion right so now uh i think it's a little bit faster"
6412880,6419360," who knows uh it's gonna have to tell well it will be visible on the whole time"
6419360,6427280," right any the why it didn't predict maybe because the key is too big i think the key is just too big"
6429920,6437840," mm-hmm so we can set the key to 100"
6437840,6446480," it's almost there almost there okay so it's it's actually faster right so as you can see this is"
6446480,6454800," what before and this is now uh business world so i think the key is too big i think the key is too big"
6455520,6458400," um how about we reduce k to 100"
6458400,6470560," how about that so uh yeah so if this is one minute right so if i just parallelize that in four"
6470560,6476560," uh is it going to be really 15 seconds though when i'm not streaming i think it's going to be faster"
6476560,6479520," right so it's definitely going to be faster"
6481040,6491760," and also as somebody said uh we can pre-compute the ends uh like a compressed distances for the training"
6491760,6499520," set right so and then the only thing that we'll have to compute is the concatenation like a cab uh in"
6499520,6505920," here so we can pre-compute this thing as well uh so this thing is pre-computed there and another thing is"
6505920,6515120," pre-computed there um so that's that may save a little bit of time as well uh still with the k it"
6515120,6520240," still doesn't really predict well right it still doesn't really predict well uh what about another"
6520240,6528480," sample right so still do they say what kind of k do they use do they say what kind of k uh it's probably"
6528480,6536400," it's not obvious right it's probably mentioned somewhere within the text or so but what's the k"
6536400,6546160," what's the actual k kind of weird all right so we can try to do a different sample let's try a different"
6546160,6556800," sample"
6556800,6562880," so uh only mention of k for all zero training methods the only hyper parameter is k"
6562880,6568320," we set k to equal for all the methods on all the data sets and we report the maximum possible accuracy"
6568320,6575440," getting from the really two"
6575440,6581680," how how two is sufficient so okay"
6581680,6589360," look i also want to double check okay thank you thank you for"
6590080,6595360," um so let me do ctrl f so to make sure that it's actually there um"
6595360,6600880," for all training"
6600880,6607360," uh for all zero"
6607360,6610720," training methods so the only hyper parameter is k"
6610720,6616160," all the methods and we report the maximum possible accuracy getting from the experiments of each"
6616800,6617600," uh okay"
6617600,6625760," all right so for the second parameter it predicted correctly right so predicted class and actual class"
6625760,6632800," uh but uh we're using k uh 100 all right so let's actually set it to two okay sure and let's see"
6632800,6639120," the first sample maybe it's just the first sample not being good enough uh right if you know what i mean"
6644000,6652240," hmm it's kind of it's kind of hard for me to believe that k of two is enough to accurately predict the class"
6652240,6654000," it's kind of bizarre to me"
6654000,6659680," i'm also a little bit worried that maybe i made a mistake somewhere"
6659680,6668240," uh right during my computation but everything i did so far makes sense right so everything i did so far makes sense"
6670640,6673680," uh just bad training data maybe"
6673680,6678560," yeah so i think it's that specific sample is kind of mad"
6678560,6682960," so yeah one of the things i want to do i want to go to ap news"
6682960,6691520," and just grab a title from there and see if it can classify just a random title from uh from ap news"
6692560,6704080," uh okay so this is those republicans so this is just like elections um okay business right so can you"
6704080,6715440," classify business investigation to focus on missing boats okay uh so we have this thing which looks like"
6716000,6726960," the thing we may care about uh right so um so does it have a dot so this is the title"
6726960,6732480," and this is some other thing so this is the text that we may want to try to predict"
6734960,6745760," uh so predicted class um"
6745760,6749760," so classify sample"
6749760,6763600," sample text so knob sv from sister so this is going to be text and we get class"
6764960,6771840," uh-uh-huh knob log knob info we're going to do text"
6771840,6781840," it's just text and then uh class class class names"
6783680,6786960," all right so let's recompile this entire thing size t class"
6786960,6795040," so you want me to have semicolon in here sure test samples we don't care about them okay let's go"
6795040,6802400," let's try to predict that specific text uh so it's supposed to be business right so it's supposed to be"
6802400,6808000," uh class world"
6808000,6814480," all right so we classified it as world not as business though"
6814480,6817920," and to be fair i would personally not classify it as business as well"
6817920,6826240," um so yeah so something like sports could have been actually something like clear"
6827200,6836240," uh right so so there was such words as coach and losing seasons and everything so that looks like"
6836240,6845120," something that could be classified as sports uh right so let's try to to see if we can classify this thing"
6845120,6853760," so what does it like uh so there's a new line in here so let's get rid of the new line let's try to"
6853760,6865520," classify that they used bzip too really uh but i mean i just use zlib all right so though all right so they're literally"
6865520,6875360," using the external tool but i mean they're just using python and what python exactly use right so"
6875360,6881840," if i understand correctly what they use they just use this thing right and what how does this thing work"
6881840,6885600," does it call to an external tool or does it do something else"
6885600,6897120," so yeah how can we replicate that in purec because in purec we just like call to zlib right so the way"
6897120,6911120," we compress this is is just this i'm not sure how good of a way to compress it this is"
6911840,6921200," uh well i mean to be fair like it classified the previous title more or less correctly uh investigation"
6921200,6928000," into why panel blew off of boeing max 9 jet focuses on missing bolts federal regulators are extended to"
6928000,6937120," ground i wouldn't classify it as business either honestly i wouldn't classify it as business either so the fact that it"
6937120,6946240," classified as this worked kind of makes sense to me so yeah so i would expect let's actually find something"
6946240,6949600," in business that is related to money um"
6949600,6954560," um so scammers for instance"
6954560,6965920," uh down but not fast enough to meet biden's goal stock market this is a good one okay uh stock market uh asian"
6965920,6978640," uh shares did i accidentally what the f is good can you just select this thing uh right so i hope they"
6978640,6987120," don't the the news website like to embed like um you know hidden things um where is the description does it"
6987120,6994320," have a description uh we can include so the first paragraph so to speak as a description"
6994320,7005040," so this looks like a solid business this looks like a solid business stock market uh shares uh"
7007280,7017840," two percent shares wall street straight up um this is a good like business i think this is a very good"
7017840,7027840," business so and hopefully that will classify this business um okay that's fun i really like that"
7028640,7033680," i think this is a good one okay okay okay even though it dog sheds slow"
7033680,7039120," this is the most business imaginable exactly"
7043200,7055680," i ran out of tea again yeah damn um um"
7055680,7065680," *sad music*"
7065680,7067680," ouch"
7067680,7071680," ouch ouch"
7071680,7083680," holy shit"
7084680,7086680," this shit works"
7086680,7090680," this fucking unironically works"
7090680,7092680," what the fuck"
7092680,7097680," like i mean it correctly so far"
7097680,7099680," like this is out of the data set"
7099680,7101680," we're picking shit out of the data set"
7101680,7103680," and it fucking works"
7103680,7104680," what the fuck"
7104680,7107680," this is so cool"
7107680,7112680," this is amazing holy shit"
7113680,7115680," okay okay okay okay okay"
7115680,7118680," so what are the class names we have"
7118680,7119680," class names"
7119680,7121680," business"
7121680,7122680," sci-tech"
7122680,7124680," okay let's actually find the sci-tech"
7124680,7126680," and let's actually read the titles"
7126680,7128680," and make sure that they're actually sci-tech"
7128680,7130680," NASA"
7130680,7131680," okay"
7131680,7132680," NASA postponed landing"
7132680,7133680," blah blah blah"
7133680,7134680," yes"
7134680,7135680," it's actually kind of sad"
7135680,7136680," why did they postpone by the way"
7136680,7138680," i kind of read"
7138680,7140680," this news"
7140680,7141680," i think today"
7141680,7143680," and i didn't look into that"
7143680,7143680," so"
7143680,7145680," what exactly happened"
7145680,7146680," is it something with"
7146680,7147680," it's actually kind of bad"
7147680,7148680," it's kind of sad"
7148680,7148680," it's actually kind of bad"
7148680,7148680," it's kind of sad"
7148680,7148680," it's kind of sad"
7148680,7148680," it's kind of sad"
7148680,7149680," it's kind of sad"
7149680,7150680," it's kind of sad"
7150680,7150680," it's kind of sad"
7150680,7151680," it's kind of sad"
7151680,7152680," it's kind of sad"
7152680,7153680," it's kind of sad"
7153680,7154680," it's kind of sad"
7154680,7155680," it's kind of sad"
7155680,7156680," it's kind of sad"
7156680,7156680," it's kind of sad"
7156680,7157680," it's kind of sad"
7157680,7158680," it's kind of sad"
7158680,7158680," it's kind of sad"
7158680,7159680," it's kind of sad"
7159680,7160680," it's kind of sad"
7160680,7161680," it's kind of sad"
7161680,7162680," it's kind of sad"
7162680,7163680," solar panel's not working"
7163680,7164680," it's kind of sad"
7164680,7166680," alrighty"
7166680,7172680," okay"
7172680,7173680," so"
7173680,7174680," so"
7174680,7175680," this should be"
7175680,7176680," scitech"
7176680,7177680," hopefully"
7177680,7188680," give it something that is misspelled"
7188680,7189680," hmm"
7189680,7191680," that would be interesting actually"
7191680,7193680," but i'm not sure if it matters"
7193680,7194680," that much"
7194680,7195680," uh"
7195680,7198680," because we have a lot of"
7198680,7199680," training samples"
7199680,7200680," and"
7200680,7202680," gzip"
7202680,7203680," might be very smart"
7203680,7204680," i think"
7204680,7206680," i don't think it matters that much"
7206680,7206680," honestly"
7206680,7208680," i think it matters that much"
7208680,7210680," and the fact that"
7210680,7212680," k equal 2"
7212680,7214680," is also enough"
7214680,7215680," it's just like"
7215680,7216680," i would expect k to be like"
7216680,7218680," at least 100"
7218680,7219680," um"
7219680,7221680," but i'm not really proficient"
7221680,7222680," i'm not really proficient"
7222680,7223680," in this kind of algorithm"
7223680,7224680," and this kind of like methods"
7224680,7225680," and stuff like that"
7225680,7226680," so"
7226680,7227680," ah"
7227680,7231680," fuck"
7231680,7232680," uh"
7232680,7233680," uh"
7233680,7236680," so we had a fluke"
7236680,7238680," we had a little bit of a fluke"
7238680,7239680," it fucked up"
7239680,7240680," uh"
7240680,7242680," fucked up"
7242680,7244680," maybe it just doesn't have enough data"
7244680,7246680," we don't have enough data guys"
7246680,7247680," guys we don't have enough data"
7247680,7249680," let's actually give it more data"
7249680,7250680," uh"
7250680,7251680," so"
7251680,7252680," maybe"
7252680,7253680," uh"
7253680,7254680," so"
7254680,7255680," maybe"
7255680,7256680," uh"
7256680,7257680," alright"
7257680,7258680," let's"
7258680,7259680," let's pick a different"
7259680,7260680," let's pick a different title"
7260680,7261680," we need to"
7261680,7262680," uh"
7262680,7263680," two companies will attempt"
7263680,7264680," the first"
7264680,7265680," uh"
7265680,7266680," so"
7266680,7269680," why is that sports"
7269680,7270680," it's"
7270680,7270680," it's"
7270680,7271680," it's so"
7271680,7272680," far off"
7272680,7273680," um"
7273680,7274680," so"
7274680,7275680," moon landing"
7275680,7276680," um"
7276680,7277680," hmm"
7277680,7278680," this one is"
7278680,7279680," looks good"
7279680,7280680," uh"
7280680,7282680," first video"
7282680,7283680," deep space"
7283680,7284680," okay"
7284680,7285680," so that looks"
7285680,7286680," very"
7286680,7287680," sci-techy"
7287680,7288680," if you know what i mean"
7288680,7289680," right"
7289680,7290680," so there's"
7290680,7291680," there's"
7291680,7292680," there are even cats in here"
7292680,7293680," cats in here"
7293680,7294680," really like that"
7294680,7295680," um"
7295680,7297680," const char"
7297680,7298680," text"
7298680,7303680," lasers"
7303680,7305680," deep space"
7305680,7306680," uh"
7306680,7307680," stars"
7307680,7308680," video"
7308680,7309680," laser"
7309680,7310680," deep space"
7310680,7311680," so"
7311680,7312680," yeah"
7312680,7313680," that could be"
7313680,7314680," that could be a thing"
7314680,7315680," so we're having a hard time"
7315680,7316680," classifying sci-tech"
7316680,7317680," apparently"
7317680,7321680," we have a little bit of a hard time"
7321680,7322680," classifying sci-tech"
7322680,7323680," mmm"
7323680,7325680," i bet the word"
7325680,7327680," place your bets chat"
7327680,7328680," place your bets"
7328680,7329680," so"
7329680,7330680," twitch has like"
7330680,7331680," these sort of prediction things"
7331680,7332680," we could have actually started"
7332680,7333680," predictions and stuff"
7333680,7335680," but i don't know how to use that"
7335680,7337680," i don't know how to twitch"
7337680,7338680," i'm sorry"
7338680,7339680," i don't know how to twitch"
7339680,7340680," i'm not engaging enough"
7340680,7342680," dead streamer"
7342680,7343680," literally"
7343680,7344680," dead streamer"
7344680,7345680," streamer"
7345680,7347680," um"
7347680,7348680," okay"
7348680,7349680," so"
7349680,7351680," world"
7351680,7353680," all right"
7353680,7354680," all right"
7354680,7355680," so that was"
7355680,7357680," somebody actually predicted world"
7357680,7358680," right"
7358680,7359680," somebody actually predicted world"
7359680,7359680," right"
7359680,7360680," somebody actually predicted world"
7360680,7361680," maybe"
7361680,7363680," something about computers"
7363680,7364680," uh"
7364680,7365680," could be"
7365680,7366680," you know"
7366680,7367680," predicted properly"
7367680,7368680," so"
7368680,7371680," is there any website on like computer news"
7371680,7372680," computer"
7372680,7373680," news"
7373680,7374680," uh"
7374680,7376680," oh my god why it's so slow computer news"
7376680,7378680," um"
7378680,7379680," so"
7379680,7381680," let's try to be deep computer news"
7381680,7384680," so"
7384680,7385680," tech news"
7385680,7386680," computer world"
7386680,7388680," wired"
7388680,7390680," uh-huh"
7390680,7391680," uh-huh"
7391680,7394680," uh"
7394680,7395680," startup firm"
7395680,7396680," uh creates"
7396680,7397680," to cache"
7397680,7398680," a"
7398680,7398680," okay"
7398680,7399680," so"
7399680,7400680," let me try to"
7400680,7401680," so"
7401680,7402680," this must be tech"
7402680,7404680," this must be tech"
7404680,7406680," uh-huh"
7406680,7408680," const char"
7408680,7409680," text"
7409680,7413680," the"
7413680,7414680," mistakes"
7414680,7416680," uh-huh"
7416680,7417680," all right"
7417680,7418680," so we also have some"
7418680,7419680," unicode"
7419680,7420680," but maybe that's fine"
7420680,7422680," maybe that's fine"
7422680,7424680," okay"
7424680,7426680," this is probably gonna be the last one"
7426680,7428680," after that one i'm gonna call it"
7428680,7430680," i'm gonna call it a"
7430680,7432680," so we also have ai in here"
7432680,7434680," i don't know how much ai we have in"
7434680,7435680," ag news"
7435680,7436680," news"
7436680,7437680," *sad music*"
7437680,7438680," *sad music*"
7438680,7439680," *sad music*"
7439680,7449680," um"
7449680,7462000," okay okay okay i i know what is it up i know what it up"
7465120,7472400," startup firm okay sci tech is a very difficult category to predict right it's a very difficult"
7472400,7483920," category to predict um so yeah uh we can okay so let me let me see so what do we have um so sci tech"
7483920,7492240," is basically four we can go into the data test and uh all right so we can just pick this thing"
7493040,7502400," and see how well does it predict so it's supposed to be uh sci tech uh right so we have that uh might"
7502400,7514800," as well just get rid of that try so yeah this one is like very easy to explain because i think it"
7514800,7519440," picked up on startup right startup is probably business so business is closer"
7520960,7523200," business turned out to be closer"
7523200,7538080," uh how is that sci tech um spam suspension shares uh percent mobile phone network"
7538080,7547680," bet business but i mean it's from the test data this is from the test data so"
7548800,7554240," uh it should predict uh it should predict so maybe the the training just doesn't have enough"
7554240,7561600," uh you know data on site tech maybe that's the problem in here that's the problem"
7561600,7572240," come on you can do that it's almost there it's almost there i'm about to dab about dab and all the"
7572240,7586480," the doubters okay so the conclusion is sci tech is very uh vague term it is very vague term it's really"
7586480,7596640," difficult to uh to predict right so so far something like sport is way easier to predict so let's take a look at the sport"
7598000,7604320," uh but though so the problem here is that the computation is also very slow it if it was a"
7604320,7609200," little bit faster we could have actually iterated a little bit quicker it would be kind of nice to"
7609200,7614880," iterate through all of the like test samples and see the percentage of how accurately it predicts the"
7614880,7626560," sum of the test samples um all right so and this one is supposed to be the sports right so uh coach right so"
7626560,7630720," so seasons and stuff like that so that's gonna be i think"
7630720,7639200," the data is biased copium yeah exactly the data is just biased"
7639200,7646960," uh all right come on come on we're almost computed"
7649040,7659120," and it is sports look at that it correctly predicted that it is conscious holy guys it is conscious it"
7659120,7665920," understands the text the only way it could have predicted that class is if only it understood it"
7665920,7673440," that's the only way it can predict the class there's no other way it understands it it has conscious holy"
7673440,7691920," all right so that was fun uh so yeah we can spend some time maybe speeding it up maybe i'll spend some"
7691920,7697760," time off screen we'll see we'll see but yeah that's a fun little paper uh right obviously what they did they"
7697760,7705120," evaluated on shed ton of different kind of data sets and uh apparently it worked it worked really well"
7705120,7712880," so and that thing performed on par with large language models"
7712880,7718320," which tells you the accuracy of large language models"
7721040,7727280," if this shit performed on par with large language models i'm i'm very pessimistic honestly right"
7727280,7736720," so anyway i guess that's it for today thanks everyone who's watching right now i really appreciate"
7736720,7744320," it uh have a good one and i see you all on the next recreation programming session with mr azuzin i love you"
